{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no gpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import tiktoken\n",
    "from llm.previous_chapters import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu available\")\n",
    "else:\n",
    "    print(\"no gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dataset_path = os.path.join(os.getcwd(), \"datasets\", \"spam_dataset\")\n",
    "dataset_path = os.path.join(root_dataset_path, \"SMSSpamCollection\")\n",
    "assert os.path.exists(dataset_path), f\"path to dataset not exists {dataset_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path, sep=\"\\t\", header=None, names =['label', 'text'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#undersample for testing\n",
    "def create_balanced_dataset(df: pd.DataFrame):\n",
    "    num_spam = df[df[\"label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    #make # of ham == # spam\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"label\"] == 'spam']])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df shape =  (3900, 2)\n",
      "valid df shape =  (557, 2)\n",
      "test df shape =  (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "def random_split(df, train_frac, valid_frac):\n",
    "    #shuffle\n",
    "    df = df.sample(frac = 1, random_state = 123).reset_index(drop=True)\n",
    "\n",
    "    train_idx = int(train_frac * len(df))\n",
    "    val_idx = train_idx + int(valid_frac * len(df))\n",
    "    #the rest is test\n",
    "\n",
    "    train_df = df[:train_idx]\n",
    "    val_df = df[train_idx:val_idx]\n",
    "    test_df = df[val_idx:]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = random_split(df, 0.7, 0.1)\n",
    "\n",
    "print(\"train df shape = \", train_df.shape)\n",
    "print(\"valid df shape = \", val_df.shape)\n",
    "print(\"test df shape = \", test_df.shape)\n",
    "\n",
    "train_df.to_csv(os.path.join(root_dataset_path, \"sample_train.csv\"), index = False)\n",
    "val_df.to_csv(os.path.join(root_dataset_path, \"sample_val.csv\"), index = False)\n",
    "test_df.to_csv(os.path.join(root_dataset_path, \"sample_test.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Map label\n",
    "balanced_df['label'] = balanced_df['label'].map({'ham': 0, 'spam': 1})\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad tokens with longest token len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50256\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "pad_id = tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})[0]\n",
    "print(pad_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv, tokenizer, pad_token_id, max_len = 200):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.df.drop(0, inplace=True)\n",
    "        self.df['label'] = self.df['label'].map({'ham': 0, 'spam': 1})\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "        self.encoded_text = [self._pad_tokens(tokenizer.encode(text)) for text in self.df['text']]\n",
    "\n",
    "    def _pad_tokens(self, tokens):\n",
    "        tokens = tokens + [self.pad_token_id] * (self.max_len - len(tokens))\n",
    "        return tokens\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.encoded_text[index]\n",
    "        y = self.df.iloc[index]['label']\n",
    "        \n",
    "        return (torch.tensor(X).long(), torch.tensor(y).long())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_text)\n",
    "    \n",
    "    def get_dataloader(self, batch_size, num_workers, drop_last = False):\n",
    "        return DataLoader(dataset = self, batch_size=batch_size, num_workers=num_workers, drop_last = drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 5122,  1736,  1077,   415, 17442,   272,   338,  2802,  3804,  1497,\n",
      "          938,  1755,    13, 12472,   329,   607,   290,  1641,    13, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]), tensor(0))\n",
      "3899\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(os.path.join(root_dataset_path, \"sample_train.csv\"), tokenizer, pad_id, max_len = 100)\n",
    "train_dataset.df.head()\n",
    "print(train_dataset[0])\n",
    "print(len(train_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556\n",
      "1114\n"
     ]
    }
   ],
   "source": [
    "val_dataset = SpamDataset(os.path.join(root_dataset_path, \"sample_val.csv\"), tokenizer, pad_id, max_len = 100)\n",
    "print(len(val_dataset))\n",
    "test_dataset = SpamDataset(os.path.join(root_dataset_path, \"sample_test.csv\"), tokenizer, pad_id, max_len = 100)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader len =  487\n",
      "X shape = torch.Size([8, 100]), y shape = torch.Size([8])\n",
      "val loader len =  70\n",
      "test loader len =  140\n"
     ]
    }
   ],
   "source": [
    "#Get dataloader\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = train_dataset.get_dataloader(batch_size=batch_size, num_workers=num_workers, drop_last=True) #drop last unmatched element for training\n",
    "val_loader = val_dataset.get_dataloader(batch_size=batch_size, num_workers=num_workers, drop_last=False)\n",
    "test_loader = test_dataset.get_dataloader(batch_size=batch_size, num_workers=num_workers, drop_last=False)\n",
    "\n",
    "print(\"train loader len = \", len(train_loader))\n",
    "sample = next(iter(train_loader))\n",
    "print(f\"X shape = {sample[0].shape}, y shape = {sample[1].shape}\")\n",
    "print(\"val loader len = \", len(val_loader))\n",
    "print(\"test loader len = \", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader len =  487\n",
      "val loader len =  70\n",
      "test loader len =  140\n"
     ]
    }
   ],
   "source": [
    "print(\"train loader len = \", len(train_loader))\n",
    "print(\"val loader len = \", len(val_loader))\n",
    "print(\"test loader len = \", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pretrained model. \n",
    "Code in Chapt 5, load from book's code, my GPT code is messed up\n",
    "because my GPTCode is slightly different than theirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = torch.load(os.path.join(\"output\", 'gpt.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are the world's first, best-known international music company,\n"
     ]
    }
   ],
   "source": [
    "text = \"we are the world\" \n",
    "tokens = text_to_token_ids(text, tokenizer)\n",
    "\n",
    "output_tokens = generate(gpt, tokens, max_new_tokens=10, context_size=BASE_CONFIG[\"context_length\"], temperature=2.0, top_k=10)\n",
    "\n",
    "decoded = token_ids_to_text(output_tokens, tokenizer)\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are the world's only company that provides the world with all the\n"
     ]
    }
   ],
   "source": [
    "# Sample instruction\n",
    "text2 = (\"Is the following spam, answer with yes or no\", \n",
    "\"'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\")\n",
    "\n",
    "tokens = text_to_token_ids(text, tokenizer)\n",
    "\n",
    "output_tokens = generate(gpt, tokens, max_new_tokens=10, context_size=BASE_CONFIG[\"context_length\"], temperature=2.0, top_k=10)\n",
    "\n",
    "decoded = token_ids_to_text(output_tokens, tokenizer)\n",
    "\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "#Freeze model params for finetuning\n",
    "for param in gpt.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "gpt.out_head = nn.Linear(\n",
    "    BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features=num_classes\n",
    ")\n",
    "\n",
    "\n",
    "#NOTE from the book: \n",
    "# training the output layer we just added is sufficient. \n",
    "# However, as I found in experiments, finetuning additional layers can \n",
    "# noticeably improve the predictive performance of the finetuned model.\n",
    "\n",
    "for p in gpt.trf_blocks[-1].parameters():\n",
    "    p.requires_grad = True\n",
    "for p in gpt.final_norm.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape =  torch.Size([1, 5])\n",
      "output shape =  torch.Size([1, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "# test new model architecture\n",
    "text = \"This definitely a spam email\"\n",
    "ids = text_to_token_ids(text, tokenizer)\n",
    "print('input shape = ', ids.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = gpt(ids)\n",
    "\n",
    "print('output shape = ', output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79bd7a421c8fa56dafc3a7d5d6c958c1d5d73add0a33880867e978912e0c760c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

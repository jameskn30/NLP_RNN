{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    " \n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    " \n",
    "file_path = \"instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    " \n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task.\"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
    "    return instruction_text + input_text\n",
    "\n",
    "def format_output(entry):\n",
    "    return f\"\\n\\n### Response:\\n{entry['output']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "input = format_input(data[50])\n",
    "output = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(input + output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train data =  935\n",
      "len test data =  110\n",
      "len valid data =  55\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85) \n",
    "valid_portion = int(len(data) * 0.05) \n",
    "test_portion = int(len(data) * 0.1) \n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion: train_portion + test_portion]\n",
    "valid_data = data[train_portion + test_portion:]\n",
    "\n",
    "print('len train data = ', len(train_data))\n",
    "print('len test data = ', len(test_data))\n",
    "print('len valid data = ', len(valid_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n",
      "1100\n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 16594, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 36, 2100, 4985, 262, 1708, 9546, 416, 25449, 340, 656, 262, 24993, 1813, 13, 198, 198, 21017, 23412, 25, 198, 19503, 521, 14610, 1545, 198, 198, 21017, 18261, 25, 198, 464, 24993, 286, 262, 1813, 9546, 366, 19503, 521, 1, 318, 11491, 11, 262, 3376, 24993, 318, 366, 6726, 1911]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "print(tokenizer.encode('<|endoftext|>', allowed_special={'<|endoftext|>'}))\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self,data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_text = []\n",
    "\n",
    "        for entry in data:\n",
    "\n",
    "            instruction_input = format_input(entry)\n",
    "            instruction_output = format_output(entry)\n",
    "            full_text = instruction_input + instruction_output\n",
    "            self.encoded_text.append(tokenizer.encode(full_text))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_text[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded_text)\n",
    "\n",
    "dataset = InstructionDataset(data, tokenizer)\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 74]) ,  tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 16594,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,\n",
      "           13,   198,   198, 21017, 23412,    25,   198,  1544,   467,   284,\n",
      "          262,  3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,  1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256])\n",
      "torch.Size([10, 74]) ,  tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 16594,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 18378,   262,  1708,  6827,   329, 23491,    13,\n",
      "          198,   198, 21017, 23412,    25,   198,  1544,   467,   284,   262,\n",
      "         3952,   790,  1110,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "         1544,  2925,   284,   262,  3952,   790,  1110,    13, 50256,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch, pad_token_id = 50256, ignore_index = -100, allowed_max_len = None, device = 'cpu'):\n",
    "    #why ignore_index = -100? \n",
    "\n",
    "    batch_max_len = max(len(item) + 1 for item in batch)\n",
    "    input_lst, target_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id] #this is for contructing target with 1 token shifted to the right\n",
    "        padded = new_item + [pad_token_id] * (batch_max_len - len(new_item))\n",
    "\n",
    "        input = torch.tensor(padded[:-1])\n",
    "        target = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = target == pad_token_id\n",
    "\n",
    "        # the reason we want this is because we want to keep the 1st\n",
    "        # endoftext token but replace the rest. therefore, indices[1:]\n",
    "        # other approach like a[a == mask] = replace_value \n",
    "        # or torch.where() works only if you want to replace ALL ELEMENTS\n",
    "\n",
    "        indicies = torch.nonzero(mask).squeeze() \n",
    "        if indicies.numel() > 1:\n",
    "            target[indicies[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_len != None: \n",
    "            input = input[:allowed_max_len]\n",
    "            target = target[:allowed_max_len]\n",
    "\n",
    "        input_lst.append(input)\n",
    "        target_lst.append(target)\n",
    "    \n",
    "    input_tensor = torch.stack(input_lst).to(device)\n",
    "    target_tensor = torch.stack(target_lst).to(device)\n",
    "    \n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "input_tensor, target_tensor = collate_fn(dataset[:10])\n",
    "print(input_tensor.shape, ', ', input_tensor[1])\n",
    "print(target_tensor.shape, ', ', target_tensor[1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 16594, 257, 2882, 326, 20431, 32543, 262, 2581, 13, 198, 198, 21017, 46486, 25, 198, 18378, 262, 1708, 6827, 329, 23491, 13, 198, 198, 21017, 23412, 25, 198, 1544, 467, 284, 262, 3952, 790, 1110, 13, 198, 198, 21017, 18261, 25, 198, 1544, 2925, 284, 262, 3952, 790, 1110, 13]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(collate_fn, device = 'cpu', allowed_max_len = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train dataset =  935\n",
      "len valid dataset =  55\n",
      "len test dataset =  110\n",
      "X.shape =  torch.Size([8, 65]) , y.shape =  torch.Size([8, 65])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle = True,\n",
    "    #last entry will have different shape, like normal batch = (10,100), last entry will have (8,100). \n",
    "    # This cause training error in the middle of training\n",
    "    drop_last = True, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(valid_data, tokenizer)\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    #last entry will have different shape, like normal batch = (10,100), last entry will have (8,100). \n",
    "    # This cause training error in the middle of training\n",
    "    drop_last = False, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle = False,\n",
    "    #last entry will have different shape, like normal batch = (10,100), last entry will have (8,100). \n",
    "    # This cause training error in the middle of training\n",
    "    drop_last = False, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "print('len train dataset = ', len(train_dataset))\n",
    "print('len valid dataset = ', len(val_dataset))\n",
    "print('len test dataset = ', len(test_dataset))\n",
    "\n",
    "\n",
    "#sample shape\n",
    "for i, (X,y) in enumerate(train_dataloader):\n",
    "    print('X.shape = ', X.shape, ', y.shape = ',y.shape)\n",
    "    print()\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download pretrained GPT2 Medium model\n",
    "\n",
    "- 355M params, 1.42gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gpt_download import download_and_load_gpt2\n",
    "# from chapter04 import GPTModel\n",
    "# from chapter05 import load_weights_into_gpt\n",
    " \n",
    "# BASE_CONFIG = {\n",
    "#     \"vocab_size\": 50257,     # Vocabulary size\n",
    "#     \"context_length\": 1024,  # Context length\n",
    "#     \"drop_rate\": 0.0,        # Dropout rate\n",
    "#     \"qkv_bias\": True         # Query-key-value bias\n",
    "# }\n",
    " \n",
    "# model_configs = {\n",
    "#     \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "#     \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "#     \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "#     \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "# }\n",
    " \n",
    "# CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "# BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    " \n",
    "# model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "# settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    " \n",
    "# model = GPTModel(BASE_CONFIG)\n",
    "# load_weights_into_gpt(model, params)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn from cleanrl implementation\n",
    "\n",
    "https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14f647490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import deque, Counter, namedtuple, defaultdict\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import math\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import uuid\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from stable_baselines3.common.atari_wrappers import (\n",
    "    ClipRewardEnv, \n",
    "    EpisodicLifeEnv, #make end of life = end of episode\n",
    "    FireResetEnv,\n",
    "    MaxAndSkipEnv,\n",
    "    NoopResetEnv\n",
    ")\n",
    "\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "#seed\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cpu\n"
     ]
    }
   ],
   "source": [
    "ENV_ARGS = {\n",
    "    'id': 'AssaultNoFrameskip-v0'\n",
    "}\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "OUTPUT = os.path.join(ROOT, 'output', ENV_ARGS['id'])\n",
    "\n",
    "if os.path.exists(OUTPUT) == False:\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "NUM_ENVS = 3\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"device = \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(**env_args):\n",
    "    env = gym.make(**env_args)\n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    env = NoopResetEnv(env)\n",
    "    env = MaxAndSkipEnv(env)\n",
    "    env = EpisodicLifeEnv(env)\n",
    "    if \"FIRE\" in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = ClipRewardEnv(env)\n",
    "    env = gym.wrappers.ResizeObservation(env, (84, 84))\n",
    "    env = gym.wrappers.GrayScaleObservation(env)\n",
    "    env = gym.wrappers.FrameStack(env, 4)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "class ReplayMemory():\n",
    "    def __init__(self, capacity, device = 'cpu') -> None:\n",
    "        self.capacity = capacity\n",
    "        self.memory = deque(maxlen = capacity)\n",
    "        self.device = device\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.memory.append(Transition(state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        '''\n",
    "        @params: \n",
    "            batch_size: int\n",
    "        @return:\n",
    "            states: torch.tensor\n",
    "            actions: torch.tensor\n",
    "            rewards: torch.tensor\n",
    "            next_states: torch.tensor\n",
    "            done: torch.tensor\n",
    "        '''\n",
    "        if batch_size > len(self.memory): return None\n",
    "        transitions = random.sample(self.memory, batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        device = self.device\n",
    "\n",
    "        state_batch = torch.tensor(batch.state).float().to(device)\n",
    "        next_state_batch = torch.tensor(batch.next_state).float().to(device)\n",
    "        action_batch = torch.tensor(np.vstack(batch.action)).long().to(device)\n",
    "        reward_batch = torch.tensor(np.vstack(batch.reward)).float().to(device)\n",
    "        done_batch = torch.tensor(np.vstack(batch.done)).float().to(device)\n",
    "\n",
    "        return (state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.memory.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, envs: gym.Env):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_shape = np.prod(envs.single_observation_space.shape)\n",
    "        self.action_shape = np.prod(envs.single_action_space.n)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.LazyConv2d(32, 8, stride = 4),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyConv2d(64, 4, stride = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyConv2d(64, 3, stride = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(512),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(self.action_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x/255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation shape =  torch.Size([3, 4, 84, 84])\n",
      "observation shape =  7\n",
      "action shape =  torch.Size([3, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# Test running network on env\n",
    "\n",
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), 'Only discrete action is supported'\n",
    "\n",
    "obs, info = envs.reset()\n",
    "obs = torch.tensor(obs)\n",
    "print('observation shape = ', obs.shape)\n",
    "print('observation shape = ', envs.single_action_space.n)\n",
    "\n",
    "qnet = QNetwork(envs)\n",
    "\n",
    "action = qnet(obs)\n",
    "\n",
    "print('action shape = ', action.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsilone decay function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(start_e: int, end_e:int , total_t:int , t:int ):\n",
    "    # epsilone value decays linear\n",
    "    slope = (end_e - start_e) / total_t\n",
    "    return max(slope * t + start_e, end_e)\n",
    "\n",
    "def plot_schedule(function, start_e, end_e, duration, explore_fraction = 1.0):\n",
    "    #  explore for some time, then only exploit (epsilon stays at end_e)\n",
    "    data = []\n",
    "\n",
    "    for t in range(duration):\n",
    "        v = function(start_e, end_e, int(explore_fraction * duration), t)\n",
    "        data.append(v)\n",
    "    \n",
    "    sns.lineplot(y = data, x = list(range(len(data))))\n",
    "    plt.title('schedule plot')\n",
    "    plt.show()\n",
    "\n",
    "def plot(history, show = False, save_path = None):\n",
    "    sns.lineplot(y = history['reward'], x = list(range(len(history['reward']))))\n",
    "\n",
    "    if save_path != None:\n",
    "        plt.savefig(save_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "plot_schedule(linear_schedule, 1.0, 0.01, 1000, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(envs, policy_net, target_net, optimizer, start_ep, end_ep, gamma,\n",
    "    explore_fraction = 0.3, \n",
    "    buffer_size=int(1e6), batch_size = 32,\n",
    "    total_timesteps = int(10e6), warmup_steps = 5000, skip_steps = 4,\n",
    "    device = DEVICE, plot_update_freq = 50, label = 'baseline'):\n",
    "\n",
    "    observation_space = envs.single_observation_space\n",
    "    action_space = envs.single_action_space\n",
    "    n_envs = envs.observation_space.shape[0]\n",
    "\n",
    "    SAVE_PATH = os.path.join(OUTPUT, label)\n",
    "    FIG_SAVE_PATH = os.path.join(SAVE_PATH, 'plot.png')\n",
    "\n",
    "    if os.path.exists(SAVE_PATH) == False:\n",
    "        os.makedirs(SAVE_PATH)\n",
    "\n",
    "    print('save path = ', SAVE_PATH)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(\n",
    "        buffer_size,\n",
    "        observation_space,\n",
    "        action_space,\n",
    "        device,\n",
    "        n_envs=n_envs,\n",
    "        optimize_memory_usage=True,\n",
    "        handle_timeout_termination=False\n",
    "    )\n",
    "\n",
    "    obs, _ = envs.reset()\n",
    "    loop = tqdm(range(total_timesteps))\n",
    "\n",
    "    score_window = deque(maxlen=100)\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for global_step in loop:\n",
    "\n",
    "\n",
    "        epsilon = linear_schedule(start_ep, end_ep, int( explore_fraction *  total_timesteps), global_step)\n",
    "\n",
    "        #greedy epsilon \n",
    "        p = random.random()\n",
    "\n",
    "        if epsilon > p:\n",
    "            #explore\n",
    "            actions = np.array([envs.single_action_space.sample() for _ in range(n_envs)])\n",
    "        else:\n",
    "            action_pred = policy_net(torch.tensor(obs).to(device)) \n",
    "            actions = torch.argmax(action_pred, dim = 1).cpu().numpy()\n",
    "        \n",
    "        # print('actions = ', actions.shape)\n",
    "        \n",
    "        next_obs, rewards, terminated, truncated, infos = envs.step(actions)\n",
    "        # print('next obs =', next_obs.shape)\n",
    "        # print('rewards obs =', rewards.shape)\n",
    "        # print('terminated obs =', terminated.shape)\n",
    "        # print('truncated obs =', truncated.shape)\n",
    "\n",
    "        if 'final_info' in infos:\n",
    "            for k,v in infos.items():\n",
    "                for info in infos['final_info']:\n",
    "                    if info and 'episode' in info:\n",
    "                        ep_return = info['episode']['r']\n",
    "                        score_window.append(ep_return)\n",
    "                        avg_reward = np.mean(score_window)\n",
    "                        history['reward'].append(avg_reward)\n",
    "        \n",
    "        #save transition to replay buffer\n",
    "        real_next_obs = next_obs.copy()\n",
    "        for idx, trunc in enumerate(truncated):\n",
    "            if trunc:\n",
    "                real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
    "        \n",
    "        replay_buffer.add(obs, real_next_obs, actions, rewards, terminated, infos)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "        #training with DQN algorithm\n",
    "        if global_step > warmup_steps:\n",
    "            if global_step % skip_steps == 0:\n",
    "                b_obs, b_actions, b_next_obs, b_dones, b_rewards = replay_buffer.sample(batch_size)\n",
    "\n",
    "                # print('b obs = ', b_obs.shape)\n",
    "                # print('b actions = ', b_actions.shape)\n",
    "                # print('b next_obs = ', b_next_obs.shape)\n",
    "                # print('b dones = ', b_dones.shape)\n",
    "                # print('b rewards = ', b_rewards.shape)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    target_value = target_net(b_next_obs).max(1).values\n",
    "                    td_target = b_rewards.flatten() + gamma * target_value * (1 - b_dones.flatten())\n",
    "                \n",
    "                old_value = policy_net(b_obs).gather(1, b_actions).squeeze()\n",
    "\n",
    "                loss = F.mse_loss(old_value, target_value)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            if global_step % plot_update_freq == 0: \n",
    "                plot(history, save_path = FIG_SAVE_PATH)\n",
    "        \n",
    "\n",
    "        loop.set_description(f\"epsilon = {epsilon:.2f}, avg_reward = {np.mean(score_window):.2f}, episodes = {len(history['reward'])}\")\n",
    "    \n",
    "    plot(history, show = True, save_path = FIG_SAVE_PATH)\n",
    "    \n",
    "    with open(os.path.join(SAVE_PATH, 'history.pickle'), 'wb') as file:\n",
    "        pickle.dump(history, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 28.24GB > 1.62GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation shape =  torch.Size([2, 4, 84, 84])\n",
      "observation shape =  7\n",
      "save path =  /Volumes/SanDisk/NLP_RNN/Reinforcement Learning/deep rl/dqn/output/AssaultNoFrameskip-v0/baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epsilon = 0.98, avg_reward = 273.00, episodes = 1794:   1%|          | 51908/10000000 [18:23<58:46:07, 47.02it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m target_net \u001b[38;5;241m=\u001b[39m QNetwork(envs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(policy_net\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43mstart_ep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_ep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_ep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_ep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_update_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mplot_update_freq\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m, in \u001b[0;36mtune\u001b[0;34m(envs, policy_net, target_net, optimizer, start_ep, end_ep, gamma, explore_fraction, buffer_size, batch_size, total_timesteps, warmup_steps, skip_steps, device, plot_update_freq, label)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# print('b obs = ', b_obs.shape)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print('b actions = ', b_actions.shape)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# print('b next_obs = ', b_next_obs.shape)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# print('b dones = ', b_dones.shape)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# print('b rewards = ', b_rewards.shape)\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 89\u001b[0m     target_value \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_next_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     90\u001b[0m     td_target \u001b[38;5;241m=\u001b[39m b_rewards\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m target_value \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m b_dones\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m     92\u001b[0m old_value \u001b[38;5;241m=\u001b[39m policy_net(b_obs)\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, b_actions)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m, in \u001b[0;36mQNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1472\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1474\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#parameters\n",
    "lr = 1e-4\n",
    "start_ep = 1.0\n",
    "end_ep = 0.01\n",
    "total_timesteps = int(1e7)\n",
    "device = DEVICE\n",
    "gamma = 0.99\n",
    "plot_update_freq =100\n",
    "\n",
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(2)]\n",
    ") \n",
    "\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), 'Only discrete action is supported'\n",
    "\n",
    "obs, info = envs.reset()\n",
    "obs = torch.tensor(obs)\n",
    "print('observation shape = ', obs.shape)\n",
    "print('observation shape = ', envs.single_action_space.n)\n",
    "\n",
    "policy_net = QNetwork(envs).to(device)\n",
    "target_net = QNetwork(envs).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr = lr)\n",
    "\n",
    "tune(envs, policy_net, target_net, optimizer, \n",
    "start_ep = start_ep, end_ep = end_ep, gamma= gamma,\n",
    "device = device, total_timesteps=total_timesteps, plot_update_freq= plot_update_freq)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

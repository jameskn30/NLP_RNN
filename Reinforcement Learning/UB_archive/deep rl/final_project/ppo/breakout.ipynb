{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n",
    "\n",
    "https://github.com/vwxyzjn/cleanrl?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import deque, Counter, namedtuple, defaultdict\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import math\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import uuid\n",
    "import pickle\n",
    "\n",
    "from stable_baselines3.common.atari_wrappers import ClipRewardEnv, FireResetEnv, MaxAndSkipEnv, NoopResetEnv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c31c2b9ad0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENV_ARGS = {\n",
    "    'id': \"BreakoutNoFrameskip-v4\"\n",
    "}\n",
    "NUM_ENVS = 6\n",
    "SEED = 1\n",
    "LR = 3e-4\n",
    "NUM_STEPS = 2048\n",
    "NUM_ITERATIONS = 1000\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "UPDATE_EPOCHS = 10\n",
    "CLIP_COEF = 0.2 # the epsilon in KL divergece in PPO paper\n",
    "ENTROPY_COEF = 0.0\n",
    "VF_COEF = 0.5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "MINI_BATCH_COUNT = 32\n",
    "UPDATE_PLOTS = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device = ', DEVICE)\n",
    "\n",
    "#output directory\n",
    "ROOT = os.getcwd()\n",
    "OUTPUT = os.path.join(ROOT, 'output', ENV_ARGS['id'])\n",
    "\n",
    "if os.path.exists(OUTPUT) == False:\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "#seeding\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.envs.registration.registry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(**ENV_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(**env_args):\n",
    "    env = gym.make(**env_args)\n",
    "    # env = gym.wrappers.FlattenObservation(env)\n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    env = NoopResetEnv(env, noop_max=30)\n",
    "    env = MaxAndSkipEnv(env, skip = 4)\n",
    "\n",
    "    env = ClipRewardEnv(env)\n",
    "    env = gym.wrappers.ResizeObservation(env, (84,84)) \n",
    "    env = gym.wrappers.GrayScaleObservation(env) \n",
    "    env = gym.wrappers.FrameStack(env, 4) \n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), 'Only discrete action is supported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer: nn.Linear, std = np.sqrt(2), bias_const = 0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "class Agent(nn.Module):\n",
    "\n",
    "    def __init__(self, envs: gym.Env, hidden_size: int = 512):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Conv2d(4, 32, 8, stride = 4)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, 4, stride = 2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, 3, stride = 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            layer_init(nn.Linear(64 * 7 * 7, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.actor = layer_init(nn.Linear(hidden_size, envs.single_action_space.n), std = 0.01)\n",
    "        self.critic = layer_init(nn.Linear(hidden_size,1 ), std = 1.0)\n",
    "    \n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x/255.0))\n",
    "    \n",
    "    def get_action_and_value(self, x, action = None):\n",
    "        '''\n",
    "        @params:\n",
    "            x: torch.tensor observation, shape = (N, observation size)\n",
    "            action: torch.tensor action\n",
    "        @returns:\n",
    "            action: torch.tensor, shape = (N, action size)\n",
    "            log_prob: torch.tensor, shape = (N,)\n",
    "            entropy: torch.tensor, shape = (N,)\n",
    "            value: torch.tensor, shape = (N,)\n",
    "        '''\n",
    "\n",
    "        hidden = self.network(x/255.0)\n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action == None:\n",
    "            action = probs.sample()\n",
    "\n",
    "        log_prob = probs.log_prob(action)\n",
    "        entropy = probs.entropy()\n",
    "        value = self.critic(hidden)\n",
    "        return action, log_prob, entropy, value\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape =  torch.Size([6, 4, 84, 84])\n",
      "action shape =  torch.Size([6])\n",
      "log prob shape =  torch.Size([6])\n",
      "entropy shape =  torch.Size([6])\n",
      "value shape =  torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "#Test agent\n",
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), 'Only discrete action is supported'\n",
    "\n",
    "obs, info = envs.reset()\n",
    "obs = torch.tensor(obs).float()\n",
    "print('obs shape = ', obs.shape)\n",
    "\n",
    "test_agent = Agent(envs)\n",
    "\n",
    "action, log_prob, entropy, value = test_agent.get_action_and_value(obs)\n",
    "\n",
    "print('action shape = ', action.shape)\n",
    "print('log prob shape = ', log_prob.shape)\n",
    "print('entropy shape = ', entropy.shape)\n",
    "print('value shape = ', value.shape)\n",
    "\n",
    "envs.close()\n",
    "del test_agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, show = False, save_path = None):\n",
    "    sns.lineplot(y = history['reward'], x = list(range(len(history['reward']))))\n",
    "\n",
    "    if save_path != None:\n",
    "        plt.savefig(save_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(agent, episodes = 10):\n",
    "    envs = gym.vector.SyncVectorEnv([lambda: make_env(gamma = GAMMA, **ENV_ARGS)])\n",
    "    agent.eval()\n",
    "    total_rewards = []\n",
    "    next_obs, _ = envs.reset()\n",
    "\n",
    "    while len(total_rewards) < episodes: \n",
    "        next_obs = torch.Tensor(next_obs)\n",
    "        with torch.no_grad():\n",
    "            action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "\n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.numpy())\n",
    "\n",
    "        if 'final_info' in info:\n",
    "            for data in info['final_info']:\n",
    "                if data:\n",
    "                    reward = data['episode']['r'][0]\n",
    "                    total_rewards.append(reward)\n",
    "\n",
    "    return total_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(envs, agent, optimizer, num_steps, num_envs, device, \n",
    "         num_iterations = 1000, update_epochs = 10,\n",
    "         label = 'test', plot_udpate_freq = 10, history = None):\n",
    "\n",
    "    # label = str(uuid.uuid4()).split('-')[0]\n",
    "    agent.to(device)\n",
    "\n",
    "    print('run id = ', label)\n",
    "    SAVE_PATH = os.path.join(OUTPUT, label)\n",
    "    FIG_SAVE_PATH = os.path.join(SAVE_PATH, 'plot.png')\n",
    "    if os.path.exists(SAVE_PATH) == False:\n",
    "        print(f'output folder: {SAVE_PATH}')\n",
    "        os.makedirs(SAVE_PATH)\n",
    "    print('save path = ', SAVE_PATH)\n",
    "\n",
    "    M,N = num_steps, num_envs\n",
    "\n",
    "    obs = torch.zeros((M, N) + envs.single_observation_space.shape).to(device)\n",
    "    actions = torch.zeros((M,N) + envs.single_action_space.shape).to(device)\n",
    "    log_probs = torch.zeros((M,N)).to(device)\n",
    "    rewards = torch.zeros((M,N)).to(device)\n",
    "    dones = torch.zeros((M,N)).to(device) # for masking\n",
    "    values = torch.zeros((M,N)).to(device)\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    #Reset env\n",
    "    next_obs, _ = envs.reset()\n",
    "    next_obs = torch.tensor(next_obs).float().to(device)\n",
    "    next_done = torch.zeros(N).to(device) #N is num envs\n",
    "\n",
    "    print('next obs = ', next_obs.shape)\n",
    "    print('next done = ', next_done.shape)\n",
    "\n",
    "    reward_window = deque(maxlen = 100)\n",
    "\n",
    "    if history == None:\n",
    "        history = defaultdict(list)\n",
    "\n",
    "    loop = tqdm(range(num_iterations))\n",
    "    agent.train()\n",
    "\n",
    "    best_score = -float('inf')\n",
    "    loss = float('inf')\n",
    "\n",
    "    for iter in loop:\n",
    "\n",
    "        #ROLLOUT phase\n",
    "        #M is max steps\n",
    "        if iter % plot_udpate_freq == 0:\n",
    "            plot(history, save_path=FIG_SAVE_PATH)\n",
    "\n",
    "        for step in range(M):\n",
    "            global_step += N\n",
    "\n",
    "            obs[step] = next_obs\n",
    "            dones[step] = next_done\n",
    "\n",
    "            #get action\n",
    "            #NOTE: no_grad disables gradient calculation --> reduce memory consumption\n",
    "            #the result of every computation will have requires_grad=False\n",
    "            with torch.no_grad():\n",
    "                action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "                values[step] = value.flatten()\n",
    "\n",
    "            actions[step] = action\n",
    "            log_probs[step] = log_prob\n",
    "\n",
    "            #make next step with actions\n",
    "            next_obs, reward, terminated, truncated, info = envs.step(action.cpu().numpy())\n",
    "\n",
    "            next_done = np.logical_or(terminated, truncated)\n",
    "\n",
    "            #NOTE: difference between view and reshape\n",
    "            # https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch\n",
    "            rewards[step] = torch.tensor(reward).view(-1)\n",
    "            next_obs = torch.tensor(next_obs).float().to(device)\n",
    "            next_done = torch.tensor(next_done).float().to(device)\n",
    "\n",
    "            #NOTE: vector envs will automatically reset, so no need to break \n",
    "            if 'final_info' in info:\n",
    "                for data in info['final_info']:\n",
    "                    if data:\n",
    "                        reward = data['episode']['r']\n",
    "                        reward_window.append(reward)\n",
    "                        avg_reward = np.mean(reward_window)\n",
    "                        history['reward'].append(avg_reward)\n",
    "                        loop.set_description(f\"reward = {avg_reward:.2f}, global_step = {global_step}, best_score = {best_score:.2f}, loss={loss:.2f}\")\n",
    "\n",
    "                        if best_score < avg_reward:\n",
    "                            best_score = avg_reward\n",
    "                            #save model\n",
    "                            torch.save(agent, os.path.join(SAVE_PATH, 'ppo.checkpoint.torch'))\n",
    "            \n",
    "        #update the history for plotting, and printing progress\n",
    "\n",
    "        #OPTIMIZE phase:\n",
    "        with torch.no_grad():\n",
    "            #bootstrap values, compute returns\n",
    "            next_value = agent.get_value(next_obs).reshape(1,-1)\n",
    "            advantages = torch.zeros_like(rewards).to(device)\n",
    "            last_gae_lambda = 0\n",
    "\n",
    "            for t in reversed(range(NUM_STEPS)):\n",
    "                if t == NUM_STEPS - 1:\n",
    "                    next_none_terminal = np.logical_not(next_done.cpu())\n",
    "                    next_values = next_value\n",
    "                else:\n",
    "                    next_none_terminal = np.logical_not(dones[t + 1].cpu())\n",
    "                    next_values = values[t + 1]\n",
    "\n",
    "                next_none_terminal = next_none_terminal.to(device)\n",
    "                \n",
    "                #A(s,a) = Q(s,a) - V(s,a) = r(t) + gamma * V(s', a) * mask - V(s)\n",
    "                delta = rewards[t] + GAMMA * next_values * next_none_terminal - values[t]\n",
    "                #NOTE: learn about this formula\n",
    "                advantages[t] = last_gae_lambda = delta + GAMMA * GAE_LAMBDA * next_none_terminal * last_gae_lambda\n",
    "            returns = advantages + values\n",
    "        \n",
    "        #flatten the batch\n",
    "        b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
    "        b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
    "        b_log_probs = log_probs.reshape(-1)\n",
    "        b_advantages = advantages.reshape(-1)\n",
    "        b_returns = returns.reshape(-1)\n",
    "        b_values = values.reshape(-1)\n",
    "\n",
    "        #NOTE: randomize the batch to break correlation\n",
    "        batch_size = M * N\n",
    "        mini_batch_size = batch_size // MINI_BATCH_COUNT\n",
    "        b_indicies = np.arange(batch_size)\n",
    "        clip_fracs = []\n",
    "        \n",
    "        for _ in range(update_epochs):\n",
    "            np.random.shuffle(b_indicies)\n",
    "\n",
    "            #NOTE: mini-batch update: \n",
    "            # pros: reduce memory usage, faster updates\n",
    "            # pros: a whole batch may stuck in local minima, mini batches introduce randomness\n",
    "            # cons: estimate a true gradient, larger mini batch size --> more accurate but more memory\n",
    "            for start in range(0, batch_size, mini_batch_size):\n",
    "                end = start + mini_batch_size\n",
    "                mini_indicies = b_indicies[start:end]\n",
    "\n",
    "                _, new_log_prob, entropy, new_value = agent.get_action_and_value(b_obs[mini_indicies], b_actions[mini_indicies])\n",
    "\n",
    "                #NOTE: what formula is this? \n",
    "                log_ratio = new_log_prob - b_log_probs[mini_indicies]\n",
    "\n",
    "                ratio = log_ratio.exp() # trick to remove log\n",
    "\n",
    "                #compute approximate KL: http://joschu.net/blog/kl-approx.html\n",
    "                with torch.no_grad():\n",
    "                    old_approx_kd = (-log_ratio).mean()\n",
    "                    approximate_kl = ((ratio - 1) - log_ratio).mean()\n",
    "                    clip_fracs += [((ratio - 1.0).abs() > CLIP_COEF).float().mean().item()]\n",
    "\n",
    "                mb_advantages = b_advantages[mini_indicies]\n",
    "\n",
    "                #normalize advantage\n",
    "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "                #policy loss (actor)\n",
    "\n",
    "                pg_loss1 = -mb_advantages * ratio\n",
    "                pg_loss2= -mb_advantages * torch.clamp(ratio, 1 - CLIP_COEF, 1 + CLIP_COEF)\n",
    "\n",
    "                pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "                new_value = new_value.view(-1)\n",
    "\n",
    "                #value loss (MSE)\n",
    "                v_loss = 0.5 * ((new_value - b_returns[mini_indicies]) ** 2).mean()\n",
    "\n",
    "                entropy_loss = entropy.mean()\n",
    "\n",
    "                loss = pg_loss - ENTROPY_COEF * entropy_loss + v_loss * VF_COEF\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                #clip grad\n",
    "                nn.utils.clip_grad_norm_(agent.parameters(), MAX_GRAD_NORM)\n",
    "                optimizer.step()\n",
    "        \n",
    "    torch.save(agent, os.path.join(SAVE_PATH, 'ppo.final.torch'))\n",
    "    plot(history, show=True, save_path=FIG_SAVE_PATH)\n",
    "\n",
    "    with open(os.path.join(SAVE_PATH, 'history.pickle'), 'wb') as file:\n",
    "        pickle.dump(history, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id =  baseline\n",
      "output folder: e:\\ML\\NLP\\Reinforcement Learning\\policy_gradient\\final_project\\ppo\\output\\BreakoutNoFrameskip-v4\\baseline\n",
      "save path =  e:\\ML\\NLP\\Reinforcement Learning\\policy_gradient\\final_project\\ppo\\output\\BreakoutNoFrameskip-v4\\baseline\n",
      "next obs =  torch.Size([6, 4, 84, 84])\n",
      "next done =  torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward = 1.46, global_step = 48990, best_score = 1.73, loss=0.01:   0%|          | 3/1000 [01:55<8:46:56, 31.71s/it] "
     ]
    }
   ],
   "source": [
    "# Create env\n",
    "envs = gym.vector.AsyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "#check to make sure this is continous action\n",
    "# assert isinstance(envs.single_action_space, gym.spaces.Box), 'Only continous action is supported'\n",
    "\n",
    "agent = Agent(envs)\n",
    "optimizer = torch.optim.Adam(agent.parameters(), lr = 1e-4, eps = 1e-5)\n",
    "\n",
    "M = NUM_STEPS\n",
    "N = NUM_ENVS\n",
    "\n",
    "tune(envs, agent, optimizer, NUM_STEPS, NUM_ENVS, device=  DEVICE, num_iterations=1000, label = 'baseline', update_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(agent, device = DEVICE, episodes = 10):\n",
    "    envs = gym.vector.SyncVectorEnv([lambda: make_env(**ENV_ARGS)])\n",
    "    agent.eval()\n",
    "    total_rewards = []\n",
    "    next_obs, _ = envs.reset()\n",
    "\n",
    "    while len(total_rewards) < episodes: \n",
    "        next_obs = torch.Tensor(next_obs).to(device)\n",
    "        with torch.no_grad():\n",
    "            action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "\n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.cpu().numpy())\n",
    "\n",
    "        if 'final_info' in info:\n",
    "            for data in info['final_info']:\n",
    "                if data:\n",
    "                    reward = data['episode']['r'][0]\n",
    "                    print('reward = ', reward)\n",
    "                    total_rewards.append(reward)\n",
    "    \n",
    "    sns.lineplot(y = total_rewards, x = list(range(len(total_rewards))))\n",
    "    return total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward =  41.0\n",
      "reward =  80.0\n",
      "reward =  24.0\n",
      "reward =  33.0\n",
      "reward =  45.0\n",
      "reward =  47.0\n",
      "reward =  54.0\n",
      "reward =  260.0\n",
      "reward =  31.0\n",
      "reward =  28.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = evaluate(agent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://spinningup.openai.com/en/latest/algorithms/sac.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import deque, Counter, namedtuple, defaultdict\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import math\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_ARGS = {\n",
    "    'id': \"Ant-v4\"\n",
    "}\n",
    "NUM_ENVS = 3\n",
    "SEED = 1\n",
    "\n",
    "LR = 1e-4\n",
    "NUM_STEPS = 2048\n",
    "NUM_ITERATIONS = 1000\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "UPDATE_EPOCHS = 10\n",
    "CLIP_COEF = 0.2 # the epsilon in KL divergece in PPO paper\n",
    "ENTROPY_COEF = 0.0\n",
    "VF_COEF = 0.5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "MINI_BATCH_COUNT = 32\n",
    "UPDATE_PLOTS = 10\n",
    "\n",
    "LOG_STD_MAX = 2\n",
    "LOG_STD_MIN = -5\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#output directory\n",
    "ROOT = os.getcwd()\n",
    "OUTPUT = os.path.join(ROOT, 'output', ENV_ARGS['id'])\n",
    "\n",
    "if os.path.exists(OUTPUT) == False:\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "#seeding\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(gamma, **env_args):\n",
    "    env = gym.make(**env_args)\n",
    "    # env = gym.wrappers.FlattenObservation(env)\n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    # env = gym.wrappers.ClipAction(env)\n",
    "    # env = gym.wrappers.NormalizeObservation(env)\n",
    "    # env = gym.wrappers.TransformObservation(env, lambda obs: np.clip(obs, -10, 10))\n",
    "    # env = gym.wrappers.NormalizeReward(env, gamma = gamma)\n",
    "    # env = gym.wrappers.TransformReward(env, lambda reward: np.clip(reward, -10, 10))\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(gamma= 0.99, **ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "#check to make sure this is continous action\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Box), 'Only continous action is supported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer: nn.Linear, std = np.sqrt(2), bias_const = 0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self,envs: gym.Env, hidden_size = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_shape = np.prod(envs.single_observation_space.shape)\n",
    "        self.action_shape = np.prod(envs.single_action_space.shape)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Linear(self.state_shape + self.action_shape, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(hidden_size, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(hidden_size, 1)),\n",
    "        )\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat((state, action), dim = 1)\n",
    "        return self.network(x)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, envs: gym.Env, hidden_size = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_shape = np.prod(envs.single_observation_space.shape)\n",
    "        self.action_shape = np.prod(envs.single_action_space.shape)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Linear(self.state_shape, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(hidden_size, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc_mean = nn.Linear(hidden_size, self.action_shape)\n",
    "        self.fc_logstd = nn.Linear(hidden_size, self.action_shape)\n",
    "\n",
    "        #NOTE: register buffer so that optimizer will not update its values\n",
    "        self.register_buffer(\n",
    "            \"action_scale\", torch.tensor((envs.single_action_space.high - envs.single_action_space.low)/2.0, dtype=torch.float32)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\", torch.tensor((envs.single_action_space.high + envs.single_action_space.low)/2.0, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.network(X)\n",
    "        mean = self.fc_mean(X)\n",
    "        logstd = torch.tanh(self.fc_logstd(X))\n",
    "        # https://spinningup.openai.com/en/latest/algorithms/sac.html\n",
    "        logstd = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (logstd + 1)\n",
    "\n",
    "        return mean, logstd\n",
    "    \n",
    "    def get_action(self, X):\n",
    "\n",
    "        mean, logstd = self(X)\n",
    "        #exponential to convert from log(std) to std\n",
    "        std = logstd.exp()\n",
    "\n",
    "        normal = torch.distributions.Normal(mean, std)\n",
    "        #reparameterize trick \n",
    "        # https://stackoverflow.com/questions/60533150/what-is-the-difference-between-sample-and-rsample\n",
    "        x_t = normal.rsample()\n",
    "        y_t = torch.tanh(x_t)\n",
    "\n",
    "        #action scale and bias is registered as buffer in init()\n",
    "        # print('y t shape = ', y_t.shape)\n",
    "        # print('scale shape = ', self.action_scale.shape)\n",
    "        # print('bias shape = ', self.action_bias.shape)\n",
    "\n",
    "        action = y_t * self.action_scale + self.action_bias\n",
    "\n",
    "        logprob = normal.log_prob(x_t)\n",
    "\n",
    "        logprob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + 1e-6)\n",
    "        logprob = logprob.sum(1, keepdim = True)\n",
    "\n",
    "        mean = torch.tanh(mean) * self.action_scale + self.action_bias\n",
    "\n",
    "        return action, logprob, mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape =  torch.Size([3, 27])\n",
      "action shape =  torch.Size([3, 8])\n",
      "q value =  torch.Size([3, 1])\n",
      "actor action =  torch.Size([3, 8])\n",
      "logprob  =  torch.Size([3, 1])\n",
      "mean  =  torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "#Test agent\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(gamma= 0.99, **ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "obs, info = envs.reset()\n",
    "\n",
    "actor = Actor(envs)\n",
    "qnet = QNetwork(envs)\n",
    "\n",
    "obs = torch.tensor(obs).float()\n",
    "action = torch.tensor(envs.action_space.sample()).float()\n",
    "print('state shape = ', obs.shape)\n",
    "print('action shape = ', action.shape)\n",
    "\n",
    "qvalue = qnet(obs, action)\n",
    "print('q value = ', qvalue.shape)\n",
    "\n",
    "actor_action, logprob, mean = actor.get_action(obs)\n",
    "print('actor action = ', actor_action.shape)\n",
    "print('logprob  = ', logprob.shape)\n",
    "print('mean  = ', mean.shape)\n",
    "\n",
    "\n",
    "# action, log_prob, entropy, value = test_agent.get_action_and_value(obs)\n",
    "\n",
    "# print('log prob shape = ', log_prob.shape)\n",
    "# print('entropy shape = ', entropy.shape)\n",
    "# print('value shape = ', value.shape)\n",
    "\n",
    "# del test_agent\n",
    "\n",
    "envs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, show = False, save_path = None):\n",
    "    sns.lineplot(y = history['reward'], x = list(range(len(history['reward']))))\n",
    "\n",
    "    if save_path != None:\n",
    "        plt.savefig(save_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def replay_buffer_usage(rb: ReplayBuffer):\n",
    "    return (rb.pos / rb.buffer_size) * 100 if rb.full == False else 100\n",
    "\n",
    "def pickle_dump(obj, path):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    \n",
    "def pickle_load(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        obj = pickle.dump(file)\n",
    "    return obj\n",
    "\n",
    "def evaluate(agent, episodes = 10, render_human = False, device = DEVICE):\n",
    "    if render_human:\n",
    "        ENV_ARGS['render_mode'] = 'human'\n",
    "    envs = gym.vector.SyncVectorEnv([lambda: make_env(gamma = GAMMA, **ENV_ARGS)])\n",
    "    agent.eval()\n",
    "    total_rewards = []\n",
    "    obs, _ = envs.reset()\n",
    "\n",
    "    while len(total_rewards) < episodes: \n",
    "        obs = torch.Tensor(obs)\n",
    "        with torch.no_grad():\n",
    "            actions, _,_ = agent.get_action(torch.tensor(obs).to(device).float())\n",
    "            actions = actions.detach().cpu().numpy()\n",
    "\n",
    "        obs, reward, terminated, truncated, infos = envs.step(actions)\n",
    "\n",
    "        if 'final_info' in infos:\n",
    "            for info in infos['final_info']:\n",
    "                if info and 'episode' in info:\n",
    "                    ep_return = info['episode']['r']\n",
    "                    total_rewards.append(ep_return.item())\n",
    "\n",
    "\n",
    "    if render_human:\n",
    "        del ENV_ARGS['render_mode']\n",
    "\n",
    "    return total_rewards\n",
    "\n",
    "\n",
    "def soft_update(net:nn.Module, other: nn.Module, tau = 0.005):\n",
    "    for this_param, other_param in zip(net.parameters(), other.parameters()):\n",
    "        this_param.data.copy_(tau * other_param.data + (1 - tau) * this_param.data)\n",
    "    \n",
    "def weight_update(net:nn.Module, other: nn.Module, tau = 0.005):\n",
    "    net.load_state_dict(other.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(\n",
    "    envs: gym.Env, actor:Actor, qf1:QNetwork, qf2:QNetwork, \n",
    "    qf1_target:QNetwork, qf2_target:QNetwork,\n",
    "    q_optimizer, actor_optimizer, device,\n",
    "    buffer_size = int(1e6), batch_size = 32,\n",
    "    total_timesteps = 1000, warmup_steps = 50,\n",
    "    policy_update_freq = 2, target_net_update_freq = 1, gamma = 0.99, \n",
    "    plot_update_freq = 10, label = 'test', plot_udpate_freq = 10, history = None):\n",
    "\n",
    "    SAVE_PATH = os.path.join(OUTPUT, label)\n",
    "    FIG_SAVE_PATH = os.path.join(SAVE_PATH, 'plot.png')\n",
    "    HISTORY_PATH = os.path.join(SAVE_PATH, 'history.pickle')\n",
    "\n",
    "    if os.path.exists(SAVE_PATH) == False:\n",
    "        os.makedirs(SAVE_PATH)\n",
    "\n",
    "    print('save path = ', SAVE_PATH)\n",
    "\n",
    "    state_size = np.prod(envs.single_observation_space.shape)\n",
    "    action_size = np.prod(envs.single_action_space.shape)\n",
    "    n_envs = envs.observation_space.shape[0]\n",
    "\n",
    "    #default to float\n",
    "    envs.single_observation_space.dtype = np.float32\n",
    "\n",
    "    alpha = 0.2 # expected return and entropy trade-off coefficient \n",
    "\n",
    "    # target_entropy = -torch.prod(torch.Tensor(envs.single_action_space.shape).to(device)).item()\n",
    "    # log_alpha = torch.zeros(1, requires_grad = True, device= device)\n",
    "    # alpha = log_alpha.exp().item()\n",
    "    # a_optimizer = torch.optim.Adam([log_alpha], lr = 1e-3)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(\n",
    "            buffer_size,\n",
    "            envs.single_observation_space, \n",
    "            envs.single_action_space, \n",
    "            device = device,\n",
    "            handle_timeout_termination=False,\n",
    "            optimize_memory_usage=True,\n",
    "            n_envs=n_envs\n",
    "    )\n",
    "\n",
    "    obs, _ = envs.reset()\n",
    "    avg_reward = 0\n",
    "    avg_reward = 0\n",
    "    best_score = -float('inf')\n",
    "    score_window = deque(maxlen = 100)\n",
    "    if history == None:\n",
    "        history = defaultdict(list)\n",
    "\n",
    "    loop = tqdm(range(total_timesteps))\n",
    "    episode_count = 0\n",
    "    updated_t = 0\n",
    "\n",
    "    #start training loop\n",
    "    for global_step in loop:\n",
    "        t = int(loop.format_dict['elapsed'])\n",
    "\n",
    "        #if still warming up, get random action\n",
    "        if global_step < warmup_steps:\n",
    "            actions = envs.action_space.sample()\n",
    "        \n",
    "        #else done warmup, get actions from actor\n",
    "        else:\n",
    "            actions, _,_ = actor.get_action(torch.tensor(obs).to(device).float())\n",
    "            actions = actions.detach().cpu().numpy()\n",
    "        \n",
    "        next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
    "\n",
    "        if 'final_info' in infos:\n",
    "            for info in infos['final_info']:\n",
    "                if info and 'episode' in info:\n",
    "                    test = True\n",
    "                    ep_return = info['episode']['r']\n",
    "                    score_window.append(ep_return)\n",
    "                    episode_count += 1\n",
    "\n",
    "                    avg_reward = np.mean(score_window)\n",
    "                    history['reward'].append(avg_reward)\n",
    "                    history['buffer_usage'].append(replay_buffer_usage(replay_buffer))\n",
    "\n",
    "                    #save model with new best score \n",
    "                    if avg_reward > best_score:\n",
    "                        best_score = avg_reward\n",
    "                        torch.save(actor, os.path.join(SAVE_PATH, 'actor.checkpoint.torch'))\n",
    "                        torch.save(qf1, os.path.join(SAVE_PATH, 'qf1.checkpoint.torch'))\n",
    "                        torch.save(qf2, os.path.join(SAVE_PATH, 'qf2.checkpoint.torch'))\n",
    "                        torch.save(qf1_target, os.path.join(SAVE_PATH, 'qf1_target.checkpoint.torch'))\n",
    "                        torch.save(qf2_target, os.path.join(SAVE_PATH, 'qf2_target.checkpoint.torch'))\n",
    "\n",
    "        real_next_obs = next_obs.copy()\n",
    "        for i, truncated in enumerate(truncations):\n",
    "            if truncated:\n",
    "                real_next_obs[i] = infos['final_observation'][i]\n",
    "        \n",
    "        replay_buffer.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "        #optimize when done warming up \n",
    "        if global_step > warmup_steps:\n",
    "\n",
    "            data = replay_buffer.sample(batch_size)\n",
    "            b_next_obs = data.next_observations.to()\n",
    "            b_obs = data.observations\n",
    "            b_actions = data.actions\n",
    "            b_rewards = data.rewards\n",
    "            b_dones = data.dones\n",
    "\n",
    "            with torch.no_grad():\n",
    "                next_state_actions, next_state_log_probs, _ = actor.get_action(b_next_obs)\n",
    "                qf1_next_target = qf1_target(b_next_obs, next_state_actions)\n",
    "                qf2_next_target = qf2_target(b_next_obs, next_state_actions)\n",
    "                min_qf_next_target = torch.min(qf1_next_target, qf2_next_target) - alpha * next_state_log_probs\n",
    "                next_q_value = b_rewards.flatten() + (1 - b_dones.flatten()) * gamma * min_qf_next_target.view(-1)\n",
    "            \n",
    "            qf1_a_values = qf1(b_obs, b_actions).view(-1)\n",
    "            qf2_a_values = qf2(b_obs, b_actions).view(-1)\n",
    "\n",
    "            qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "            qf2_loss = F.mse_loss(qf2_a_values, next_q_value)\n",
    "\n",
    "            qf_loss = qf1_loss + qf2_loss\n",
    "\n",
    "            #step q_optimizer\n",
    "            q_optimizer.zero_grad()\n",
    "            qf_loss.backward()\n",
    "            q_optimizer.step()\n",
    "\n",
    "            #TD3 update delayed\n",
    "            if global_step % policy_update_freq == 0:\n",
    "                for _ in range(policy_update_freq):\n",
    "\n",
    "                    pi, log_pi, _ = actor.get_action(b_obs)\n",
    "\n",
    "                    qf1_pi = qf1(b_obs, pi)\n",
    "                    qf2_pi = qf2(b_obs, pi)\n",
    "\n",
    "                    min_qf_pi = torch.min(qf1_pi, qf2_pi)\n",
    "\n",
    "                    actor_loss = ((alpha * log_pi) - min_qf_pi).mean()\n",
    "\n",
    "                    actor_optimizer.zero_grad()\n",
    "                    actor_loss.backward()\n",
    "                    actor_optimizer.step()\n",
    "\n",
    "            if global_step % target_net_update_freq == 0:\n",
    "                soft_update(qf1_target, qf1)\n",
    "                soft_update(qf2_target, qf2)\n",
    "        \n",
    "        if t != updated_t and t % plot_update_freq == 0: \n",
    "            updated_t = t\n",
    "            loop.set_description(f\"avg_reward = {avg_reward:.2f}, best_score = {best_score}, episode_count = {episode_count}, buffer usage = {replay_buffer_usage(replay_buffer):.2f}\")\n",
    "            plot(history, save_path = FIG_SAVE_PATH)\n",
    "            pickle_dump(history, HISTORY_PATH)\n",
    "\n",
    "    plot(history, show = True, save_path = FIG_SAVE_PATH)\n",
    "    envs.reset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save path =  /Volumes/SanDisk/NLP_RNN/Reinforcement Learning/deep rl/final_project/sac/output/Ant-v4/exp1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg_reward = 17.50, best_score = 17.50325584411621, episode_count = 104, buffer usage = 9.91:  17%|█▋        | 16846/100000 [02:23<11:48, 117.33it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m actor_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(actor\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m actor_lr) \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#NOTE: use fixec entropy method mentioned in Spin-up, improve this later with enforce method\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# https://spinningup.openai.com/en/latest/algorithms/sac.html\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqf1_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqf2_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43mq_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexp1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m envs\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[8], line 144\u001b[0m, in \u001b[0;36mtune\u001b[0;34m(envs, actor, qf1, qf2, qf1_target, qf2_target, q_optimizer, actor_optimizer, device, buffer_size, batch_size, total_timesteps, warmup_steps, policy_update_freq, target_net_update_freq, gamma, plot_update_freq, label, plot_udpate_freq, history)\u001b[0m\n\u001b[1;32m    141\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m ((alpha \u001b[38;5;241m*\u001b[39m log_pi) \u001b[38;5;241m-\u001b[39m min_qf_pi)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    143\u001b[0m actor_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 144\u001b[0m \u001b[43mactor_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m actor_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#     _, log_pi,_ = actor.get_action(b_obs)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# alpha = log_alpha.exp().item()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device= DEVICE\n",
    "q_lr = 1e-3\n",
    "actor_lr = 1e-3\n",
    "total_timesteps = int(1e5)\n",
    "warmup_steps = int(1e3)\n",
    "buffer_size = int(5e5)\n",
    "batch_size = 256\n",
    "fc_hidden_size = 256\n",
    "\n",
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(gamma= 0.99, **ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "assert isinstance(envs.single_action_space, gym.spaces.Box), 'Only continous action is supported'\n",
    "\n",
    "actor = Actor(envs, hidden_size=fc_hidden_size).to(device)\n",
    "qf1 = QNetwork(envs).to(device)\n",
    "qf2 = QNetwork(envs).to(device)\n",
    "qf1_target = QNetwork(envs).to(device)\n",
    "qf2_target = QNetwork(envs).to(device)\n",
    "qf1_target.load_state_dict(qf1.state_dict())\n",
    "qf2_target.load_state_dict(qf2.state_dict())\n",
    "\n",
    "q_optimizer = torch.optim.Adam(list(qf1.parameters()) + list(qf2.parameters()), lr = q_lr) \n",
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr = actor_lr) \n",
    "#NOTE: use fixec entropy method mentioned in Spin-up, improve this later with enforce method\n",
    "# https://spinningup.openai.com/en/latest/algorithms/sac.html\n",
    "\n",
    "\n",
    "tune(envs, actor, qf1, qf2, qf1_target, qf2_target, \n",
    "q_optimizer, actor_optimizer, device = device,\n",
    "total_timesteps= total_timesteps, warmup_steps=warmup_steps,\n",
    "buffer_size=buffer_size, batch_size=batch_size, label = 'exp1'\n",
    ")\n",
    "\n",
    "envs.close()\n",
    "# #check to make sure this is continous action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/SanDisk/NLP_RNN/Reinforcement Learning/deep rl/final_project/sac/output/Ant-v4/good/actor.checkpoint.torch\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOAD_PATH = os.path.join(OUTPUT, 'good', 'actor.checkpoint.torch')\n",
    "print(LOAD_PATH)\n",
    "eval_actor = torch.load(LOAD_PATH)\n",
    "\n",
    "total_rewards = evaluate(eval_actor, episodes=10)\n",
    "sns.lineplot(y = total_rewards, x = list(range(len(total_rewards))))\n",
    "EVALUATION_PLOT_SAVE = os.path.join(OUTPUT, 'good', 'evaluation.png') \n",
    "plt.savefig(EVALUATION_PLOT_SAVE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pressed ESC\n",
      "Quitting.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_actor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_human\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(agent, episodes, render_human, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m     actions, _,_ \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mget_action(torch\u001b[38;5;241m.\u001b[39mtensor(obs)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     36\u001b[0m     actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 38\u001b[0m obs, reward, terminated, truncated, infos \u001b[38;5;241m=\u001b[39m \u001b[43menvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_info\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m infos:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m infos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_info\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/vector/vector_env.py:203\u001b[0m, in \u001b[0;36mVectorEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take an action for each parallel environment.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m    {}\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/vector/sync_vector_env.py:149\u001b[0m, in \u001b[0;36mSyncVectorEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m observations, infos \u001b[39m=\u001b[39m [], {}\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m i, (env, action) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menvs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actions)):\n\u001b[1;32m    143\u001b[0m     (\n\u001b[1;32m    144\u001b[0m         observation,\n\u001b[1;32m    145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rewards[i],\n\u001b[1;32m    146\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_terminateds[i],\n\u001b[1;32m    147\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncateds[i],\n\u001b[1;32m    148\u001b[0m         info,\n\u001b[0;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_terminateds[i] \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncateds[i]:\n\u001b[1;32m    152\u001b[0m         old_observation, old_info \u001b[39m=\u001b[39m observation, info\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/wrappers/record_episode_statistics.py:89\u001b[0m, in \u001b[0;36mRecordEpisodeStatistics.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     82\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment, recording the episode statistics.\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     (\n\u001b[1;32m     84\u001b[0m         observations,\n\u001b[1;32m     85\u001b[0m         rewards,\n\u001b[1;32m     86\u001b[0m         terminations,\n\u001b[1;32m     87\u001b[0m         truncations,\n\u001b[1;32m     88\u001b[0m         infos,\n\u001b[0;32m---> 89\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     90\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m     91\u001b[0m         infos, \u001b[39mdict\u001b[39m\n\u001b[1;32m     92\u001b[0m     ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`info` dtype is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(infos)\u001b[39m}\u001b[39;00m\u001b[39m while supported dtype is `dict`. This may be due to usage of other wrappers in the wrong order.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepisode_returns \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m rewards\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/envs/mujoco/ant_v4.py:349\u001b[0m, in \u001b[0;36mAntEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    346\u001b[0m reward \u001b[39m=\u001b[39m rewards \u001b[39m-\u001b[39m costs\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    350\u001b[0m \u001b[39mreturn\u001b[39;00m observation, reward, terminated, \u001b[39mFalse\u001b[39;00m, info\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/envs/mujoco/mujoco_env.py:379\u001b[0m, in \u001b[0;36mMujocoEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmujoco_renderer\u001b[39m.\u001b[39;49mrender(\n\u001b[1;32m    380\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender_mode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcamera_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcamera_name\n\u001b[1;32m    381\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:673\u001b[0m, in \u001b[0;36mMujocoRenderer.render\u001b[0;34m(self, render_mode, camera_id, camera_name)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n\u001b[1;32m    672\u001b[0m \u001b[39melif\u001b[39;00m render_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 673\u001b[0m     \u001b[39mreturn\u001b[39;00m viewer\u001b[39m.\u001b[39;49mrender()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:402\u001b[0m, in \u001b[0;36mWindowViewer.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paused:\n\u001b[1;32m    401\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_paused:\n\u001b[0;32m--> 402\u001b[0m         update()\n\u001b[1;32m    403\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_advance_by_one_step:\n\u001b[1;32m    404\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_advance_by_one_step \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:353\u001b[0m, in \u001b[0;36mWindowViewer.render.<locals>.update\u001b[0;34m()\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m():\n\u001b[1;32m    352\u001b[0m     \u001b[39m# fill overlay items\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_overlay()\n\u001b[1;32m    355\u001b[0m     render_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:580\u001b[0m, in \u001b[0;36mWindowViewer._create_overlay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_overlay(topleft, \u001b[39m\"\u001b[39m\u001b[39mStart\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m[Space]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    577\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_overlay(\n\u001b[1;32m    578\u001b[0m             topleft, \u001b[39m\"\u001b[39m\u001b[39mAdvance simulation by one step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m[right arrow]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_overlay(\n\u001b[1;32m    581\u001b[0m     topleft, \u001b[39m\"\u001b[39;49m\u001b[39mReferenc[e] frames\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mOn\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvopt\u001b[39m.\u001b[39;49mframe \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mOff\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    582\u001b[0m )\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_overlay(topleft, \u001b[39m\"\u001b[39m\u001b[39m[H]ide Menu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_idx \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:75\u001b[0m, in \u001b[0;36mBaseRender.add_overlay\u001b[0;34m(self, gridpos, text1, text2)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m gridpos \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_overlays:\n\u001b[1;32m     74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_overlays[gridpos] \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_overlays[gridpos][\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m text1 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_overlays[gridpos][\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m text2 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(eval_actor, episodes=1, render_human=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

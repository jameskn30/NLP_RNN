{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://spinningup.openai.com/en/latest/algorithms/sac.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import deque, Counter, namedtuple, defaultdict\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import math\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_ARGS = {\n",
    "    'id': \"HalfCheetah-v4\"\n",
    "}\n",
    "NUM_ENVS = 3\n",
    "SEED = 1\n",
    "\n",
    "LR = 1e-4\n",
    "NUM_STEPS = 2048\n",
    "NUM_ITERATIONS = 1000\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "UPDATE_EPOCHS = 10\n",
    "CLIP_COEF = 0.2 # the epsilon in KL divergece in PPO paper\n",
    "ENTROPY_COEF = 0.0\n",
    "VF_COEF = 0.5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "MINI_BATCH_COUNT = 32\n",
    "UPDATE_PLOTS = 10\n",
    "\n",
    "LOG_STD_MAX = 2\n",
    "LOG_STD_MIN = -5\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#output directory\n",
    "ROOT = os.getcwd()\n",
    "OUTPUT = os.path.join(ROOT, 'output', ENV_ARGS['id'])\n",
    "\n",
    "if os.path.exists(OUTPUT) == False:\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "#seeding\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(gamma, **env_args):\n",
    "    env = gym.make(**env_args)\n",
    "    # env = gym.wrappers.FlattenObservation(env)\n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    # env = gym.wrappers.ClipAction(env)\n",
    "    # env = gym.wrappers.NormalizeObservation(env)\n",
    "    # env = gym.wrappers.TransformObservation(env, lambda obs: np.clip(obs, -10, 10))\n",
    "    # env = gym.wrappers.NormalizeReward(env, gamma = gamma)\n",
    "    # env = gym.wrappers.TransformReward(env, lambda reward: np.clip(reward, -10, 10))\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(gamma= 0.99, **ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "#check to make sure this is continous action\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Box), 'Only continous action is supported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer: nn.Linear, std = np.sqrt(2), bias_const = 0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self,envs: gym.Env, hidden_size = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_shape = np.prod(envs.single_observation_space.shape)\n",
    "        self.action_shape = np.prod(envs.single_action_space.shape)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Linear(self.state_shape + self.action_shape, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(hidden_size, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(hidden_size, 1)),\n",
    "        )\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat((state, action), dim = 1)\n",
    "        return self.network(x)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, envs: gym.Env, hidden_size = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_shape = np.prod(envs.single_observation_space.shape)\n",
    "        self.action_shape = np.prod(envs.single_action_space.shape)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Linear(self.state_shape, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(hidden_size, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc_mean = nn.Linear(hidden_size, self.action_shape)\n",
    "        self.fc_logstd = nn.Linear(hidden_size, self.action_shape)\n",
    "\n",
    "        #NOTE: register buffer so that optimizer will not update its values\n",
    "        self.register_buffer(\n",
    "            \"action_scale\", torch.tensor((envs.single_action_space.high - envs.single_action_space.low)/2.0, dtype=torch.float32)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\", torch.tensor((envs.single_action_space.high + envs.single_action_space.low)/2.0, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.network(X)\n",
    "        mean = self.fc_mean(X)\n",
    "        logstd = torch.tanh(self.fc_logstd(X))\n",
    "        # https://spinningup.openai.com/en/latest/algorithms/sac.html\n",
    "        logstd = LOG_STD_MIN + 0.5 * (LOG_STD_MAX - LOG_STD_MIN) * (logstd + 1)\n",
    "\n",
    "        return mean, logstd\n",
    "    \n",
    "    def get_action(self, X):\n",
    "\n",
    "        mean, logstd = self(X)\n",
    "        #exponential to convert from log(std) to std\n",
    "        std = logstd.exp()\n",
    "\n",
    "        normal = torch.distributions.Normal(mean, std)\n",
    "        #reparameterize trick \n",
    "        # https://stackoverflow.com/questions/60533150/what-is-the-difference-between-sample-and-rsample\n",
    "        x_t = normal.rsample()\n",
    "        y_t = torch.tanh(x_t)\n",
    "\n",
    "        #action scale and bias is registered as buffer in init()\n",
    "        # print('y t shape = ', y_t.shape)\n",
    "        # print('scale shape = ', self.action_scale.shape)\n",
    "        # print('bias shape = ', self.action_bias.shape)\n",
    "\n",
    "        action = y_t * self.action_scale + self.action_bias\n",
    "\n",
    "        logprob = normal.log_prob(x_t)\n",
    "\n",
    "        logprob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + 1e-6)\n",
    "        logprob = logprob.sum(1, keepdim = True)\n",
    "\n",
    "        mean = torch.tanh(mean) * self.action_scale + self.action_bias\n",
    "\n",
    "        return action, logprob, mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape =  torch.Size([3, 17])\n",
      "action shape =  torch.Size([3, 6])\n",
      "q value =  torch.Size([3, 1])\n",
      "actor action =  torch.Size([3, 6])\n",
      "logprob  =  torch.Size([3, 1])\n",
      "mean  =  torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "#Test agent\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(gamma= 0.99, **ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "obs, info = envs.reset()\n",
    "\n",
    "actor = Actor(envs)\n",
    "qnet = QNetwork(envs)\n",
    "\n",
    "obs = torch.tensor(obs).float()\n",
    "action = torch.tensor(envs.action_space.sample()).float()\n",
    "print('state shape = ', obs.shape)\n",
    "print('action shape = ', action.shape)\n",
    "\n",
    "qvalue = qnet(obs, action)\n",
    "print('q value = ', qvalue.shape)\n",
    "\n",
    "actor_action, logprob, mean = actor.get_action(obs)\n",
    "print('actor action = ', actor_action.shape)\n",
    "print('logprob  = ', logprob.shape)\n",
    "print('mean  = ', mean.shape)\n",
    "\n",
    "\n",
    "# action, log_prob, entropy, value = test_agent.get_action_and_value(obs)\n",
    "\n",
    "# print('log prob shape = ', log_prob.shape)\n",
    "# print('entropy shape = ', entropy.shape)\n",
    "# print('value shape = ', value.shape)\n",
    "\n",
    "# del test_agent\n",
    "\n",
    "envs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, show = False, save_path = None):\n",
    "    sns.lineplot(y = history['reward'], x = list(range(len(history['reward']))))\n",
    "\n",
    "    if save_path != None:\n",
    "        plt.savefig(save_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def replay_buffer_usage(rb: ReplayBuffer):\n",
    "    return (rb.pos / rb.buffer_size) * 100 if rb.full == False else 100\n",
    "\n",
    "def pickle_dump(obj, path):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(obj, file)\n",
    "    \n",
    "def pickle_load(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        obj = pickle.dump(file)\n",
    "    return obj\n",
    "\n",
    "def evaluate(agent, episodes = 10):\n",
    "    envs = gym.vector.SyncVectorEnv([lambda: make_env(gamma = GAMMA, **ENV_ARGS)])\n",
    "    agent.eval()\n",
    "    total_rewards = []\n",
    "    next_obs, _ = envs.reset()\n",
    "\n",
    "    while len(total_rewards) < episodes: \n",
    "        next_obs = torch.Tensor(next_obs)\n",
    "        with torch.no_grad():\n",
    "            action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "\n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.numpy())\n",
    "\n",
    "        if 'final_info' in info:\n",
    "            for data in info['final_info']:\n",
    "                if data:\n",
    "                    reward = data['episode']['r'][0]\n",
    "                    total_rewards.append(reward)\n",
    "\n",
    "    return total_rewards\n",
    "\n",
    "def soft_update(net:nn.Module, other: nn.Module, tau = 0.005):\n",
    "    for this_param, other_param in zip(net.parameters(), other.parameters()):\n",
    "        this_param.data.copy_(tau * other_param.data + (1 - tau) * this_param.data)\n",
    "    \n",
    "def weight_update(net:nn.Module, other: nn.Module, tau = 0.005):\n",
    "    net.load_state_dict(other.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(\n",
    "    envs: gym.Env, actor:Actor, qf1:QNetwork, qf2:QNetwork, \n",
    "    qf1_target:QNetwork, qf2_target:QNetwork,\n",
    "    q_optimizer, actor_optimizer, device,\n",
    "    buffer_size = int(1e6), batch_size = 32,\n",
    "    total_timesteps = 1000, warmup_steps = 50,\n",
    "    policy_update_freq = 2, target_net_update_freq = 1, gamma = 0.99, \n",
    "    plot_update_freq = 10, label = 'test', plot_udpate_freq = 10, history = None):\n",
    "\n",
    "    SAVE_PATH = os.path.join(OUTPUT, label)\n",
    "    FIG_SAVE_PATH = os.path.join(SAVE_PATH, 'plot.png')\n",
    "    HISTORY_PATH = os.path.join(SAVE_PATH, 'history.pickle')\n",
    "\n",
    "    if os.path.exists(SAVE_PATH) == False:\n",
    "        os.makedirs(SAVE_PATH)\n",
    "\n",
    "    print('save path = ', SAVE_PATH)\n",
    "\n",
    "    state_size = np.prod(envs.single_observation_space.shape)\n",
    "    action_size = np.prod(envs.single_action_space.shape)\n",
    "    n_envs = envs.observation_space.shape[0]\n",
    "\n",
    "    #default to float\n",
    "    envs.single_observation_space.dtype = np.float32\n",
    "\n",
    "    alpha = 0.2 # expected return and entropy trade-off coefficient \n",
    "\n",
    "    # target_entropy = -torch.prod(torch.Tensor(envs.single_action_space.shape).to(device)).item()\n",
    "    # log_alpha = torch.zeros(1, requires_grad = True, device= device)\n",
    "    # alpha = log_alpha.exp().item()\n",
    "    # a_optimizer = torch.optim.Adam([log_alpha], lr = 1e-3)\n",
    "\n",
    "    replay_buffer = ReplayBuffer(\n",
    "            buffer_size,\n",
    "            envs.single_observation_space, \n",
    "            envs.single_action_space, \n",
    "            device = device,\n",
    "            handle_timeout_termination=False,\n",
    "            optimize_memory_usage=True,\n",
    "            n_envs=n_envs\n",
    "    )\n",
    "\n",
    "    obs, _ = envs.reset()\n",
    "    avg_reward = 0\n",
    "    avg_reward = 0\n",
    "    best_score = -float('inf')\n",
    "    score_window = deque(maxlen = 100)\n",
    "    if history == None:\n",
    "        history = defaultdict(list)\n",
    "\n",
    "    loop = tqdm(range(total_timesteps))\n",
    "    episode_count = 0\n",
    "    updated_t = 0\n",
    "\n",
    "    #start training loop\n",
    "    for global_step in loop:\n",
    "        t = int(loop.format_dict['elapsed'])\n",
    "\n",
    "        #if still warming up, get random action\n",
    "        if global_step < warmup_steps:\n",
    "            actions = envs.action_space.sample()\n",
    "        \n",
    "        #else done warmup, get actions from actor\n",
    "        else:\n",
    "            actions, _,_ = actor.get_action(torch.tensor(obs).to(device).float())\n",
    "            actions = actions.detach().cpu().numpy()\n",
    "        \n",
    "        next_obs, rewards, terminations, truncations, infos = envs.step(actions)\n",
    "\n",
    "        if 'final_info' in infos:\n",
    "            for info in infos['final_info']:\n",
    "                if info and 'episode' in info:\n",
    "                    test = True\n",
    "                    ep_return = info['episode']['r']\n",
    "                    score_window.append(ep_return)\n",
    "                    episode_count += 1\n",
    "\n",
    "                    avg_reward = np.mean(score_window)\n",
    "                    history['reward'].append(avg_reward)\n",
    "                    history['buffer_usage'].append(replay_buffer_usage(replay_buffer))\n",
    "\n",
    "                    #save model with new best score \n",
    "                    if avg_reward > best_score:\n",
    "                        best_score = avg_reward\n",
    "                        torch.save(actor, os.path.join(SAVE_PATH, 'actor.checkpoint.torch'))\n",
    "                        torch.save(qf1, os.path.join(SAVE_PATH, 'qf1.checkpoint.torch'))\n",
    "                        torch.save(qf2, os.path.join(SAVE_PATH, 'qf2.checkpoint.torch'))\n",
    "                        torch.save(qf1_target, os.path.join(SAVE_PATH, 'qf1_target.checkpoint.torch'))\n",
    "                        torch.save(qf2_target, os.path.join(SAVE_PATH, 'qf2_target.checkpoint.torch'))\n",
    "\n",
    "        real_next_obs = next_obs.copy()\n",
    "        for i, truncated in enumerate(truncations):\n",
    "            if truncated:\n",
    "                real_next_obs[i] = infos['final_observation'][i]\n",
    "        \n",
    "        replay_buffer.add(obs, real_next_obs, actions, rewards, terminations, infos)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "        #optimize when done warming up \n",
    "        if global_step > warmup_steps:\n",
    "\n",
    "            data = replay_buffer.sample(batch_size)\n",
    "            b_next_obs = data.next_observations.to()\n",
    "            b_obs = data.observations\n",
    "            b_actions = data.actions\n",
    "            b_rewards = data.rewards\n",
    "            b_dones = data.dones\n",
    "\n",
    "            with torch.no_grad():\n",
    "                next_state_actions, next_state_log_probs, _ = actor.get_action(b_next_obs)\n",
    "                qf1_next_target = qf1_target(b_next_obs, next_state_actions)\n",
    "                qf2_next_target = qf2_target(b_next_obs, next_state_actions)\n",
    "                min_qf_next_target = torch.min(qf1_next_target, qf2_next_target) - alpha * next_state_log_probs\n",
    "                next_q_value = b_rewards.flatten() + (1 - b_dones.flatten()) * gamma * min_qf_next_target.view(-1)\n",
    "            \n",
    "            qf1_a_values = qf1(b_obs, b_actions).view(-1)\n",
    "            qf2_a_values = qf2(b_obs, b_actions).view(-1)\n",
    "\n",
    "            qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "            qf2_loss = F.mse_loss(qf2_a_values, next_q_value)\n",
    "\n",
    "            qf_loss = qf1_loss + qf2_loss\n",
    "\n",
    "            #step q_optimizer\n",
    "            q_optimizer.zero_grad()\n",
    "            qf_loss.backward()\n",
    "            q_optimizer.step()\n",
    "\n",
    "            #TD3 update delayed\n",
    "            if global_step % policy_update_freq == 0:\n",
    "                for _ in range(policy_update_freq):\n",
    "\n",
    "                    pi, log_pi, _ = actor.get_action(b_obs)\n",
    "\n",
    "                    qf1_pi = qf1(b_obs, pi)\n",
    "                    qf2_pi = qf2(b_obs, pi)\n",
    "\n",
    "                    min_qf_pi = torch.min(qf1_pi, qf2_pi)\n",
    "\n",
    "                    actor_loss = ((alpha * log_pi) - min_qf_pi).mean()\n",
    "\n",
    "                    actor_optimizer.zero_grad()\n",
    "                    actor_loss.backward()\n",
    "                    actor_optimizer.step()\n",
    "\n",
    "                    # with torch.no_grad():\n",
    "                    #     _, log_pi,_ = actor.get_action(b_obs)\n",
    "\n",
    "                    # alpha_loss = (-log_alpha.exp() * (log_pi + target_entropy)).mean()\n",
    "\n",
    "                    # a_optimizer.zero_grad()\n",
    "                    # alpha_loss.backward()\n",
    "                    # a_optimizer.step()\n",
    "\n",
    "                    # alpha = log_alpha.exp().item()\n",
    "            \n",
    "            if global_step % target_net_update_freq == 0:\n",
    "                soft_update(qf1_target, qf1)\n",
    "                soft_update(qf2_target, qf2)\n",
    "        \n",
    "        if t != updated_t and t % plot_update_freq == 0: \n",
    "            updated_t = t\n",
    "            loop.set_description(f\"avg_reward = {avg_reward:.2f}, best_score = {best_score}, episode_count = {episode_count}, buffer usage = {replay_buffer_usage(replay_buffer):.2f}\")\n",
    "            plot(history, save_path = FIG_SAVE_PATH)\n",
    "            pickle_dump(history, HISTORY_PATH)\n",
    "\n",
    "    plot(history, show = True, save_path = FIG_SAVE_PATH)\n",
    "    envs.reset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save path =  /Volumes/SanDisk/NLP_RNN/Reinforcement Learning/deep rl/sac/output/HalfCheetah-v4/baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "avg_reward = 1944.90, best_score = 1945.2420654296875, episode_count = 1497, buffer usage = 100.00: 100%|██████████| 500000/500000 [1:38:26<00:00, 84.65it/s]  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device= DEVICE\n",
    "q_lr = 1e-3\n",
    "actor_lr = 1e-3\n",
    "total_timesteps = int(5e5)\n",
    "warmup_steps = int(1e3)\n",
    "buffer_size = int(5e5)\n",
    "batch_size = 256\n",
    "fc_hidden_size = 256\n",
    "\n",
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(gamma= 0.99, **ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "assert isinstance(envs.single_action_space, gym.spaces.Box), 'Only continous action is supported'\n",
    "\n",
    "actor = Actor(envs, hidden_size=fc_hidden_size).to(device)\n",
    "qf1 = QNetwork(envs).to(device)\n",
    "qf2 = QNetwork(envs).to(device)\n",
    "qf1_target = QNetwork(envs).to(device)\n",
    "qf2_target = QNetwork(envs).to(device)\n",
    "qf1_target.load_state_dict(qf1.state_dict())\n",
    "qf2_target.load_state_dict(qf2.state_dict())\n",
    "\n",
    "q_optimizer = torch.optim.Adam(list(qf1.parameters()) + list(qf2.parameters()), lr = q_lr) \n",
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr = actor_lr) \n",
    "#NOTE: use fixec entropy method mentioned in Spin-up, improve this later with enforce method\n",
    "# https://spinningup.openai.com/en/latest/algorithms/sac.html\n",
    "\n",
    "\n",
    "tune(envs, actor, qf1, qf2, qf1_target, qf2_target, \n",
    "q_optimizer, actor_optimizer, device = device,\n",
    "total_timesteps= total_timesteps, warmup_steps=warmup_steps,\n",
    "buffer_size=buffer_size, batch_size=batch_size, label = 'baseline'\n",
    ")\n",
    "\n",
    "envs.close()\n",
    "\n",
    "\n",
    "# #check to make sure this is continous action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n",
    "\n",
    "https://github.com/vwxyzjn/cleanrl?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import deque, Counter, namedtuple, defaultdict\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "import math\n",
    "from itertools import count\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from stable_baselines3.common.atari_wrappers import ClipRewardEnv, FireResetEnv, MaxAndSkipEnv, NoopResetEnv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20f4311ea10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENV_ARGS = {\n",
    "    'id': \"BreakoutNoFrameskip-v4\"\n",
    "}\n",
    "NUM_ENVS = 3\n",
    "SEED = 1\n",
    "LR = 3e-4\n",
    "NUM_STEPS = 2048\n",
    "NUM_ITERATIONS = 1000\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "UPDATE_EPOCHS = 10\n",
    "CLIP_COEF = 0.2 # the epsilon in KL divergece in PPO paper\n",
    "ENTROPY_COEF = 0.0\n",
    "VF_COEF = 0.5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "MINI_BATCH_COUNT = 32\n",
    "UPDATE_PLOTS = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device = ', DEVICE)\n",
    "\n",
    "#output directory\n",
    "ROOT = os.getcwd()\n",
    "OUTPUT = os.path.join(ROOT, 'output')\n",
    "\n",
    "if os.path.exists(OUTPUT) == False:\n",
    "    os.makedirs(OUTPUT)\n",
    "\n",
    "#seeding\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'CartPoleJax-v0', 'CartPoleJax-v1', 'PendulumJax-v0', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Jax-Blackjack-v0', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'GymV26Environment-v0', 'GymV21Environment-v0', 'Adventure-v0', 'AdventureDeterministic-v0', 'AdventureNoFrameskip-v0', 'Adventure-v4', 'AdventureDeterministic-v4', 'AdventureNoFrameskip-v4', 'Adventure-ram-v0', 'Adventure-ramDeterministic-v0', 'Adventure-ramNoFrameskip-v0', 'Adventure-ram-v4', 'Adventure-ramDeterministic-v4', 'Adventure-ramNoFrameskip-v4', 'AirRaid-v0', 'AirRaidDeterministic-v0', 'AirRaidNoFrameskip-v0', 'AirRaid-v4', 'AirRaidDeterministic-v4', 'AirRaidNoFrameskip-v4', 'AirRaid-ram-v0', 'AirRaid-ramDeterministic-v0', 'AirRaid-ramNoFrameskip-v0', 'AirRaid-ram-v4', 'AirRaid-ramDeterministic-v4', 'AirRaid-ramNoFrameskip-v4', 'Alien-v0', 'AlienDeterministic-v0', 'AlienNoFrameskip-v0', 'Alien-v4', 'AlienDeterministic-v4', 'AlienNoFrameskip-v4', 'Alien-ram-v0', 'Alien-ramDeterministic-v0', 'Alien-ramNoFrameskip-v0', 'Alien-ram-v4', 'Alien-ramDeterministic-v4', 'Alien-ramNoFrameskip-v4', 'Amidar-v0', 'AmidarDeterministic-v0', 'AmidarNoFrameskip-v0', 'Amidar-v4', 'AmidarDeterministic-v4', 'AmidarNoFrameskip-v4', 'Amidar-ram-v0', 'Amidar-ramDeterministic-v0', 'Amidar-ramNoFrameskip-v0', 'Amidar-ram-v4', 'Amidar-ramDeterministic-v4', 'Amidar-ramNoFrameskip-v4', 'Assault-v0', 'AssaultDeterministic-v0', 'AssaultNoFrameskip-v0', 'Assault-v4', 'AssaultDeterministic-v4', 'AssaultNoFrameskip-v4', 'Assault-ram-v0', 'Assault-ramDeterministic-v0', 'Assault-ramNoFrameskip-v0', 'Assault-ram-v4', 'Assault-ramDeterministic-v4', 'Assault-ramNoFrameskip-v4', 'Asterix-v0', 'AsterixDeterministic-v0', 'AsterixNoFrameskip-v0', 'Asterix-v4', 'AsterixDeterministic-v4', 'AsterixNoFrameskip-v4', 'Asterix-ram-v0', 'Asterix-ramDeterministic-v0', 'Asterix-ramNoFrameskip-v0', 'Asterix-ram-v4', 'Asterix-ramDeterministic-v4', 'Asterix-ramNoFrameskip-v4', 'Asteroids-v0', 'AsteroidsDeterministic-v0', 'AsteroidsNoFrameskip-v0', 'Asteroids-v4', 'AsteroidsDeterministic-v4', 'AsteroidsNoFrameskip-v4', 'Asteroids-ram-v0', 'Asteroids-ramDeterministic-v0', 'Asteroids-ramNoFrameskip-v0', 'Asteroids-ram-v4', 'Asteroids-ramDeterministic-v4', 'Asteroids-ramNoFrameskip-v4', 'Atlantis-v0', 'AtlantisDeterministic-v0', 'AtlantisNoFrameskip-v0', 'Atlantis-v4', 'AtlantisDeterministic-v4', 'AtlantisNoFrameskip-v4', 'Atlantis-ram-v0', 'Atlantis-ramDeterministic-v0', 'Atlantis-ramNoFrameskip-v0', 'Atlantis-ram-v4', 'Atlantis-ramDeterministic-v4', 'Atlantis-ramNoFrameskip-v4', 'BankHeist-v0', 'BankHeistDeterministic-v0', 'BankHeistNoFrameskip-v0', 'BankHeist-v4', 'BankHeistDeterministic-v4', 'BankHeistNoFrameskip-v4', 'BankHeist-ram-v0', 'BankHeist-ramDeterministic-v0', 'BankHeist-ramNoFrameskip-v0', 'BankHeist-ram-v4', 'BankHeist-ramDeterministic-v4', 'BankHeist-ramNoFrameskip-v4', 'BattleZone-v0', 'BattleZoneDeterministic-v0', 'BattleZoneNoFrameskip-v0', 'BattleZone-v4', 'BattleZoneDeterministic-v4', 'BattleZoneNoFrameskip-v4', 'BattleZone-ram-v0', 'BattleZone-ramDeterministic-v0', 'BattleZone-ramNoFrameskip-v0', 'BattleZone-ram-v4', 'BattleZone-ramDeterministic-v4', 'BattleZone-ramNoFrameskip-v4', 'BeamRider-v0', 'BeamRiderDeterministic-v0', 'BeamRiderNoFrameskip-v0', 'BeamRider-v4', 'BeamRiderDeterministic-v4', 'BeamRiderNoFrameskip-v4', 'BeamRider-ram-v0', 'BeamRider-ramDeterministic-v0', 'BeamRider-ramNoFrameskip-v0', 'BeamRider-ram-v4', 'BeamRider-ramDeterministic-v4', 'BeamRider-ramNoFrameskip-v4', 'Berzerk-v0', 'BerzerkDeterministic-v0', 'BerzerkNoFrameskip-v0', 'Berzerk-v4', 'BerzerkDeterministic-v4', 'BerzerkNoFrameskip-v4', 'Berzerk-ram-v0', 'Berzerk-ramDeterministic-v0', 'Berzerk-ramNoFrameskip-v0', 'Berzerk-ram-v4', 'Berzerk-ramDeterministic-v4', 'Berzerk-ramNoFrameskip-v4', 'Bowling-v0', 'BowlingDeterministic-v0', 'BowlingNoFrameskip-v0', 'Bowling-v4', 'BowlingDeterministic-v4', 'BowlingNoFrameskip-v4', 'Bowling-ram-v0', 'Bowling-ramDeterministic-v0', 'Bowling-ramNoFrameskip-v0', 'Bowling-ram-v4', 'Bowling-ramDeterministic-v4', 'Bowling-ramNoFrameskip-v4', 'Boxing-v0', 'BoxingDeterministic-v0', 'BoxingNoFrameskip-v0', 'Boxing-v4', 'BoxingDeterministic-v4', 'BoxingNoFrameskip-v4', 'Boxing-ram-v0', 'Boxing-ramDeterministic-v0', 'Boxing-ramNoFrameskip-v0', 'Boxing-ram-v4', 'Boxing-ramDeterministic-v4', 'Boxing-ramNoFrameskip-v4', 'Breakout-v0', 'BreakoutDeterministic-v0', 'BreakoutNoFrameskip-v0', 'Breakout-v4', 'BreakoutDeterministic-v4', 'BreakoutNoFrameskip-v4', 'Breakout-ram-v0', 'Breakout-ramDeterministic-v0', 'Breakout-ramNoFrameskip-v0', 'Breakout-ram-v4', 'Breakout-ramDeterministic-v4', 'Breakout-ramNoFrameskip-v4', 'Carnival-v0', 'CarnivalDeterministic-v0', 'CarnivalNoFrameskip-v0', 'Carnival-v4', 'CarnivalDeterministic-v4', 'CarnivalNoFrameskip-v4', 'Carnival-ram-v0', 'Carnival-ramDeterministic-v0', 'Carnival-ramNoFrameskip-v0', 'Carnival-ram-v4', 'Carnival-ramDeterministic-v4', 'Carnival-ramNoFrameskip-v4', 'Centipede-v0', 'CentipedeDeterministic-v0', 'CentipedeNoFrameskip-v0', 'Centipede-v4', 'CentipedeDeterministic-v4', 'CentipedeNoFrameskip-v4', 'Centipede-ram-v0', 'Centipede-ramDeterministic-v0', 'Centipede-ramNoFrameskip-v0', 'Centipede-ram-v4', 'Centipede-ramDeterministic-v4', 'Centipede-ramNoFrameskip-v4', 'ChopperCommand-v0', 'ChopperCommandDeterministic-v0', 'ChopperCommandNoFrameskip-v0', 'ChopperCommand-v4', 'ChopperCommandDeterministic-v4', 'ChopperCommandNoFrameskip-v4', 'ChopperCommand-ram-v0', 'ChopperCommand-ramDeterministic-v0', 'ChopperCommand-ramNoFrameskip-v0', 'ChopperCommand-ram-v4', 'ChopperCommand-ramDeterministic-v4', 'ChopperCommand-ramNoFrameskip-v4', 'CrazyClimber-v0', 'CrazyClimberDeterministic-v0', 'CrazyClimberNoFrameskip-v0', 'CrazyClimber-v4', 'CrazyClimberDeterministic-v4', 'CrazyClimberNoFrameskip-v4', 'CrazyClimber-ram-v0', 'CrazyClimber-ramDeterministic-v0', 'CrazyClimber-ramNoFrameskip-v0', 'CrazyClimber-ram-v4', 'CrazyClimber-ramDeterministic-v4', 'CrazyClimber-ramNoFrameskip-v4', 'Defender-v0', 'DefenderDeterministic-v0', 'DefenderNoFrameskip-v0', 'Defender-v4', 'DefenderDeterministic-v4', 'DefenderNoFrameskip-v4', 'Defender-ram-v0', 'Defender-ramDeterministic-v0', 'Defender-ramNoFrameskip-v0', 'Defender-ram-v4', 'Defender-ramDeterministic-v4', 'Defender-ramNoFrameskip-v4', 'DemonAttack-v0', 'DemonAttackDeterministic-v0', 'DemonAttackNoFrameskip-v0', 'DemonAttack-v4', 'DemonAttackDeterministic-v4', 'DemonAttackNoFrameskip-v4', 'DemonAttack-ram-v0', 'DemonAttack-ramDeterministic-v0', 'DemonAttack-ramNoFrameskip-v0', 'DemonAttack-ram-v4', 'DemonAttack-ramDeterministic-v4', 'DemonAttack-ramNoFrameskip-v4', 'DoubleDunk-v0', 'DoubleDunkDeterministic-v0', 'DoubleDunkNoFrameskip-v0', 'DoubleDunk-v4', 'DoubleDunkDeterministic-v4', 'DoubleDunkNoFrameskip-v4', 'DoubleDunk-ram-v0', 'DoubleDunk-ramDeterministic-v0', 'DoubleDunk-ramNoFrameskip-v0', 'DoubleDunk-ram-v4', 'DoubleDunk-ramDeterministic-v4', 'DoubleDunk-ramNoFrameskip-v4', 'ElevatorAction-v0', 'ElevatorActionDeterministic-v0', 'ElevatorActionNoFrameskip-v0', 'ElevatorAction-v4', 'ElevatorActionDeterministic-v4', 'ElevatorActionNoFrameskip-v4', 'ElevatorAction-ram-v0', 'ElevatorAction-ramDeterministic-v0', 'ElevatorAction-ramNoFrameskip-v0', 'ElevatorAction-ram-v4', 'ElevatorAction-ramDeterministic-v4', 'ElevatorAction-ramNoFrameskip-v4', 'Enduro-v0', 'EnduroDeterministic-v0', 'EnduroNoFrameskip-v0', 'Enduro-v4', 'EnduroDeterministic-v4', 'EnduroNoFrameskip-v4', 'Enduro-ram-v0', 'Enduro-ramDeterministic-v0', 'Enduro-ramNoFrameskip-v0', 'Enduro-ram-v4', 'Enduro-ramDeterministic-v4', 'Enduro-ramNoFrameskip-v4', 'FishingDerby-v0', 'FishingDerbyDeterministic-v0', 'FishingDerbyNoFrameskip-v0', 'FishingDerby-v4', 'FishingDerbyDeterministic-v4', 'FishingDerbyNoFrameskip-v4', 'FishingDerby-ram-v0', 'FishingDerby-ramDeterministic-v0', 'FishingDerby-ramNoFrameskip-v0', 'FishingDerby-ram-v4', 'FishingDerby-ramDeterministic-v4', 'FishingDerby-ramNoFrameskip-v4', 'Freeway-v0', 'FreewayDeterministic-v0', 'FreewayNoFrameskip-v0', 'Freeway-v4', 'FreewayDeterministic-v4', 'FreewayNoFrameskip-v4', 'Freeway-ram-v0', 'Freeway-ramDeterministic-v0', 'Freeway-ramNoFrameskip-v0', 'Freeway-ram-v4', 'Freeway-ramDeterministic-v4', 'Freeway-ramNoFrameskip-v4', 'Frostbite-v0', 'FrostbiteDeterministic-v0', 'FrostbiteNoFrameskip-v0', 'Frostbite-v4', 'FrostbiteDeterministic-v4', 'FrostbiteNoFrameskip-v4', 'Frostbite-ram-v0', 'Frostbite-ramDeterministic-v0', 'Frostbite-ramNoFrameskip-v0', 'Frostbite-ram-v4', 'Frostbite-ramDeterministic-v4', 'Frostbite-ramNoFrameskip-v4', 'Gopher-v0', 'GopherDeterministic-v0', 'GopherNoFrameskip-v0', 'Gopher-v4', 'GopherDeterministic-v4', 'GopherNoFrameskip-v4', 'Gopher-ram-v0', 'Gopher-ramDeterministic-v0', 'Gopher-ramNoFrameskip-v0', 'Gopher-ram-v4', 'Gopher-ramDeterministic-v4', 'Gopher-ramNoFrameskip-v4', 'Gravitar-v0', 'GravitarDeterministic-v0', 'GravitarNoFrameskip-v0', 'Gravitar-v4', 'GravitarDeterministic-v4', 'GravitarNoFrameskip-v4', 'Gravitar-ram-v0', 'Gravitar-ramDeterministic-v0', 'Gravitar-ramNoFrameskip-v0', 'Gravitar-ram-v4', 'Gravitar-ramDeterministic-v4', 'Gravitar-ramNoFrameskip-v4', 'Hero-v0', 'HeroDeterministic-v0', 'HeroNoFrameskip-v0', 'Hero-v4', 'HeroDeterministic-v4', 'HeroNoFrameskip-v4', 'Hero-ram-v0', 'Hero-ramDeterministic-v0', 'Hero-ramNoFrameskip-v0', 'Hero-ram-v4', 'Hero-ramDeterministic-v4', 'Hero-ramNoFrameskip-v4', 'IceHockey-v0', 'IceHockeyDeterministic-v0', 'IceHockeyNoFrameskip-v0', 'IceHockey-v4', 'IceHockeyDeterministic-v4', 'IceHockeyNoFrameskip-v4', 'IceHockey-ram-v0', 'IceHockey-ramDeterministic-v0', 'IceHockey-ramNoFrameskip-v0', 'IceHockey-ram-v4', 'IceHockey-ramDeterministic-v4', 'IceHockey-ramNoFrameskip-v4', 'Jamesbond-v0', 'JamesbondDeterministic-v0', 'JamesbondNoFrameskip-v0', 'Jamesbond-v4', 'JamesbondDeterministic-v4', 'JamesbondNoFrameskip-v4', 'Jamesbond-ram-v0', 'Jamesbond-ramDeterministic-v0', 'Jamesbond-ramNoFrameskip-v0', 'Jamesbond-ram-v4', 'Jamesbond-ramDeterministic-v4', 'Jamesbond-ramNoFrameskip-v4', 'JourneyEscape-v0', 'JourneyEscapeDeterministic-v0', 'JourneyEscapeNoFrameskip-v0', 'JourneyEscape-v4', 'JourneyEscapeDeterministic-v4', 'JourneyEscapeNoFrameskip-v4', 'JourneyEscape-ram-v0', 'JourneyEscape-ramDeterministic-v0', 'JourneyEscape-ramNoFrameskip-v0', 'JourneyEscape-ram-v4', 'JourneyEscape-ramDeterministic-v4', 'JourneyEscape-ramNoFrameskip-v4', 'Kangaroo-v0', 'KangarooDeterministic-v0', 'KangarooNoFrameskip-v0', 'Kangaroo-v4', 'KangarooDeterministic-v4', 'KangarooNoFrameskip-v4', 'Kangaroo-ram-v0', 'Kangaroo-ramDeterministic-v0', 'Kangaroo-ramNoFrameskip-v0', 'Kangaroo-ram-v4', 'Kangaroo-ramDeterministic-v4', 'Kangaroo-ramNoFrameskip-v4', 'Krull-v0', 'KrullDeterministic-v0', 'KrullNoFrameskip-v0', 'Krull-v4', 'KrullDeterministic-v4', 'KrullNoFrameskip-v4', 'Krull-ram-v0', 'Krull-ramDeterministic-v0', 'Krull-ramNoFrameskip-v0', 'Krull-ram-v4', 'Krull-ramDeterministic-v4', 'Krull-ramNoFrameskip-v4', 'KungFuMaster-v0', 'KungFuMasterDeterministic-v0', 'KungFuMasterNoFrameskip-v0', 'KungFuMaster-v4', 'KungFuMasterDeterministic-v4', 'KungFuMasterNoFrameskip-v4', 'KungFuMaster-ram-v0', 'KungFuMaster-ramDeterministic-v0', 'KungFuMaster-ramNoFrameskip-v0', 'KungFuMaster-ram-v4', 'KungFuMaster-ramDeterministic-v4', 'KungFuMaster-ramNoFrameskip-v4', 'MontezumaRevenge-v0', 'MontezumaRevengeDeterministic-v0', 'MontezumaRevengeNoFrameskip-v0', 'MontezumaRevenge-v4', 'MontezumaRevengeDeterministic-v4', 'MontezumaRevengeNoFrameskip-v4', 'MontezumaRevenge-ram-v0', 'MontezumaRevenge-ramDeterministic-v0', 'MontezumaRevenge-ramNoFrameskip-v0', 'MontezumaRevenge-ram-v4', 'MontezumaRevenge-ramDeterministic-v4', 'MontezumaRevenge-ramNoFrameskip-v4', 'MsPacman-v0', 'MsPacmanDeterministic-v0', 'MsPacmanNoFrameskip-v0', 'MsPacman-v4', 'MsPacmanDeterministic-v4', 'MsPacmanNoFrameskip-v4', 'MsPacman-ram-v0', 'MsPacman-ramDeterministic-v0', 'MsPacman-ramNoFrameskip-v0', 'MsPacman-ram-v4', 'MsPacman-ramDeterministic-v4', 'MsPacman-ramNoFrameskip-v4', 'NameThisGame-v0', 'NameThisGameDeterministic-v0', 'NameThisGameNoFrameskip-v0', 'NameThisGame-v4', 'NameThisGameDeterministic-v4', 'NameThisGameNoFrameskip-v4', 'NameThisGame-ram-v0', 'NameThisGame-ramDeterministic-v0', 'NameThisGame-ramNoFrameskip-v0', 'NameThisGame-ram-v4', 'NameThisGame-ramDeterministic-v4', 'NameThisGame-ramNoFrameskip-v4', 'Phoenix-v0', 'PhoenixDeterministic-v0', 'PhoenixNoFrameskip-v0', 'Phoenix-v4', 'PhoenixDeterministic-v4', 'PhoenixNoFrameskip-v4', 'Phoenix-ram-v0', 'Phoenix-ramDeterministic-v0', 'Phoenix-ramNoFrameskip-v0', 'Phoenix-ram-v4', 'Phoenix-ramDeterministic-v4', 'Phoenix-ramNoFrameskip-v4', 'Pitfall-v0', 'PitfallDeterministic-v0', 'PitfallNoFrameskip-v0', 'Pitfall-v4', 'PitfallDeterministic-v4', 'PitfallNoFrameskip-v4', 'Pitfall-ram-v0', 'Pitfall-ramDeterministic-v0', 'Pitfall-ramNoFrameskip-v0', 'Pitfall-ram-v4', 'Pitfall-ramDeterministic-v4', 'Pitfall-ramNoFrameskip-v4', 'Pong-v0', 'PongDeterministic-v0', 'PongNoFrameskip-v0', 'Pong-v4', 'PongDeterministic-v4', 'PongNoFrameskip-v4', 'Pong-ram-v0', 'Pong-ramDeterministic-v0', 'Pong-ramNoFrameskip-v0', 'Pong-ram-v4', 'Pong-ramDeterministic-v4', 'Pong-ramNoFrameskip-v4', 'Pooyan-v0', 'PooyanDeterministic-v0', 'PooyanNoFrameskip-v0', 'Pooyan-v4', 'PooyanDeterministic-v4', 'PooyanNoFrameskip-v4', 'Pooyan-ram-v0', 'Pooyan-ramDeterministic-v0', 'Pooyan-ramNoFrameskip-v0', 'Pooyan-ram-v4', 'Pooyan-ramDeterministic-v4', 'Pooyan-ramNoFrameskip-v4', 'PrivateEye-v0', 'PrivateEyeDeterministic-v0', 'PrivateEyeNoFrameskip-v0', 'PrivateEye-v4', 'PrivateEyeDeterministic-v4', 'PrivateEyeNoFrameskip-v4', 'PrivateEye-ram-v0', 'PrivateEye-ramDeterministic-v0', 'PrivateEye-ramNoFrameskip-v0', 'PrivateEye-ram-v4', 'PrivateEye-ramDeterministic-v4', 'PrivateEye-ramNoFrameskip-v4', 'Qbert-v0', 'QbertDeterministic-v0', 'QbertNoFrameskip-v0', 'Qbert-v4', 'QbertDeterministic-v4', 'QbertNoFrameskip-v4', 'Qbert-ram-v0', 'Qbert-ramDeterministic-v0', 'Qbert-ramNoFrameskip-v0', 'Qbert-ram-v4', 'Qbert-ramDeterministic-v4', 'Qbert-ramNoFrameskip-v4', 'Riverraid-v0', 'RiverraidDeterministic-v0', 'RiverraidNoFrameskip-v0', 'Riverraid-v4', 'RiverraidDeterministic-v4', 'RiverraidNoFrameskip-v4', 'Riverraid-ram-v0', 'Riverraid-ramDeterministic-v0', 'Riverraid-ramNoFrameskip-v0', 'Riverraid-ram-v4', 'Riverraid-ramDeterministic-v4', 'Riverraid-ramNoFrameskip-v4', 'RoadRunner-v0', 'RoadRunnerDeterministic-v0', 'RoadRunnerNoFrameskip-v0', 'RoadRunner-v4', 'RoadRunnerDeterministic-v4', 'RoadRunnerNoFrameskip-v4', 'RoadRunner-ram-v0', 'RoadRunner-ramDeterministic-v0', 'RoadRunner-ramNoFrameskip-v0', 'RoadRunner-ram-v4', 'RoadRunner-ramDeterministic-v4', 'RoadRunner-ramNoFrameskip-v4', 'Robotank-v0', 'RobotankDeterministic-v0', 'RobotankNoFrameskip-v0', 'Robotank-v4', 'RobotankDeterministic-v4', 'RobotankNoFrameskip-v4', 'Robotank-ram-v0', 'Robotank-ramDeterministic-v0', 'Robotank-ramNoFrameskip-v0', 'Robotank-ram-v4', 'Robotank-ramDeterministic-v4', 'Robotank-ramNoFrameskip-v4', 'Seaquest-v0', 'SeaquestDeterministic-v0', 'SeaquestNoFrameskip-v0', 'Seaquest-v4', 'SeaquestDeterministic-v4', 'SeaquestNoFrameskip-v4', 'Seaquest-ram-v0', 'Seaquest-ramDeterministic-v0', 'Seaquest-ramNoFrameskip-v0', 'Seaquest-ram-v4', 'Seaquest-ramDeterministic-v4', 'Seaquest-ramNoFrameskip-v4', 'Skiing-v0', 'SkiingDeterministic-v0', 'SkiingNoFrameskip-v0', 'Skiing-v4', 'SkiingDeterministic-v4', 'SkiingNoFrameskip-v4', 'Skiing-ram-v0', 'Skiing-ramDeterministic-v0', 'Skiing-ramNoFrameskip-v0', 'Skiing-ram-v4', 'Skiing-ramDeterministic-v4', 'Skiing-ramNoFrameskip-v4', 'Solaris-v0', 'SolarisDeterministic-v0', 'SolarisNoFrameskip-v0', 'Solaris-v4', 'SolarisDeterministic-v4', 'SolarisNoFrameskip-v4', 'Solaris-ram-v0', 'Solaris-ramDeterministic-v0', 'Solaris-ramNoFrameskip-v0', 'Solaris-ram-v4', 'Solaris-ramDeterministic-v4', 'Solaris-ramNoFrameskip-v4', 'SpaceInvaders-v0', 'SpaceInvadersDeterministic-v0', 'SpaceInvadersNoFrameskip-v0', 'SpaceInvaders-v4', 'SpaceInvadersDeterministic-v4', 'SpaceInvadersNoFrameskip-v4', 'SpaceInvaders-ram-v0', 'SpaceInvaders-ramDeterministic-v0', 'SpaceInvaders-ramNoFrameskip-v0', 'SpaceInvaders-ram-v4', 'SpaceInvaders-ramDeterministic-v4', 'SpaceInvaders-ramNoFrameskip-v4', 'StarGunner-v0', 'StarGunnerDeterministic-v0', 'StarGunnerNoFrameskip-v0', 'StarGunner-v4', 'StarGunnerDeterministic-v4', 'StarGunnerNoFrameskip-v4', 'StarGunner-ram-v0', 'StarGunner-ramDeterministic-v0', 'StarGunner-ramNoFrameskip-v0', 'StarGunner-ram-v4', 'StarGunner-ramDeterministic-v4', 'StarGunner-ramNoFrameskip-v4', 'Tennis-v0', 'TennisDeterministic-v0', 'TennisNoFrameskip-v0', 'Tennis-v4', 'TennisDeterministic-v4', 'TennisNoFrameskip-v4', 'Tennis-ram-v0', 'Tennis-ramDeterministic-v0', 'Tennis-ramNoFrameskip-v0', 'Tennis-ram-v4', 'Tennis-ramDeterministic-v4', 'Tennis-ramNoFrameskip-v4', 'TimePilot-v0', 'TimePilotDeterministic-v0', 'TimePilotNoFrameskip-v0', 'TimePilot-v4', 'TimePilotDeterministic-v4', 'TimePilotNoFrameskip-v4', 'TimePilot-ram-v0', 'TimePilot-ramDeterministic-v0', 'TimePilot-ramNoFrameskip-v0', 'TimePilot-ram-v4', 'TimePilot-ramDeterministic-v4', 'TimePilot-ramNoFrameskip-v4', 'Tutankham-v0', 'TutankhamDeterministic-v0', 'TutankhamNoFrameskip-v0', 'Tutankham-v4', 'TutankhamDeterministic-v4', 'TutankhamNoFrameskip-v4', 'Tutankham-ram-v0', 'Tutankham-ramDeterministic-v0', 'Tutankham-ramNoFrameskip-v0', 'Tutankham-ram-v4', 'Tutankham-ramDeterministic-v4', 'Tutankham-ramNoFrameskip-v4', 'UpNDown-v0', 'UpNDownDeterministic-v0', 'UpNDownNoFrameskip-v0', 'UpNDown-v4', 'UpNDownDeterministic-v4', 'UpNDownNoFrameskip-v4', 'UpNDown-ram-v0', 'UpNDown-ramDeterministic-v0', 'UpNDown-ramNoFrameskip-v0', 'UpNDown-ram-v4', 'UpNDown-ramDeterministic-v4', 'UpNDown-ramNoFrameskip-v4', 'Venture-v0', 'VentureDeterministic-v0', 'VentureNoFrameskip-v0', 'Venture-v4', 'VentureDeterministic-v4', 'VentureNoFrameskip-v4', 'Venture-ram-v0', 'Venture-ramDeterministic-v0', 'Venture-ramNoFrameskip-v0', 'Venture-ram-v4', 'Venture-ramDeterministic-v4', 'Venture-ramNoFrameskip-v4', 'VideoPinball-v0', 'VideoPinballDeterministic-v0', 'VideoPinballNoFrameskip-v0', 'VideoPinball-v4', 'VideoPinballDeterministic-v4', 'VideoPinballNoFrameskip-v4', 'VideoPinball-ram-v0', 'VideoPinball-ramDeterministic-v0', 'VideoPinball-ramNoFrameskip-v0', 'VideoPinball-ram-v4', 'VideoPinball-ramDeterministic-v4', 'VideoPinball-ramNoFrameskip-v4', 'WizardOfWor-v0', 'WizardOfWorDeterministic-v0', 'WizardOfWorNoFrameskip-v0', 'WizardOfWor-v4', 'WizardOfWorDeterministic-v4', 'WizardOfWorNoFrameskip-v4', 'WizardOfWor-ram-v0', 'WizardOfWor-ramDeterministic-v0', 'WizardOfWor-ramNoFrameskip-v0', 'WizardOfWor-ram-v4', 'WizardOfWor-ramDeterministic-v4', 'WizardOfWor-ramNoFrameskip-v4', 'YarsRevenge-v0', 'YarsRevengeDeterministic-v0', 'YarsRevengeNoFrameskip-v0', 'YarsRevenge-v4', 'YarsRevengeDeterministic-v4', 'YarsRevengeNoFrameskip-v4', 'YarsRevenge-ram-v0', 'YarsRevenge-ramDeterministic-v0', 'YarsRevenge-ramNoFrameskip-v0', 'YarsRevenge-ram-v4', 'YarsRevenge-ramDeterministic-v4', 'YarsRevenge-ramNoFrameskip-v4', 'Zaxxon-v0', 'ZaxxonDeterministic-v0', 'ZaxxonNoFrameskip-v0', 'Zaxxon-v4', 'ZaxxonDeterministic-v4', 'ZaxxonNoFrameskip-v4', 'Zaxxon-ram-v0', 'Zaxxon-ramDeterministic-v0', 'Zaxxon-ramNoFrameskip-v0', 'Zaxxon-ram-v4', 'Zaxxon-ramDeterministic-v4', 'Zaxxon-ramNoFrameskip-v4', 'ALE/Adventure-v5', 'ALE/Adventure-ram-v5', 'ALE/AirRaid-v5', 'ALE/AirRaid-ram-v5', 'ALE/Alien-v5', 'ALE/Alien-ram-v5', 'ALE/Amidar-v5', 'ALE/Amidar-ram-v5', 'ALE/Assault-v5', 'ALE/Assault-ram-v5', 'ALE/Asterix-v5', 'ALE/Asterix-ram-v5', 'ALE/Asteroids-v5', 'ALE/Asteroids-ram-v5', 'ALE/Atlantis-v5', 'ALE/Atlantis-ram-v5', 'ALE/Atlantis2-v5', 'ALE/Atlantis2-ram-v5', 'ALE/Backgammon-v5', 'ALE/Backgammon-ram-v5', 'ALE/BankHeist-v5', 'ALE/BankHeist-ram-v5', 'ALE/BasicMath-v5', 'ALE/BasicMath-ram-v5', 'ALE/BattleZone-v5', 'ALE/BattleZone-ram-v5', 'ALE/BeamRider-v5', 'ALE/BeamRider-ram-v5', 'ALE/Berzerk-v5', 'ALE/Berzerk-ram-v5', 'ALE/Blackjack-v5', 'ALE/Blackjack-ram-v5', 'ALE/Bowling-v5', 'ALE/Bowling-ram-v5', 'ALE/Boxing-v5', 'ALE/Boxing-ram-v5', 'ALE/Breakout-v5', 'ALE/Breakout-ram-v5', 'ALE/Carnival-v5', 'ALE/Carnival-ram-v5', 'ALE/Casino-v5', 'ALE/Casino-ram-v5', 'ALE/Centipede-v5', 'ALE/Centipede-ram-v5', 'ALE/ChopperCommand-v5', 'ALE/ChopperCommand-ram-v5', 'ALE/CrazyClimber-v5', 'ALE/CrazyClimber-ram-v5', 'ALE/Crossbow-v5', 'ALE/Crossbow-ram-v5', 'ALE/Darkchambers-v5', 'ALE/Darkchambers-ram-v5', 'ALE/Defender-v5', 'ALE/Defender-ram-v5', 'ALE/DemonAttack-v5', 'ALE/DemonAttack-ram-v5', 'ALE/DonkeyKong-v5', 'ALE/DonkeyKong-ram-v5', 'ALE/DoubleDunk-v5', 'ALE/DoubleDunk-ram-v5', 'ALE/Earthworld-v5', 'ALE/Earthworld-ram-v5', 'ALE/ElevatorAction-v5', 'ALE/ElevatorAction-ram-v5', 'ALE/Enduro-v5', 'ALE/Enduro-ram-v5', 'ALE/Entombed-v5', 'ALE/Entombed-ram-v5', 'ALE/Et-v5', 'ALE/Et-ram-v5', 'ALE/FishingDerby-v5', 'ALE/FishingDerby-ram-v5', 'ALE/FlagCapture-v5', 'ALE/FlagCapture-ram-v5', 'ALE/Freeway-v5', 'ALE/Freeway-ram-v5', 'ALE/Frogger-v5', 'ALE/Frogger-ram-v5', 'ALE/Frostbite-v5', 'ALE/Frostbite-ram-v5', 'ALE/Galaxian-v5', 'ALE/Galaxian-ram-v5', 'ALE/Gopher-v5', 'ALE/Gopher-ram-v5', 'ALE/Gravitar-v5', 'ALE/Gravitar-ram-v5', 'ALE/Hangman-v5', 'ALE/Hangman-ram-v5', 'ALE/HauntedHouse-v5', 'ALE/HauntedHouse-ram-v5', 'ALE/Hero-v5', 'ALE/Hero-ram-v5', 'ALE/HumanCannonball-v5', 'ALE/HumanCannonball-ram-v5', 'ALE/IceHockey-v5', 'ALE/IceHockey-ram-v5', 'ALE/Jamesbond-v5', 'ALE/Jamesbond-ram-v5', 'ALE/JourneyEscape-v5', 'ALE/JourneyEscape-ram-v5', 'ALE/Kaboom-v5', 'ALE/Kaboom-ram-v5', 'ALE/Kangaroo-v5', 'ALE/Kangaroo-ram-v5', 'ALE/KeystoneKapers-v5', 'ALE/KeystoneKapers-ram-v5', 'ALE/KingKong-v5', 'ALE/KingKong-ram-v5', 'ALE/Klax-v5', 'ALE/Klax-ram-v5', 'ALE/Koolaid-v5', 'ALE/Koolaid-ram-v5', 'ALE/Krull-v5', 'ALE/Krull-ram-v5', 'ALE/KungFuMaster-v5', 'ALE/KungFuMaster-ram-v5', 'ALE/LaserGates-v5', 'ALE/LaserGates-ram-v5', 'ALE/LostLuggage-v5', 'ALE/LostLuggage-ram-v5', 'ALE/MarioBros-v5', 'ALE/MarioBros-ram-v5', 'ALE/MiniatureGolf-v5', 'ALE/MiniatureGolf-ram-v5', 'ALE/MontezumaRevenge-v5', 'ALE/MontezumaRevenge-ram-v5', 'ALE/MrDo-v5', 'ALE/MrDo-ram-v5', 'ALE/MsPacman-v5', 'ALE/MsPacman-ram-v5', 'ALE/NameThisGame-v5', 'ALE/NameThisGame-ram-v5', 'ALE/Othello-v5', 'ALE/Othello-ram-v5', 'ALE/Pacman-v5', 'ALE/Pacman-ram-v5', 'ALE/Phoenix-v5', 'ALE/Phoenix-ram-v5', 'ALE/Pitfall-v5', 'ALE/Pitfall-ram-v5', 'ALE/Pitfall2-v5', 'ALE/Pitfall2-ram-v5', 'ALE/Pong-v5', 'ALE/Pong-ram-v5', 'ALE/Pooyan-v5', 'ALE/Pooyan-ram-v5', 'ALE/PrivateEye-v5', 'ALE/PrivateEye-ram-v5', 'ALE/Qbert-v5', 'ALE/Qbert-ram-v5', 'ALE/Riverraid-v5', 'ALE/Riverraid-ram-v5', 'ALE/RoadRunner-v5', 'ALE/RoadRunner-ram-v5', 'ALE/Robotank-v5', 'ALE/Robotank-ram-v5', 'ALE/Seaquest-v5', 'ALE/Seaquest-ram-v5', 'ALE/SirLancelot-v5', 'ALE/SirLancelot-ram-v5', 'ALE/Skiing-v5', 'ALE/Skiing-ram-v5', 'ALE/Solaris-v5', 'ALE/Solaris-ram-v5', 'ALE/SpaceInvaders-v5', 'ALE/SpaceInvaders-ram-v5', 'ALE/SpaceWar-v5', 'ALE/SpaceWar-ram-v5', 'ALE/StarGunner-v5', 'ALE/StarGunner-ram-v5', 'ALE/Superman-v5', 'ALE/Superman-ram-v5', 'ALE/Surround-v5', 'ALE/Surround-ram-v5', 'ALE/Tennis-v5', 'ALE/Tennis-ram-v5', 'ALE/Tetris-v5', 'ALE/Tetris-ram-v5', 'ALE/TicTacToe3D-v5', 'ALE/TicTacToe3D-ram-v5', 'ALE/TimePilot-v5', 'ALE/TimePilot-ram-v5', 'ALE/Trondead-v5', 'ALE/Trondead-ram-v5', 'ALE/Turmoil-v5', 'ALE/Turmoil-ram-v5', 'ALE/Tutankham-v5', 'ALE/Tutankham-ram-v5', 'ALE/UpNDown-v5', 'ALE/UpNDown-ram-v5', 'ALE/Venture-v5', 'ALE/Venture-ram-v5', 'ALE/VideoCheckers-v5', 'ALE/VideoCheckers-ram-v5', 'ALE/VideoChess-v5', 'ALE/VideoChess-ram-v5', 'ALE/VideoCube-v5', 'ALE/VideoCube-ram-v5', 'ALE/VideoPinball-v5', 'ALE/VideoPinball-ram-v5', 'ALE/WizardOfWor-v5', 'ALE/WizardOfWor-ram-v5', 'ALE/WordZapper-v5', 'ALE/WordZapper-ram-v5', 'ALE/YarsRevenge-v5', 'ALE/YarsRevenge-ram-v5', 'ALE/Zaxxon-v5', 'ALE/Zaxxon-ram-v5'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gym.envs.registration.registry.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(**ENV_ARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(**env_args):\n",
    "    env = gym.make(**env_args)\n",
    "    # env = gym.wrappers.FlattenObservation(env)\n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    env = NoopResetEnv(env, noop_max=30)\n",
    "    env = MaxAndSkipEnv(env, skip = 4)\n",
    "\n",
    "    env = ClipRewardEnv(env)\n",
    "    env = gym.wrappers.ResizeObservation(env, (84,84)) \n",
    "    env = gym.wrappers.GrayScaleObservation(env) \n",
    "    env = gym.wrappers.FrameStack(env, 4) \n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), 'Only discrete action is supported'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer: nn.Linear, std = np.sqrt(2), bias_const = 0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "class Agent(nn.Module):\n",
    "\n",
    "    def __init__(self, envs: gym.Env, hidden_size: int = 512):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            layer_init(nn.Conv2d(4, 32, 8, stride = 4)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(32, 64, 4, stride = 2)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Conv2d(64, 64, 3, stride = 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            layer_init(nn.Linear(64 * 7 * 7, hidden_size)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.actor = layer_init(nn.Linear(hidden_size, envs.single_action_space.n), std = 0.01)\n",
    "        self.critic = layer_init(nn.Linear(hidden_size,1 ), std = 1.0)\n",
    "    \n",
    "    def get_value(self, x):\n",
    "        return self.critic(self.network(x/255.0))\n",
    "    \n",
    "    def get_action_and_value(self, x, action = None):\n",
    "        '''\n",
    "        @params:\n",
    "            x: torch.tensor observation, shape = (N, observation size)\n",
    "            action: torch.tensor action\n",
    "        @returns:\n",
    "            action: torch.tensor, shape = (N, action size)\n",
    "            log_prob: torch.tensor, shape = (N,)\n",
    "            entropy: torch.tensor, shape = (N,)\n",
    "            value: torch.tensor, shape = (N,)\n",
    "        '''\n",
    "\n",
    "        hidden = self.network(x/255.0)\n",
    "        logits = self.actor(hidden)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action == None:\n",
    "            action = probs.sample()\n",
    "\n",
    "        log_prob = probs.log_prob(action)\n",
    "        entropy = probs.entropy()\n",
    "        value = self.critic(hidden)\n",
    "        return action, log_prob, entropy, value\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs shape =  torch.Size([3, 4, 84, 84])\n",
      "action shape =  torch.Size([3])\n",
      "log prob shape =  torch.Size([3])\n",
      "entropy shape =  torch.Size([3])\n",
      "value shape =  torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#Test agent\n",
    "# Test env\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), 'Only discrete action is supported'\n",
    "\n",
    "obs, info = envs.reset()\n",
    "obs = torch.tensor(obs).float()\n",
    "print('obs shape = ', obs.shape)\n",
    "\n",
    "test_agent = Agent(envs)\n",
    "\n",
    "action, log_prob, entropy, value = test_agent.get_action_and_value(obs)\n",
    "\n",
    "print('action shape = ', action.shape)\n",
    "print('log prob shape = ', log_prob.shape)\n",
    "print('entropy shape = ', entropy.shape)\n",
    "print('value shape = ', value.shape)\n",
    "\n",
    "envs.close()\n",
    "del test_agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, show = False, save_path = None):\n",
    "    sns.lineplot(y = history['reward'], x = list(range(len(history['reward']))))\n",
    "\n",
    "    if save_path != None:\n",
    "        plt.savefig(save_path)\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(agent, episodes = 10):\n",
    "    envs = gym.vector.SyncVectorEnv([lambda: make_env(gamma = GAMMA, **ENV_ARGS)])\n",
    "    agent.eval()\n",
    "    total_rewards = []\n",
    "    next_obs, _ = envs.reset()\n",
    "\n",
    "    while len(total_rewards) < episodes: \n",
    "        next_obs = torch.Tensor(next_obs)\n",
    "        with torch.no_grad():\n",
    "            action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "\n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.numpy())\n",
    "\n",
    "        if 'final_info' in info:\n",
    "            for data in info['final_info']:\n",
    "                if data:\n",
    "                    reward = data['episode']['r'][0]\n",
    "                    total_rewards.append(reward)\n",
    "\n",
    "    return total_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id =  f3e84445\n",
      "output folder: e:\\ML\\NLP\\Reinforcement Learning\\policy_gradient\\ppo\\atari\\output\\f3e84445\n",
      "next obs =  torch.Size([3, 4, 84, 84])\n",
      "next done =  torch.Size([3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward = 32.62, global_step = 6143229, best_score = 48.15, loss=-0.07: 100%|██████████| 1000/1000 [4:22:47<00:00, 15.77s/it] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 190\u001b[0m\n\u001b[0;32m    187\u001b[0m             nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(agent\u001b[38;5;241m.\u001b[39mparameters(), MAX_GRAD_NORM)\n\u001b[0;32m    188\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 190\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mevaluate\u001b[49m(agent))\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation = \u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(evaluation))\n\u001b[0;32m    192\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(agent, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(SAVE_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mppo.final.torch\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "# Create env\n",
    "envs = gym.vector.AsyncVectorEnv(\n",
    "    [lambda : make_env(**ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "agent = Agent(envs).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(agent.parameters(), lr = LR, eps = 1e-5)\n",
    "\n",
    "M = NUM_STEPS\n",
    "N = NUM_ENVS\n",
    "\n",
    "label = str(uuid.uuid4()).split('-')[0]\n",
    "print('run id = ', label)\n",
    "\n",
    "SAVE_PATH = os.path.join(OUTPUT, label)\n",
    "FIG_SAVE_PATH = os.path.join(SAVE_PATH, 'plot.png')\n",
    "if os.path.exists(SAVE_PATH) == False:\n",
    "    print(f'output folder: {SAVE_PATH}')\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "obs = torch.zeros((M, N) + envs.single_observation_space.shape).to(DEVICE)\n",
    "actions = torch.zeros((M,N) + envs.single_action_space.shape).to(DEVICE)\n",
    "log_probs = torch.zeros((M,N)).to(DEVICE)\n",
    "rewards = torch.zeros((M,N)).to(DEVICE)\n",
    "dones = torch.zeros((M,N)).to(DEVICE) # for masking\n",
    "values = torch.zeros((M,N)).to(DEVICE)\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "next_obs, _ = envs.reset()\n",
    "next_obs = torch.Tensor(next_obs).to(DEVICE)\n",
    "next_done = torch.zeros(N).to(DEVICE) #N is num envs\n",
    "\n",
    "print('next obs = ', next_obs.shape)\n",
    "print('next done = ', next_done.shape)\n",
    "\n",
    "reward_window = deque(maxlen = 100)\n",
    "history = defaultdict(list)\n",
    "\n",
    "loop = tqdm(range(NUM_ITERATIONS))\n",
    "agent.train()\n",
    "\n",
    "best_score = -float('inf')\n",
    "evaluation = 0\n",
    "loss = float('inf')\n",
    "\n",
    "for iter in loop:\n",
    "\n",
    "    #ROLLOUT phase\n",
    "    #M is max steps\n",
    "    if iter % UPDATE_PLOTS == 0:\n",
    "        plot(history, save_path=FIG_SAVE_PATH)\n",
    "\n",
    "    for step in range(M):\n",
    "        global_step += N\n",
    "\n",
    "        obs[step] = next_obs\n",
    "        dones[step] = next_done\n",
    "\n",
    "        #get action\n",
    "        #NOTE: no_grad disables gradient calculation --> reduce memory consumption\n",
    "        #the result of every computation will have requires_grad=False\n",
    "        with torch.no_grad():\n",
    "            action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "            values[step] = value.flatten()\n",
    "\n",
    "        actions[step] = action\n",
    "        log_probs[step] = log_prob\n",
    "\n",
    "        #make next step with actions\n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.cpu().numpy())\n",
    "\n",
    "        next_done = np.logical_or(terminated, truncated)\n",
    "\n",
    "        #NOTE: difference between view and reshape\n",
    "        # https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch\n",
    "        rewards[step] = torch.tensor(reward).view(-1)\n",
    "        next_obs = torch.tensor(next_obs).to(DEVICE)\n",
    "        next_done = torch.tensor(next_done).to(DEVICE)\n",
    "\n",
    "        #NOTE: vector envs will automatically reset, so no need to break \n",
    "        if 'final_info' in info:\n",
    "            for data in info['final_info']:\n",
    "                if data:\n",
    "                    reward = data['episode']['r']\n",
    "                    reward_window.append(reward)\n",
    "                    avg_reward = np.mean(reward_window)\n",
    "                    history['reward'].append(avg_reward)\n",
    "                    loop.set_description(f\"reward = {avg_reward:.2f}, global_step = {global_step}, best_score = {best_score:.2f}, loss={loss:.2f}\")\n",
    "\n",
    "                    if best_score < avg_reward:\n",
    "                        best_score = avg_reward\n",
    "                        #save model\n",
    "                        torch.save(agent, os.path.join(SAVE_PATH, 'ppo.checkpoint.torch'))\n",
    "        \n",
    "    #update the history for plotting, and printing progress\n",
    "\n",
    "    #OPTIMIZE phase:\n",
    "    with torch.no_grad():\n",
    "        #bootstrap values, compute returns\n",
    "        next_value = agent.get_value(next_obs).reshape(1,-1)\n",
    "        advantages = torch.zeros_like(rewards).to(DEVICE)\n",
    "        last_gae_lambda = 0\n",
    "\n",
    "        for t in reversed(range(NUM_STEPS)):\n",
    "            if t == NUM_STEPS - 1:\n",
    "                next_none_terminal = np.logical_not(next_done.cpu())\n",
    "                next_values = next_value\n",
    "            else:\n",
    "                next_none_terminal = np.logical_not(dones[t + 1].cpu())\n",
    "                next_values = values[t + 1]\n",
    "            \n",
    "            #A(s,a) = Q(s,a) - V(s,a) = r(t) + gamma * V(s', a) * mask - V(s)\n",
    "            # print(rewards[t].device)\n",
    "            # print(values[t].device)\n",
    "            # print(next_values.device)\n",
    "            # print(next_none_terminal.device)\n",
    "            next_none_terminal = next_none_terminal.to(DEVICE)\n",
    "\n",
    "            delta = rewards[t] + GAMMA * next_values * next_none_terminal - values[t]\n",
    "            #NOTE: learn about this formula\n",
    "            advantages[t] = last_gae_lambda = delta + GAMMA * GAE_LAMBDA * next_none_terminal * last_gae_lambda\n",
    "        returns = advantages + values\n",
    "    \n",
    "    #flatten the batch\n",
    "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
    "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
    "    b_log_probs = log_probs.reshape(-1)\n",
    "    b_advantages = advantages.reshape(-1)\n",
    "    b_returns = returns.reshape(-1)\n",
    "    b_values = values.reshape(-1)\n",
    "\n",
    "    #NOTE: randomize the batch to break correlation\n",
    "    batch_size = M * N\n",
    "    mini_batch_size = batch_size // MINI_BATCH_COUNT\n",
    "    b_indicies = np.arange(batch_size)\n",
    "    clip_fracs = []\n",
    "    \n",
    "    for epoch in range(UPDATE_EPOCHS):\n",
    "        np.random.shuffle(b_indicies)\n",
    "\n",
    "        #NOTE: mini-batch update: \n",
    "        # pros: reduce memory usage, faster updates\n",
    "        # pros: a whole batch may stuck in local minima, mini batches introduce randomness\n",
    "        # cons: estimate a true gradient, larger mini batch size --> more accurate but more memory\n",
    "        for start in range(0, batch_size, mini_batch_size):\n",
    "            end = start + mini_batch_size\n",
    "            mini_indicies = b_indicies[start:end]\n",
    "\n",
    "            _, new_log_prob, entropy, new_value = agent.get_action_and_value(b_obs[mini_indicies], b_actions[mini_indicies])\n",
    "\n",
    "            #NOTE: what formula is this? \n",
    "            log_ratio = new_log_prob - b_log_probs[mini_indicies]\n",
    "\n",
    "            ratio = log_ratio.exp() # trick to remove log\n",
    "\n",
    "            #compute approximate KL: http://joschu.net/blog/kl-approx.html\n",
    "            with torch.no_grad():\n",
    "                old_approx_kd = (-log_ratio).mean()\n",
    "                approximate_kl = ((ratio - 1) - log_ratio).mean()\n",
    "                clip_fracs += [((ratio - 1.0).abs() > CLIP_COEF).float().mean().item()]\n",
    "\n",
    "            mb_advantages = b_advantages[mini_indicies]\n",
    "\n",
    "            #normalize advantage\n",
    "            mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "            #policy loss (actor)\n",
    "\n",
    "            pg_loss1 = -mb_advantages * ratio\n",
    "            pg_loss2= -mb_advantages * torch.clamp(ratio, 1 - CLIP_COEF, 1 + CLIP_COEF)\n",
    "\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "            new_value = new_value.view(-1)\n",
    "\n",
    "            #value loss (MSE)\n",
    "            v_loss = 0.5 * ((new_value - b_returns[mini_indicies]) ** 2).mean()\n",
    "\n",
    "            entropy_loss = entropy.mean()\n",
    "\n",
    "            loss = pg_loss - ENTROPY_COEF * entropy_loss + v_loss * VF_COEF\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #clip grad\n",
    "            nn.utils.clip_grad_norm_(agent.parameters(), MAX_GRAD_NORM)\n",
    "            optimizer.step()\n",
    "    \n",
    "evaluation = np.mean(evaluate(agent))\n",
    "print('evaluation = ', np.mean(evaluation))\n",
    "torch.save(agent, os.path.join(SAVE_PATH, 'ppo.final.torch'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268.0151\n",
      "266.8834\n",
      "260.6238\n",
      "75.81549\n",
      "267.05634\n",
      "263.5786\n",
      "266.1446\n",
      "258.57123\n",
      "263.439\n",
      "-70.78032\n"
     ]
    }
   ],
   "source": [
    "next_obs, _ = envs.reset()\n",
    "total_rewards = []\n",
    "episodes = 10\n",
    "\n",
    "while len(total_rewards) < episodes: \n",
    "    next_obs = torch.Tensor(next_obs)\n",
    "    with torch.no_grad():\n",
    "        action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "\n",
    "    next_obs, reward, terminated, truncated, info = envs.step(action.numpy())\n",
    "\n",
    "    if 'final_info' in info:\n",
    "        for data in info['final_info']:\n",
    "            if data:\n",
    "                reward = data['episode']['r'][0]\n",
    "                print(reward)\n",
    "                total_rewards.append(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function AsyncVectorEnv.__del__ at 0x132e0e310>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/vector/async_vector_env.py\", line 546, in __del__\n",
      "    self.close(terminate=True)\n",
      "  File \"/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/vector/vector_env.py\", line 265, in close\n",
      "    self.close_extras(**kwargs)\n",
      "  File \"/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/vector/async_vector_env.py\", line 461, in close_extras\n",
      "    function(timeout)\n",
      "  File \"/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/vector/async_vector_env.py\", line 321, in step_wait\n",
      "    obs, rew, terminated, truncated, info = result\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.542747\n",
      "307.70154\n",
      "304.33347\n",
      "-23.915497\n",
      "305.6151\n",
      "304.5836\n",
      "302.65884\n",
      "303.71445\n",
      "305.96878\n",
      "303.6156\n"
     ]
    }
   ],
   "source": [
    "ENV_ARGS['render_mode'] = 'human'\n",
    "envs1 = gym.vector.AsyncVectorEnv(\n",
    "    [lambda : make_env(gamma= 0.99, **ENV_ARGS) for _ in range(NUM_ENVS)]\n",
    ") \n",
    "\n",
    "next_obs, _ = envs1.reset()\n",
    "total_rewards = []\n",
    "episodes = 10\n",
    "\n",
    "while len(total_rewards) < episodes: \n",
    "    next_obs = torch.Tensor(next_obs)\n",
    "    with torch.no_grad():\n",
    "        action, log_prob, _, value = agent.get_action_and_value(next_obs)\n",
    "\n",
    "    next_obs, reward, terminated, truncated, info = envs1.step(action.numpy())\n",
    "\n",
    "    if 'final_info' in info:\n",
    "        for data in info['final_info']:\n",
    "            if data:\n",
    "                reward = data['episode']['r'][0]\n",
    "                print(reward)\n",
    "                total_rewards.append(reward)\n",
    "    \n",
    "del ENV_ARGS['render_mode']\n",
    "envs1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

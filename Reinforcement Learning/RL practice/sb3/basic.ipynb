{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecVideoRecorder, VecNormalize\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if os.path.exists('output') == False:\n",
    "    os.makedirs('output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for printing rewards during training\n",
    "    \"\"\"\n",
    "    def __init__(self, print_freq=1000, verbose=0):\n",
    "        super(RewardCallback, self).__init__(verbose)\n",
    "        self.print_freq = print_freq\n",
    "        self.episode_rewards = []\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        # Get the current episode rewards for all environments\n",
    "        for info in self.locals['infos']:\n",
    "            if 'episode' in info:\n",
    "                self.episode_rewards.append(info['episode']['r'])\n",
    "                # Print the reward\n",
    "                print(f\"Step: {self.num_timesteps}, Episode Reward: {info['episode']['r']:.2f}\")\n",
    "                \n",
    "        # Print average reward every print_freq steps\n",
    "        if len(self.episode_rewards) > 0 and self.num_timesteps % self.print_freq == 0:\n",
    "            mean_reward = np.mean(self.episode_rewards)\n",
    "            print(f\"Step: {self.num_timesteps}, Mean Episode Reward: {mean_reward:.2f}\")\n",
    "            self.episode_rewards = []  # Reset the list\n",
    "            \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2974f3fe99b4fe7bcb4240f76c599e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 66, Episode Reward: -189.96\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 66, Episode Reward: -189.96\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 159, Episode Reward: -132.54\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 159, Episode Reward: -132.54\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 223, Episode Reward: -248.27\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 223, Episode Reward: -248.27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 313, Episode Reward: -526.03\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 313, Episode Reward: -526.03\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 376, Episode Reward: -518.89\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 376, Episode Reward: -518.89\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 479, Episode Reward: -607.13\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 479, Episode Reward: -607.13\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 574, Episode Reward: -539.82\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 574, Episode Reward: -539.82\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 693, Episode Reward: -264.19\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 693, Episode Reward: -264.19\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 770, Episode Reward: -362.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 770, Episode Reward: -362.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 876, Episode Reward: -141.80\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 876, Episode Reward: -141.80\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1000, Mean Episode Reward: -353.06\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1000, Mean Episode Reward: -353.06\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1072, Episode Reward: -200.66\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1072, Episode Reward: -200.66\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1164, Episode Reward: -355.38\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1164, Episode Reward: -355.38\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1374, Episode Reward: -248.84\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1374, Episode Reward: -248.84\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1468, Episode Reward: -425.10\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1468, Episode Reward: -425.10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1536, Episode Reward: -240.36\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1536, Episode Reward: -240.36\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1596, Episode Reward: -218.00\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1596, Episode Reward: -218.00\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1670, Episode Reward: -109.39\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1670, Episode Reward: -109.39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1758, Episode Reward: -107.90\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1758, Episode Reward: -107.90\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1840, Episode Reward: -210.55\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1840, Episode Reward: -210.55\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1938, Episode Reward: -128.09\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1938, Episode Reward: -128.09\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 1994, Episode Reward: -75.63\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 1994, Episode Reward: -75.63\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2000, Mean Episode Reward: -210.90\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2000, Mean Episode Reward: -210.90\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2070, Episode Reward: -167.91\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2070, Episode Reward: -167.91\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2140, Episode Reward: -155.58\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2140, Episode Reward: -155.58\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2196, Episode Reward: -47.32\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2196, Episode Reward: -47.32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2265, Episode Reward: 27.50\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2265, Episode Reward: 27.50\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2328, Episode Reward: -111.37\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2328, Episode Reward: -111.37\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2403, Episode Reward: -148.38\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2403, Episode Reward: -148.38\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2479, Episode Reward: -134.86\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2479, Episode Reward: -134.86\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2541, Episode Reward: -135.25\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2541, Episode Reward: -135.25\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2607, Episode Reward: -158.82\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2607, Episode Reward: -158.82\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2666, Episode Reward: -96.46\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2666, Episode Reward: -96.46\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2719, Episode Reward: -97.35\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2719, Episode Reward: -97.35\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2784, Episode Reward: -142.74\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2784, Episode Reward: -142.74\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2875, Episode Reward: -174.75\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2875, Episode Reward: -174.75\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 2962, Episode Reward: -120.50\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 2962, Episode Reward: -120.50\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3000, Mean Episode Reward: -118.84\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3000, Mean Episode Reward: -118.84\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3031, Episode Reward: -155.07\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3031, Episode Reward: -155.07\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3088, Episode Reward: -143.65\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3088, Episode Reward: -143.65\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3181, Episode Reward: -145.14\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3181, Episode Reward: -145.14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3273, Episode Reward: -140.20\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3273, Episode Reward: -140.20\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3362, Episode Reward: -158.23\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3362, Episode Reward: -158.23\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3427, Episode Reward: -169.89\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3427, Episode Reward: -169.89\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3497, Episode Reward: -138.79\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3497, Episode Reward: -138.79\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3600, Episode Reward: 32.74\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3600, Episode Reward: 32.74\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3688, Episode Reward: -182.15\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3688, Episode Reward: -182.15\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3766, Episode Reward: -173.65\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3766, Episode Reward: -173.65\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3843, Episode Reward: -278.29\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3843, Episode Reward: -278.29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 3916, Episode Reward: -165.98\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 3916, Episode Reward: -165.98\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 4000, Mean Episode Reward: -151.52\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 4000, Mean Episode Reward: -151.52\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 4001, Episode Reward: -156.42\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 4001, Episode Reward: -156.42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 4074, Episode Reward: 21.95\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 4074, Episode Reward: 21.95\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 4137, Episode Reward: -161.58\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 4137, Episode Reward: -161.58\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 4240, Episode Reward: 8.19\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 4240, Episode Reward: 8.19\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 4329, Episode Reward: -76.26\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 4329, Episode Reward: -76.26\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 4576, Episode Reward: 238.64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 4576, Episode Reward: 238.64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Step: 5000, Mean Episode Reward: -20.91\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Step: 5000, Mean Episode Reward: -20.91\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to /home/nguyen/Desktop/NLP_RNN/Reinforcement Learning/RL practice/sb3/output/lunarlander_dqn/dqn-agent-step-0-to-step-1000.mp4\n",
      "MoviePy - Building video /home/nguyen/Desktop/NLP_RNN/Reinforcement Learning/RL practice/sb3/output/lunarlander_dqn/dqn-agent-step-0-to-step-1000.mp4.\n",
      "MoviePy - Writing video /home/nguyen/Desktop/NLP_RNN/Reinforcement Learning/RL practice/sb3/output/lunarlander_dqn/dqn-agent-step-0-to-step-1000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /home/nguyen/Desktop/NLP_RNN/Reinforcement Learning/RL practice/sb3/output/lunarlander_dqn/dqn-agent-step-0-to-step-1000.mp4\n",
      "mean reward:-136.58 +/- 82.16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "env_id = \"LunarLander-v3\"\n",
    "num_cpu =  1 # Number of processes to use\n",
    "# Create the vectorized environment\n",
    "\n",
    "# Stable Baselines provides you with make_vec_env() helper\n",
    "# which does exactly the previous steps for you.\n",
    "# You can choose between `DummyVecEnv` (usually faster) and `SubprocVecEnv`\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, seed=0, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "model = DQN(\"MlpPolicy\", vec_env, device = device)\n",
    "model.learn(\n",
    "    total_timesteps=5e3, \n",
    "    progress_bar=True,\n",
    "    callback=RewardCallback(1000),\n",
    "    )\n",
    "\n",
    "model.save(\"lunar_dqn\")\n",
    "\n",
    "vec_env.close()\n",
    "\n",
    "model.load(\"lunar_dqn\")\n",
    "env = make_vec_env(env_id, n_envs=1, seed=0)\n",
    "#wrap env to record video\n",
    "env = VecVideoRecorder(\n",
    "    env, \n",
    "    \"output/lunarlander_dqn\", \n",
    "    record_video_trigger=lambda x: x % 1000 == 0, \n",
    "    video_length=1000, \n",
    "    name_prefix=\"dqn-agent\")\n",
    "\n",
    "mean, std = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "print(f\"mean reward:{mean:.2f} +/- {std:.2f}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Mujoco Cheetah-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen/Desktop/NLP_RNN/Reinforcement Learning/.env/lib/python3.11/site-packages/gymnasium/envs/registration.py:517: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfa189df9684f2896e9b631adbf4d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen/Desktop/NLP_RNN/Reinforcement Learning/.env/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen/Desktop/NLP_RNN/Reinforcement Learning/.env/lib/python3.11/site-packages/gymnasium/envs/registration.py:517: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:1722.30 +/- 17.64\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "env_id = \"HalfCheetah-v4\"\n",
    "num_cpu = 4\n",
    "vec_env = make_vec_env(env_id, n_envs=num_cpu, seed=0)\n",
    "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True, clip_obs = 10.0)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", vec_env, device = device)\n",
    "\n",
    "model.learn(total_timesteps=1e6, progress_bar=True, log_interval=10)\n",
    "\n",
    "model.save(\"output/halfcheetah_ppo\")\n",
    "vec_env.save(\"output/halfcheetah_ppo_env\")\n",
    "vec_env.close()\n",
    "\n",
    "# Load the trained agent and normalized env\n",
    "del vec_env\n",
    "\n",
    "vec_env = make_vec_env(env_id, n_envs=1)\n",
    "vec_env = VecNormalize.load(\"output/halfcheetah_ppo_env\", vec_env)\n",
    "\n",
    "vec_env.training = False\n",
    "vec_env.norm_reward = False\n",
    "\n",
    "model = PPO.load(\"output/halfcheetah_ppo\", env=vec_env)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=10)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "vec_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

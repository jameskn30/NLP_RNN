{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import time\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs available: 1\n",
      "Current device: 0\n",
      "GPU 0: NVIDIA GeForce RTX 3060\n",
      "Memory allocated: 0.00 GB\n",
      "Memory reserved: 0.00 GB\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "\n",
    "# Get the number of available GPUs\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {gpu_count}\")\n",
    "\n",
    "# Get current device information\n",
    "if cuda_available:\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(f\"Current device: {current_device}\")\n",
    "    \n",
    "    # Print information for each available GPU\n",
    "    for i in range(gpu_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Memory allocated: {torch.cuda.memory_allocated(i) / 1e9:.2f} GB\")\n",
    "        print(f\"Memory reserved: {torch.cuda.memory_reserved(i) / 1e9:.2f} GB\")\n",
    "        print(\"-\" * 40)\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_env(name = 'LunarLander-v3', record_name = None):\n",
    "    # Delete all contents in lunar-agent folder\n",
    "\n",
    "    # Initialise the environment\n",
    "    env = gym.make(name, render_mode=\"rgb_array\")\n",
    "\n",
    "    if record_name != None and record_name != \"\":\n",
    "        if os.path.exists(record_name):\n",
    "            shutil.rmtree(record_name)\n",
    "\n",
    "        env = RecordVideo(\n",
    "            env,\n",
    "            video_folder=record_name,\n",
    "            episode_trigger=lambda x: True,  # Record every episode\n",
    "            name_prefix=\"training\",\n",
    "            video_length=3000,  # Maximum number of steps to record per episode\n",
    "        )\n",
    "\n",
    "    return env\n",
    "\n",
    "env = build_env()\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in range(1000):\n",
    "    # this is where you would insert your policy\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # step (transition) through the environment with the action\n",
    "    # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO\n",
    "\n",
    "in value based, we use value function (Qnet, Q-table) to estimate the policy\n",
    "\n",
    "policy-based directly optimize the policy function without using intermediate value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "-1.0543193817138672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31325/800881004.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensor = torch.tensor(state, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, state_size = 8, hidden_size = 16, action_size = 4):\n",
    "        super(Policy, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(8, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, action_size),\n",
    "            nn.Softmax(dim=1) #turn output into probability distribution\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def act(self, state):\n",
    "        tensor = torch.tensor(state, dtype=torch.float32)\n",
    "        probs = self.forward(tensor)\n",
    "        m = torch.distributions.Categorical(probs)\n",
    "        action = m.sample()\n",
    "        return action.item(), m.log_prob(action)\n",
    "\n",
    "# Test\n",
    "model = Policy()\n",
    "\n",
    "state = torch.rand(1, 8)\n",
    "\n",
    "action, log_prob = model.act(state)\n",
    "print(action)\n",
    "print(log_prob.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "policy = Policy()\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-2)\n",
    "gamma = 0.99\n",
    "num_episodes = 1000\n",
    "reward_threshold = 200\n",
    "print_every = 10\n",
    "total_steps = 1000\n",
    "\n",
    "env = build_env()\n",
    "\n",
    "for i in range(total_steps):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

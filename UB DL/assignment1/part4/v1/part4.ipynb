{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords =  {'hers', 'over', 'than', 'against', 'again', 'd', 'below', 'before', \"wouldn't\", 'on', \"you've\", 'whom', 'will', 'about', 'for', 'of', \"couldn't\", 'is', 'were', 'when', 'the', \"wasn't\", 'couldn', \"mightn't\", \"shouldn't\", 'does', 'down', 'any', \"needn't\", 'between', 'here', 'both', 'your', 'there', 'nor', 'are', 'm', \"you'll\", 'isn', 'himself', 'because', 'very', 'won', \"didn't\", 'most', 'only', 'her', 'just', 'did', 'haven', 'under', 'above', 'mustn', 'you', 'as', 'that', 'me', 'until', \"shan't\", 'into', 'shouldn', 'didn', 'we', 'their', 'all', 'having', \"hasn't\", 'those', \"that'll\", 'have', \"don't\", 'shan', 'while', 'then', 'to', 'so', 'where', 'now', 'further', 'and', 'being', 'after', 'doesn', 'been', \"mustn't\", 'wouldn', 'my', 'i', 'yourselves', 'such', 'a', 'themselves', 'o', 'our', 'herself', 'once', 'it', 'other', 'am', 're', 'needn', 'll', 'yours', 'she', 'don', 'this', \"you'd\", 'no', 've', 'with', 'had', 'hasn', 'ain', 'out', 'from', 'what', 'he', 'off', \"hadn't\", 'ours', 'during', \"weren't\", 'same', 'too', \"doesn't\", 't', \"it's\", 'by', \"won't\", 'him', 'myself', \"she's\", 'own', 'mightn', \"should've\", \"you're\", 'up', 'not', 'an', 'do', 'some', 'weren', 'them', 'which', 'through', 'in', 'was', 'has', 's', \"isn't\", 'why', 'these', 'ourselves', 'wasn', 'who', 'how', 'yourself', \"aren't\", 'they', 'should', 'at', 'theirs', 'ma', 'doing', 'or', \"haven't\", 'if', 'aren', 'few', 'more', 'itself', 'be', 'y', 'his', 'can', 'hadn', 'but', 'its', 'each'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "print('stopwords = ', STOPWORDS)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import training\n",
    "\n",
    "import logging \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:created trainer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<utils.training.Trainer object at 0x000001AAA26C71C0>\n"
     ]
    }
   ],
   "source": [
    "print(training.Trainer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "data_path = os.path.join(root, 'dataset', 'processed_amazon_reviews.csv')\n",
    "assert os.path.exists(data_path), f'data path does not exist {data_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999812, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>more like funchuck Gave this to my dad for a g...</td>\n",
       "      <td>like funchuck gave dad gag gift directing nuns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Inspiring I hope a lot of people hear this cd....</td>\n",
       "      <td>inspiring hope lot people hear cd need strong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>The best soundtrack ever to anything. I'm read...</td>\n",
       "      <td>best soundtrack ever anything im reading lot r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Chrono Cross OST The music of Yasunori Misuda ...</td>\n",
       "      <td>chrono cross ost music yasunori misuda without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Too good to be true Probably the greatest soun...</td>\n",
       "      <td>good true probably greatest soundtrack history...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review                                               text  \\\n",
       "0       3  more like funchuck Gave this to my dad for a g...   \n",
       "1       5  Inspiring I hope a lot of people hear this cd....   \n",
       "2       5  The best soundtrack ever to anything. I'm read...   \n",
       "3       4  Chrono Cross OST The music of Yasunori Misuda ...   \n",
       "4       5  Too good to be true Probably the greatest soun...   \n",
       "\n",
       "                                              tokens  \n",
       "0  like funchuck gave dad gag gift directing nuns...  \n",
       "1  inspiring hope lot people hear cd need strong ...  \n",
       "2  best soundtrack ever anything im reading lot r...  \n",
       "3  chrono cross ost music yasunori misuda without...  \n",
       "4  good true probably greatest soundtrack history...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>like funchuck gave dad gag gift directing nuns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>inspiring hope lot people hear cd need strong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>best soundtrack ever anything im reading lot r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>chrono cross ost music yasunori misuda without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>good true probably greatest soundtrack history...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review                                             tokens\n",
       "0       3  like funchuck gave dad gag gift directing nuns...\n",
       "1       5  inspiring hope lot people hear cd need strong ...\n",
       "2       5  best soundtrack ever anything im reading lot r...\n",
       "3       4  chrono cross ost music yasunori misuda without...\n",
       "4       5  good true probably greatest soundtrack history..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('text', axis = 1, inplace = True)\n",
    "# df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2999812, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>like funchuck gave dad gag gift directing nuns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>inspiring hope lot people hear cd need strong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>best soundtrack ever anything im reading lot r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>chrono cross ost music yasunori misuda without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>good true probably greatest soundtrack history...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review                                             tokens\n",
       "0       3  like funchuck gave dad gag gift directing nuns...\n",
       "1       5  inspiring hope lot people hear cd need strong ...\n",
       "2       5  best soundtrack ever anything im reading lot r...\n",
       "3       4  chrono cross ost music yasunori misuda without...\n",
       "4       5  good true probably greatest soundtrack history..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df[:10000].copy()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = train_df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like funchuck gave dad gag gift directing nunsense got reall kick'\n",
      " 'inspiring hope lot people hear cd need strong positive vibes like great vocals fresh tunes crosscultural happiness blues gut pop sounds catchy mature'\n",
      " 'best soundtrack ever anything im reading lot reviews saying best game soundtrack figured id write review disagree bit opinino yasunori mitsudas ultimate masterpiece music timeless im listening years beauty simply refuses fadethe price tag pretty staggering must say going buy cd much money one feel would worth every penny'\n",
      " 'chrono cross ost music yasunori misuda without question close second great nobuo uematsuchrono cross ost wonderful creation filled rich orchestra synthesized sounds ambiance one musics major factors yet times uplifting vigorous favourite tracks include scars left time girl stole stars another world'\n",
      " 'good true probably greatest soundtrack history usually better played game first enjoyable anyway worked hard getting soundtrack spending money get really worth every penny get ost amazing first tracks dancing around delight especially scars left time buy'\n",
      " 'theres reason price theres reason cd expensive even version thats importsome best music ever could listen every track every minute every day thats say'\n",
      " 'buyer beware selfpublished book want know whyread paragraphs 5 star reviews must written ms haddons family friendsor perhaps cant imagine anyone reading whole thingi spent evening book friend hysterics reading bits pieces one another definitely bad enough entered kind worst book contest cant believe amazon even sells kind thing maybe offer 8th grade term paper kill mockingbirda book quite sure ms haddon never heard anyway unless mood send book someone jokestay far far away one'\n",
      " 'errors great story dissapointed see errors back cover since paid book read anyway say love couldnt put read whole book two hours say buy say read sad gives interesting point view church today spend much time looking faults others also enjoyed belovedsincerlyjaylynn r'\n",
      " 'worst complete waste time typographical errors poor grammar totally pathetic plot add absolutely nothing im embarrassed author disappointed actually paid book'\n",
      " 'oh please guess romance novel lover one discerning one others beware absolute drivel figured trouble typo prominently featured back cover first page book removed doubt wait maybe im missing point quick reread beginning makes clear intentional churning overheated prose satiric purposes phew glad didnt waste 1095']\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "tokens = train_df['tokens'].values\n",
    "print(tokens[:10])\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length =  39914\n",
      "built the vocab, len =  39916\n"
     ]
    }
   ],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, token_list, \n",
    "                 min_freq = 0) -> None:\n",
    "        '''\n",
    "        @params\n",
    "            tokens_col: list, 2D list. each row of token is a list of tokens seperated by comma,\n",
    "                        eg: a,bc,d,...\n",
    "        '''\n",
    "        special_tokens = ['<pad>', '<unk>']\n",
    "        self.unk = '<unk>'\n",
    "        self.pad = '<pad>'\n",
    "\n",
    "        #buil corpus from tokens\n",
    "        self.corpus = Counter()\n",
    "\n",
    "        for row in token_list:\n",
    "            tokens = row.split(' ')\n",
    "            self.corpus.update(tokens)\n",
    "        \n",
    "        print('corpus length = ', len(self.corpus))\n",
    "\n",
    "        # with open('corpus.txt', 'w') as file:\n",
    "        #     json.dump(self.corpus.most_common(), file)\n",
    "\n",
    "        #build vocab from tokens\n",
    "        self._token_to_idx = {}\n",
    "        self._idx_to_token = {}\n",
    "\n",
    "        for i, t in enumerate(special_tokens):\n",
    "            self._token_to_idx[t] = i\n",
    "            self._idx_to_token[i] = t\n",
    "\n",
    "\n",
    "        for k, freq in self.corpus.most_common():\n",
    "            if  freq >= min_freq:\n",
    "                idx =  len(self._token_to_idx)\n",
    "                self._token_to_idx[k] = idx\n",
    "                self._idx_to_token[idx] = k\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(\"built the vocab, len = \", len(self._token_to_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "    \n",
    "    \n",
    "    def get_index(self, tokens):\n",
    "        '''\n",
    "        @params:\n",
    "            tokens: list[str], list of tokens, eg: ('a', 'b', 'c')\n",
    "        @return:\n",
    "            res: list[int], list of int\n",
    "        '''\n",
    "        assert isinstance(tokens, list), 'tokens must be list of tokens, eg: [\"a\", \"b\", \"c\", ..]'\n",
    "\n",
    "        res = []\n",
    "        for token in tokens:\n",
    "            if token in self._token_to_idx:\n",
    "                res.append(self._token_to_idx[token])\n",
    "            else:\n",
    "                res.append(self._token_to_idx[self.unk])\n",
    "        return res\n",
    "    \n",
    "    def get_tokens(self, indices):\n",
    "        assert isinstance(indices, list), 'indices must be list of index, eg: [1,2,3, ..]'\n",
    "        res = []\n",
    "        for index in indices:\n",
    "            if index in self._idx_to_token:\n",
    "                res.append(self._idx_to_token[index])\n",
    "            else:\n",
    "                unk_idx = self._token_to_idx[self.unk]\n",
    "                res.append(self._idx_to_token[unk_idx])\n",
    "        return res\n",
    "\n",
    "    \n",
    "vocab = Vocab(train_df['tokens'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens to idx, len = 39916\n",
      "idx to tokens, len = 39916\n"
     ]
    }
   ],
   "source": [
    "print(f'tokens to idx, len = {len(vocab._token_to_idx)}')\n",
    "print(f'idx to tokens, len = {len(vocab._idx_to_token)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'funchuck', 'gave', 'dad', 'gag', 'gift', 'directing', 'nunsense', 'got', 'reall', 'kick']\n",
      "[5, 17002, 238, 2105, 6483, 462, 3434, 17003, 44, 12194, 2890]\n",
      "[77, 1, 1, 4]\n",
      "['like', '<unk>', 'gave', 'dad', 'gag', 'gift', 'directing', '<unk>', 'got', '<unk>', 'kick']\n"
     ]
    }
   ],
   "source": [
    "tokens = train_df.iloc[0]['tokens'].split(' ')\n",
    "print(tokens)\n",
    "\n",
    "res = vocab.get_index(tokens)\n",
    "print(res)\n",
    "\n",
    "res = vocab.get_index('something here is good'.split(' '))\n",
    "print(res)\n",
    "\n",
    "res = vocab.get_tokens([5, 1, 238, 2105, 6483, 462, 3434, 1, 44, 1, 2890])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>like funchuck gave dad gag gift directing nuns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>inspiring hope lot people hear cd need strong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>best soundtrack ever anything im reading lot r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>chrono cross ost music yasunori misuda without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>good true probably greatest soundtrack history...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review                                             tokens\n",
       "0       3  like funchuck gave dad gag gift directing nuns...\n",
       "1       5  inspiring hope lot people hear cd need strong ...\n",
       "2       5  best soundtrack ever anything im reading lot r...\n",
       "3       4  chrono cross ost music yasunori misuda without...\n",
       "4       5  good true probably greatest soundtrack history..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape =  torch.Size([10000, 140])\n",
      "y train shape =  torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#Using vocab object to build the train dataset\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for row in train_df.iterrows():\n",
    "    review = row[1][0]\n",
    "    tokens = row[1][1].split(\" \")\n",
    "\n",
    "    #map reviews to good (4,5) or bad (1,2,3)\n",
    "    # review = 0 if review in (1,2,3) else 1\n",
    "\n",
    "    X_train.append(torch.tensor(vocab.get_index(tokens)))\n",
    "    y_train.append(torch.tensor(review))\n",
    "\n",
    "X_train = pad_sequence(X_train, batch_first= True, padding_value = vocab._token_to_idx[vocab.pad])\n",
    "print('X train shape = ',X_train.shape)\n",
    "y_train = torch.tensor(y_train)\n",
    "print('y train shape = ',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens =  tensor([    5, 17002,   238,  2105,  6483,   462,  3434, 17003,    44, 12194,\n",
      "         2890,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "labels =  tensor(3)\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(X_train, y_train):\n",
    "    print('tokens = ', x)\n",
    "    print('labels = ', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonReviewSentimentDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X =X \n",
    "        self.y =y \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset len =  10000\n",
      "train dataloader len =  313\n",
      "X shape =  torch.Size([32, 140])\n",
      "y shape =  torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AmazonReviewSentimentDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE)\n",
    "\n",
    "print('train dataset len = ', len(train_dataset))\n",
    "print('train dataloader len = ', len(train_dataloader))\n",
    "sampleX, sampleY = next(iter(train_dataloader))\n",
    "\n",
    "print('X shape = ', sampleX.shape)\n",
    "print('y shape = ', sampleY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif \"weight\" in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, vocab_size, hidden_size, embedding_size, num_layers, dropout = 0.3):\n",
    "        super().__init__()\n",
    "        # self.num_layers = num_layers\n",
    "        # self.vocab_size = vocab_size\n",
    "        # self.hidden_size = hidden_size\n",
    "        # self.num_steps = num_steps\n",
    "        # self.embedding_size = embedding_size\n",
    "        # self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(input_size = embedding_size, hidden_size = hidden_size,\\\n",
    "                             num_layers = num_layers, batch_first = True) \n",
    "\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "\n",
    "        self.dense = nn.LazyLinear(num_classes)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def init_state(self, batch):\n",
    "        hidden = torch.rand(self.num_layers, batch, self.hidden_size, dtype = torch.float32, device = X.device)\n",
    "        cell = torch.rand(self.num_layers, batch, self.hidden_size, dtype = torch.float32, device = X.device)\n",
    "        return (hidden, cell)\n",
    "\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "\n",
    "        embeds = self.embedding(X)\n",
    "\n",
    "        output, state = self.rnn(embeds, state)\n",
    "        output = self.dropout(output)\n",
    "        output = self.sigmoid(self.dense(output))\n",
    "\n",
    "        return output[:, -1], state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample x shape =  torch.Size([32, 140])\n",
      "sample Y shape =  torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m sampleY \u001b[38;5;241m=\u001b[39m sampleY\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample Y shape = \u001b[39m\u001b[38;5;124m\"\u001b[39m, sampleY\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 15\u001b[0m output,(hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampleX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     18\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'state'"
     ]
    }
   ],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device)\n",
    "device = 'cpu'\n",
    "\n",
    "test_model = SentimentRNN(num_classes= 1, vocab_size = len(vocab), hidden_size = 10, embedding_size=5, num_layers = 2)\n",
    "test_model.to(device)\n",
    "\n",
    "sampleX, sampleY = next(iter(train_dataloader))\n",
    "\n",
    "sampleX = sampleX.to(device)\n",
    "print(\"sample x shape = \", sampleX.shape)\n",
    "sampleY = sampleY.to(device)\n",
    "print(\"sample Y shape = \", sampleY.shape)\n",
    "\n",
    "output,(hidden, cell) = test_model(sampleX)\n",
    "print(output.shape)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "loss = loss_fn(output.squeeze(-1), sampleY.float())\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning on \u001b[39m\u001b[38;5;124m'\u001b[39m, device)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m SentimentRNN(num_classes\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocab), hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, embedding_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m, num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      9\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('running on ', device)\n",
    "\n",
    "\n",
    "model = SentimentRNN(num_classes= 5, vocab_size = len(vocab), hidden_size = 500, embedding_size= 400, num_layers = 2)\n",
    "model.to(device)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "grad_clip = 5\n",
    "\n",
    "for e in range(10):\n",
    "    state = None\n",
    "    running_loss = 0.0\n",
    "    loop = tqdm(train_dataloader)\n",
    "    state = None\n",
    "    for X,y in loop:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        batch, step = X.shape\n",
    "        if state == None or state[0].shape[0] != batch:\n",
    "            state = model.init_state(batch)\n",
    "        else:\n",
    "            state = (state[0].data, state[1].data)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        outputs, state = model(X, state)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), grad_clip)\n",
    "        optim.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loop.set_description(f'epoch = {e}, loss = {running_loss:.5f}')\n",
    "        break\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

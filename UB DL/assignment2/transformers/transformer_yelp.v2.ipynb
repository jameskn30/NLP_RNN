{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import re\n",
    "import contractions\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import math\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, random_split \n",
    "from torch import nn\n",
    "import torch \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('device = ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install contractions\n",
    "# !pip install torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "#yelp polarity has 2 labels, \n",
    "#yelp dataset has 5 labels, they have the same text content\n",
    "train_datapath = os.path.join(root, 'dataset', 'yelp_polarity', 'train.csv') \n",
    "test_datapath = os.path.join(root,  'dataset', 'yelp_polarity', 'test.csv') \n",
    "\n",
    "assert os.path.exists(train_datapath),  f\"train dataset path {train_datapath} not found\"\n",
    "assert os.path.exists(test_datapath),   f\"test dataset path {test_datapath} not found\"\n",
    "\n",
    "sample_size = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am only give it two stars because they did h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's been a long time since I was lured to thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Rip-off artists.\\n\\n I only used them cuz they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>YUM!  Finally, a place we like.  This place is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This place has the location down, that's for s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review                                               text\n",
       "0       1  I am only give it two stars because they did h...\n",
       "1       1  It's been a long time since I was lured to thi...\n",
       "2       1  Rip-off artists.\\n\\n I only used them cuz they...\n",
       "3       2  YUM!  Finally, a place we like.  This place is...\n",
       "4       1  This place has the location down, that's for s..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_datapath, names = [\"review\",\"text\"])\n",
    "train_df = train_df.sample(frac = sample_size)\n",
    "print(train_df.shape)\n",
    "train_df.reset_index(inplace=True, drop = True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test string special characters punctuations _'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Text\n",
    "\n",
    "def remove_urls(text):\n",
    "    #if there's link in text, like www.something.com, https://www.something.com,\n",
    "    # replace it with the <url> token\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = pattern.sub(' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub(\"\\d\", ' ', text)\n",
    "\n",
    "def remove_punctation(text):\n",
    "    return re.sub(r'[^\\w\\s]',' ',text)\n",
    "\n",
    "def expand_contraction(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split(' ') if word not in STOPWORDS])\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    extract feature and label from line and process the text\n",
    "    @params:\n",
    "        text: string, format: __label__2 some text.\n",
    "    @return:\n",
    "        feature: string\n",
    "        label: int, 0: bad review, 1 good review\n",
    "    '''\n",
    "    #Each line has format: __label__2 some text.\n",
    "    #The first part is label, the rest is text feature\n",
    "    #lower case the features\n",
    "    text = text.lower()\n",
    "    #start cleaning\n",
    "\n",
    "    #remove urls in text\n",
    "    text = remove_urls(text)\n",
    "    #remove digits\n",
    "    text = remove_digits(text)\n",
    "    # # #expand contractions\n",
    "    text = expand_contraction(text)\n",
    "    # # #remove punctuations\n",
    "    text = remove_punctation(text)\n",
    "    # # #remove stop words\n",
    "    text = remove_stopwords(text)\n",
    "\n",
    "    #after cleaning, there's a letter n that occur most frequently\n",
    "    #this don't make sense so remove a standalone letter n\n",
    "    text = ' '.join(t for t in text.split() if t != '' and t != 'n')\n",
    "    return text.strip()\n",
    "\n",
    "test_string = '''This is a test string. Here are some special characters: &,#,$. How about some punctuations? !@#$%^&*()_+=-`~{[]}|:;'<,>.?/\"|https://www.example.com'''\n",
    "\n",
    "clean_text(test_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>give two stars good guacamole rest food would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>long time since lured place sweet location ayc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rip artists used cuz cheaper dental plan aetna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>yum finally place like place really clean pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>place location sure food terrible ingredients ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review                                               text\n",
       "0       1  give two stars good guacamole rest food would ...\n",
       "1       1  long time since lured place sweet location ayc...\n",
       "2       1  rip artists used cuz cheaper dental plan aetna...\n",
       "3       2  yum finally place like place really clean pret...\n",
       "4       1  place location sure food terrible ingredients ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_df = train_df.copy()\n",
    "eda_df['text'] = eda_df['text'].apply(lambda s: clean_text(s))\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A little EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent words\n",
      "[('food', 164930), ('place', 161067), ('good', 150570), ('would', 139053), ('like', 131241), ('get', 118390), ('one', 118292), ('time', 108493), ('great', 105250), ('service', 104214)]\n"
     ]
    }
   ],
   "source": [
    "# wordcloud of common words\n",
    "freq = collections.Counter()\n",
    "\n",
    "for row in eda_df.iterrows():\n",
    "    label, text = row[1]\n",
    "    freq.update(text.split())\n",
    "\n",
    "print('most frequent words')\n",
    "print(freq.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bad_reviews = eda_df.loc[eda_df['review'] == 1]['text'].apply(lambda s: len(s)).values\n",
    "good_reviews = eda_df.loc[eda_df['review'] == 2]['text'].apply(lambda s: len(s)).values\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "sns.histplot(x = bad_reviews, label = 'bad reviews', ax = ax1)\n",
    "ax1.set_title('bad reviews')\n",
    "sns.histplot(x = good_reviews, label = 'good reviews', ax = ax2)\n",
    "ax2.set_title('good reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review\n",
      "2    140222\n",
      "1    139778\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(eda_df['review'].value_counts())\n",
    "sns.countplot(x = eda_df['review'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "\n",
    "def build_array(X, maxlength = 256):\n",
    "    X_tokens = []\n",
    "    X_lengths = []\n",
    "    for text in tqdm(X):\n",
    "        tokens = tokenizer(text)[:maxlength]\n",
    "        X_tokens.append(tokens)\n",
    "        X_lengths.append(len(tokens))\n",
    "\n",
    "    return X_tokens, X_lengths\n",
    "\n",
    "\n",
    "def get_ids(tokens, vocab):\n",
    "    ids = vocab.lookup_indices(tokens)\n",
    "    return torch.tensor(ids)\n",
    "\n",
    "def build_train_test_data(feature_train, label_train, min_vocab_freq = 5, **kwargs):\n",
    "    train_tokens, train_lengths = build_array(feature_train)\n",
    "\n",
    "    unk_token = '<unk>'\n",
    "    pad_token = '<pad>'\n",
    "    special_tokens = [unk_token, pad_token]\n",
    "\n",
    "    vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "        train_tokens,\n",
    "        min_freq=min_vocab_freq,\n",
    "        specials=special_tokens,\n",
    "    )\n",
    "\n",
    "    unk_id = vocab[unk_token]\n",
    "    pad_id = vocab[unk_token]\n",
    "\n",
    "    vocab.set_default_index(unk_id)\n",
    "\n",
    "    print('vocab len = ', len(vocab))\n",
    "\n",
    "    def convert_to_ids_labels_lengths(token_list, labels, lengths):\n",
    "        id_list = []\n",
    "\n",
    "        for tokens in tqdm(token_list):\n",
    "            ids = get_ids(tokens, vocab)\n",
    "            id_list.append(ids)\n",
    "\n",
    "        #convert y to tensor\n",
    "        labels = torch.tensor([0 if label == 1 else 1 for label in labels])\n",
    "        #convert X lengths to tensor\n",
    "        lengths = torch.tensor(lengths)\n",
    "\n",
    "        return id_list, labels, lengths\n",
    "\n",
    "    train_ids, train_y, train_lengths = convert_to_ids_labels_lengths(train_tokens, label_train, train_lengths)\n",
    "\n",
    "    return (train_tokens, train_ids, train_y, train_lengths), vocab, pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280000/280000 [00:09<00:00, 28407.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len =  46657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280000/280000 [00:07<00:00, 35921.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids shape =  torch.Size([280000, 256])\n",
      "y shape =  torch.Size([280000])\n",
      "lengths shape =  torch.Size([280000])\n"
     ]
    }
   ],
   "source": [
    "X_array = train_df['text'].apply(lambda s: clean_text(s)).values\n",
    "y_array = train_df['review'].values\n",
    "\n",
    "(train_tokens, train_ids, train_y, train_lengths), vocab, pad_id = build_train_test_data(X_array, y_array)\n",
    "\n",
    "train_ids = pad_sequence(train_ids, batch_first=True, padding_value=pad_id)\n",
    "\n",
    "print('ids shape = ', train_ids.shape )\n",
    "print('y shape = ', train_y.shape )\n",
    "print('lengths shape = ', train_lengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=0\n",
      "tokens=['give', 'two', 'stars', 'good', 'guacamole', 'rest', 'food', 'would', 'get', 'star', 'ni', 'thought', 'impossible', 'mess', 'tacos', 'bland', 'even', 'drown', 'salsa', 'try', 'help', 'even', 'work', 'ni', 'zero', 'plans', 'go', 'back', 'eat', 'would', 'maybe', 'drinks', 'guacamole']\n",
      "length=33\n",
      "ids=tensor([  77,   40,  134,    4, 1257,  485,    2,    5,    7,  199,   19,  147,\n",
      "        1959,  938,  406,  413,   16, 7625,  497,   42,  305,   16,  116,   19,\n",
      "        1184, 2884,   13,   12,   74,    5,  173,   97, 1257,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n",
      "vocab len =  46657\n"
     ]
    }
   ],
   "source": [
    "for label, token, id, length in zip(train_y[:1], train_tokens[:1], train_ids[:1], train_lengths[:1]):\n",
    "    print(f'label={label}\\ntokens={token}\\nlength={length}\\nids={id}')\n",
    "\n",
    "print('vocab len = ', len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, num_hiddens: int, dropout:float = 0, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        assert num_hiddens % 2 == 0, f'num hiddens ({num_hiddens}),has to be even'\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        x = torch.arange(max_len).float().unsqueeze(1)\n",
    "        #N = 10000 as defined in the Attention is All You Need paper\n",
    "        denom = torch.pow(10000, torch.arange(0, num_hiddens,2).float()/num_hiddens)\n",
    "        x = x/denom\n",
    "        self.P[:,:,0::2] = torch.sin(x)\n",
    "        self.P[:,:,1::2] = torch.cos(x)\n",
    "\n",
    "        # self.P = self.P.to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # assert x.device == self.P.device, 'in positional encoding, X should have the same device with P'\n",
    "        batch_size, length, num_hiddens = x.shape\n",
    "        x = x + self.P[:,:length,:].to(x.device)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_class, \n",
    "    num_heads, dim_fc, num_tokens, device,\n",
    "    dropout = 0.2, num_encoder_layers = 2, batch_first = True):\n",
    "\n",
    "        '''\n",
    "        @params:\n",
    "            input_size: input features or embedding size\n",
    "            num_heads: number of multi attentino heads \n",
    "            dim_fc:  dimension of feedforward layer\n",
    "            dropout: drop out rate\n",
    "            num_tokens: number of tokens in vocabulary (some call vocab_size)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(input_size, dropout)\n",
    "        self.encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model = input_size,\n",
    "            nhead = num_heads,\n",
    "            dim_feedforward= dim_fc,\n",
    "            dropout = dropout,\n",
    "            batch_first=batch_first,\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer=self.encoder_layers, num_layers = num_encoder_layers)\n",
    "        self.embedding = nn.Embedding(num_tokens, input_size)\n",
    "        self.input_size = input_size \n",
    "\n",
    "        self.fc = nn.Linear(input_size, num_class) \n",
    "\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "    \n",
    "    def forward(self, src, mask = None):\n",
    "        batch_size, input_len = src.shape\n",
    "        \n",
    "        src = self.embedding(src)\n",
    "        src = src * math.sqrt(self.input_size)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        if mask == None:\n",
    "            mask = nn.Transformer.generate_square_subsequent_mask(input_len).to(src.device)\n",
    "\n",
    "        transformer_output = self.encoder(src, mask)\n",
    "\n",
    "        # print('transformer output shape = ', transformer_output.shape)\n",
    "        output = self.fc(transformer_output[:,-1]) \n",
    "        # print('fc output shape = ', output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100 \n",
    "num_class = 2\n",
    "num_heads = 5\n",
    "fc_hidden_size = 5\n",
    "num_tokens = 1000\n",
    "    \n",
    "clf = TransformerClassifier(input_size, num_class, num_heads, fc_hidden_size, num_tokens, device = DEVICE)\n",
    "clf.to(DEVICE)\n",
    "# clf.convert_to_device(DEVICE)\n",
    "X = torch.randint(0,1000,(10,5)).to(DEVICE)\n",
    "\n",
    "y = clf(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num class =  2\n",
      "train dataset len =  224000\n",
      "train dataloader len =  7000\n",
      "val dataset len =  56000\n",
      "val dataloader len =  1750\n"
     ]
    }
   ],
   "source": [
    "class YelpReview(Dataset):\n",
    "\n",
    "    def __init__(self, ids, labels, lengths):\n",
    "        self.ids = ids\n",
    "        self.labels = labels\n",
    "        self.lengths = lengths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ids[idx], self.labels[idx], self.lengths[idx]\n",
    "\n",
    "NUM_CLASSES = len(set(list(train_y.tolist())))\n",
    "\n",
    "train_dataset = YelpReview(train_ids, train_y, train_lengths)\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_len = int(train_ratio * len(train_dataset))\n",
    "val_len = len(train_dataset) - train_len\n",
    "train_dataset, val_dataset = random_split(train_dataset,[train_len, val_len])\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
    "\n",
    "print('num class = ', NUM_CLASSES)\n",
    "print('train dataset len = ', len(train_dataset))\n",
    "print('train dataloader len = ', len(train_dataloader))\n",
    "print('val dataset len = ', len(val_dataset))\n",
    "print('val dataloader len = ', len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id shape =  torch.Size([32, 256])\n",
      "label shape =  torch.Size([32])\n",
      "lengths shape =  torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# test model running on dataloader\n",
    "\n",
    "(sample_ids, sample_y, sample_lengths) = next(iter(train_dataloader)) \n",
    "print('id shape = ', sample_ids.shape)\n",
    "print('label shape = ', sample_y.shape)\n",
    "print('lengths shape = ', sample_lengths.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy\n",
    "\n",
    "def train(dataloader, model, criterion, optimizer, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    for ids, label, length in tqdm(dataloader, desc=\"training...\"):\n",
    "        ids = ids.to(device)\n",
    "        label = label.to(device)\n",
    "        length = length\n",
    "        # prediction = model(ids, length)\n",
    "        prediction = model(ids)\n",
    "\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)\n",
    "\n",
    "        \n",
    "\n",
    "def evaluate(dataloader, model, criterion, device, earlyStopping):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    max_consecutive = 0\n",
    "    consecutive_count = 0\n",
    "    previous_number = float('inf')\n",
    "    \n",
    "    for ids, label, length in tqdm(dataloader, desc=\"evaluating...\"):\n",
    "        ids = ids.to(device)\n",
    "        length = length\n",
    "        label = label.to(device)\n",
    "        # prediction = model(ids, length)\n",
    "        prediction = model(ids)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "        if earlyStopping:\n",
    "            if loss < previous_number:\n",
    "                previous_number = loss\n",
    "                consecutive_count = 0\n",
    "            else:\n",
    "                consecutive_count += 1\n",
    "                max_consecutive = max(max_consecutive, consecutive_count)\n",
    "                if max_consecutive == 3:\n",
    "                    print(\"\\nStopping training as Validation Loss stopped improving.\")\n",
    "                break\n",
    "            \n",
    "        if earlyStopping:\n",
    "            if max_consecutive == 5:\n",
    "                break\n",
    "            \n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)\n",
    "\n",
    "def tune(model, optimizer, criterion, device, epochs = 10, earlyStopping=False):\n",
    "    print(f\"The model has {model.count_parameters()} trainable parameters\")\n",
    "\n",
    "    criterion = criterion.to(device)\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    history = []\n",
    "\n",
    "    history = collections.defaultdict(list)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(val_dataloader, model, criterion, device, earlyStopping)\n",
    "        # test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\n",
    "        history[\"train_losses\"].append(train_loss)\n",
    "        history[\"train_accs\"].append(train_acc)\n",
    "        history[\"valid_losses\"].append(val_loss)\n",
    "        history[\"valid_accs\"].append(val_acc)\n",
    "        # history[\"test_losses\"].append(test_loss)\n",
    "        # history[\"test_accs\"].append(test_acc)\n",
    "        # if test_loss < best_valid_loss:\n",
    "        #     best_valid_loss = test_loss\n",
    "        #     torch.save(model, f\"lstm.checkpoint.pt\")\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        print(f\"train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}\")\n",
    "        print(f\"val_loss: {val_loss:.3f}, valid_acc: {val_acc:.3f}\")\n",
    "        # print(f\"test_loss: {test_loss:.3f}, test_acc: {test_acc:.3f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "def plot(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\n",
    "    epochs = list(range(len(history['train_accs'])))\n",
    "    sns.lineplot(y = history[\"train_accs\"],   label ='train accuracy',  x = epochs, ax = ax1)\n",
    "    sns.lineplot(y = history[\"valid_accs\"],   label ='val accuracy',    x = epochs, ax = ax1)\n",
    "    # sns.lineplot(y = history[\"test_accs\"],  label ='test accuracy', x = epochs, ax = ax1)\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "\n",
    "    sns.lineplot(y = history[\"train_losses\"], label ='train loss', x = epochs, ax = ax2)\n",
    "    sns.lineplot(y = history[\"valid_losses\"],   label ='val loss', x = epochs, ax = ax2)\n",
    "    # sns.lineplot(y = history[\"test_losses\"],  label ='test loss', x = epochs, ax = ax2)\n",
    "    ax2.set_title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.GloVe()\n",
    "pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dim =  2\n",
      "The model has 15201194 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training...:   7%|▋         | 514/7000 [00:15<03:13, 33.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m     26\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearlyStopping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m plot(history)\n",
      "Cell \u001b[1;32mIn[17], line 77\u001b[0m, in \u001b[0;36mtune\u001b[1;34m(model, optimizer, criterion, device, epochs, earlyStopping)\u001b[0m\n\u001b[0;32m     74\u001b[0m history \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 77\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(val_dataloader, model, criterion, device, earlyStopping)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     17\u001b[0m length \u001b[38;5;241m=\u001b[39m length\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# prediction = model(ids, length)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(prediction, label)\n\u001b[0;32m     22\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m get_accuracy(prediction, label)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[13], line 77\u001b[0m, in \u001b[0;36mTransformerClassifier.forward\u001b[1;34m(self, src, mask)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     mask \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer\u001b[38;5;241m.\u001b[39mgenerate_square_subsequent_mask(input_len)\u001b[38;5;241m.\u001b[39mto(src\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 77\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# print('transformer output shape = ', transformer_output.shape)\u001b[39;00m\n\u001b[0;32m     80\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(transformer_output[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    303\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m make_causal\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 306\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    309\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:573\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    571\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 573\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:585\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[0;32m    580\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    581\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, x, x,\n\u001b[0;32m    582\u001b[0m                        attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[0;32m    583\u001b[0m                        key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[0;32m    584\u001b[0m                        need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 5e-4\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "output_dim = NUM_CLASSES\n",
    "print('output dim = ', output_dim)\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    input_size = embedding_dim,\n",
    "    num_class=  NUM_CLASSES,\n",
    "    num_heads = 5,\n",
    "    dim_fc = 64,\n",
    "    num_tokens = vocab_size,\n",
    "    device = DEVICE,\n",
    "    dropout = dropout_rate\n",
    ")\n",
    "\n",
    "model.embedding.weight.data = pretrained_embedding\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = tune(model, optimizer, criterion, epochs = 10, device = DEVICE, earlyStopping = False)\n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Rate + L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "output_dim = NUM_CLASSES\n",
    "print('output dim = ', output_dim)\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "weight_decay = 0.001\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    input_size = embedding_dim,\n",
    "    num_class=  NUM_CLASSES,\n",
    "    num_heads = 5,\n",
    "    dim_fc = 64,\n",
    "    num_tokens = vocab_size,\n",
    "    device = DEVICE,\n",
    "    dropout = dropout_rate\n",
    ")\n",
    "\n",
    "model.embedding.weight.data = pretrained_embedding\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = tune(model, optimizer, criterion, epochs = 10, device = DEVICE, earlyStopping = False)\n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping + L2 Regularization + Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "output_dim = NUM_CLASSES\n",
    "print('output dim = ', output_dim)\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "weight_decay = 0.001\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    input_size = embedding_dim,\n",
    "    num_class=  NUM_CLASSES,\n",
    "    num_heads = 5,\n",
    "    dim_fc = 64,\n",
    "    num_tokens = vocab_size,\n",
    "    device = DEVICE,\n",
    "    dropout=dropout_rate\n",
    ")\n",
    "\n",
    "model.embedding.weight.data = pretrained_embedding\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = tune(model, optimizer, criterion, epochs = 10, device = DEVICE, earlyStopping = True)\n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 2 but more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "output_dim = NUM_CLASSES\n",
    "print('output dim = ', output_dim)\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout_rate = 0.5\n",
    "weight_decay = 0.001\n",
    "epochs = 20\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    input_size = embedding_dim,\n",
    "    num_class=  NUM_CLASSES,\n",
    "    num_heads = 5,\n",
    "    dim_fc = 64,\n",
    "    num_tokens = vocab_size,\n",
    "    device = DEVICE,\n",
    "    dropout = dropout_rate\n",
    ")\n",
    "\n",
    "model.embedding.weight.data = pretrained_embedding\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = tune(model, optimizer, criterion, epochs = epochs, device = DEVICE, earlyStopping = False)\n",
    "\n",
    "plot(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

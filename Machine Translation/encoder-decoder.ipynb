{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gBIpoXiubl98"},"outputs":[],"source":["# !pip install d2l==1.0.3\n","# !pip install matplotlib_inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38s-iJ9ybg3q"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import shutil\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","import unittest\n","from d2l import torch as d2l\n","import logging\n","import requests\n","import pickle\n","from tqdm import tqdm\n","import numpy as np\n","import shutil"]},{"cell_type":"markdown","metadata":{"id":"TAkeNIyrbg3t"},"source":["### Download the Spanish-English dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1249,"status":"ok","timestamp":1708110991219,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"wMJXKWl7dFAc","outputId":"83588a93-6c6b-48c0-8ade-5e5b83d70aaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 5286k  100 5286k    0     0  2587k      0  0:00:02  0:00:02 --:--:-- 2598k\n","Archive:  data/spa-eng.zip\n","  inflating: data/_about.txt         \n","  inflating: data/spa.txt            \n"]}],"source":["# Google Collab\n","!mkdir data\n","!curl https://www.manythings.org/anki/spa-eng.zip -o data/spa-eng.zip\n","!unzip data/spa-eng.zip -d data/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIAbqZ69bg3v"},"outputs":[],"source":["#Windows\n","# !mkdir data\n","# !curl https://www.manythings.org/anki/spa-eng.zip -o data/spa-eng.zip\n","# !tar -xf data/spa-eng.zip -C data"]},{"cell_type":"markdown","metadata":{"id":"id6Ugoysbg3w"},"source":["### Setting up logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYg9xe5sbg3w"},"outputs":[],"source":["logging.basicConfig(level=logging.DEBUG, format='%(levelname)s - %(message)s')"]},{"cell_type":"markdown","metadata":{"id":"7Q3o30FGbg3w"},"source":["### Dataset\n","###  Process the english spanish translation\n","### link: https://www.manythings.org/anki/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QccGM6o7bg3w"},"outputs":[],"source":["class SpanishDataset(Dataset):\n","\n","    def setup_logger(self, level = logging.DEBUG):\n","        self.logger = logging.getLogger()\n","        self.logger.setLevel(level)\n","\n","    def log(self, message:str, level: str = 'debug'):\n","        if level == 'debug':\n","            self.logger.debug(message)\n","        if level == 'info':\n","            self.logger.info(message)\n","        if level == 'warning':\n","            self.logger.warning(message)\n","        if level == 'error':\n","            self.logger.error(message)\n","\n","\n","    def __init__(self, debug = False, num_steps = 10):\n","        super().__init__()\n","\n","        self.setup_logger()\n","\n","        self.DATASET_PATH = './data/spa.txt'\n","        assert os.path.exists(self.DATASET_PATH), 'English spanish dataset is not found'\n","        self.num_steps = num_steps\n","\n","        self.source = []\n","        self.target = []\n","\n","        self.log('start building the dataset')\n","\n","        with open(self.DATASET_PATH, 'r') as file:\n","            for idx, line in enumerate(file.readlines()):\n","                processed = self._preprocess(line)\n","                source_tokens, target_tokens = self._tokenize(processed)\n","                self.source.append(source_tokens)\n","                self.target.append(target_tokens)\n","\n","        self.log(f'done tokenizing source and target, source len = {len(self.source)}, target len = {len(self.target)}', 'info')\n","\n","        (self.source_array, self.target_array, self.valid_len, self.label_target_array), self.source_vocab, self.target_vocab = \\\n","            self._build_arrays(self.source, self.target)\n","\n","        #add tgt_pad (target pad) for masking in training phase\n","        self.tgt_pad = self.target_vocab['<pad>']\n","\n","        shape2d = lambda a: f'({len(a)},{len(a[0])})'\n","        self.log(f'done building source and target arrays', 'info')\n","        self.log(f'source array shape {shape2d(self.source_array)}')\n","        self.log(f'source vocab len = {len(self.source_vocab)}')\n","        self.log(f'valid_len shape  = {self.valid_len.shape}')\n","        self.log(f'target array shape = {shape2d(self.target_array)}')\n","        self.log(f'target vocab len = {len(self.target_vocab)}')\n","\n","    def _preprocess(self, text):\n","        # from D2L processing step in chapter 10\n","        # Replace non-breaking space with space\n","        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n","        # Insert space between words and punctuation marks\n","        no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '\n","        out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n","            for i, char in enumerate(text.lower())]\n","        return ''.join(out)\n","\n","    def _tokenize(self, text):\n","        # Tokenization method in D2L processing step in chapter 10\n","        if len(text.split('\\t')[:-1]) == 2:\n","            part = text.split('\\t')[:-1]\n","            src = [token for token in f'{part[0]} <eos>'.split(' ') if token]\n","            tgt = [token for token in f'{part[1]} <eos>'.split(' ') if token]\n","            return src, tgt\n","        else:\n","            return '',''\n","    def _build_arrays(self, source, target):\n","        '''\n","        @params:\n","            source_raw: list[list[string]], source sequence, eg: [['a', 'b', '<eos>'], ...]\n","            target_rwa: list[list[string]], target sequence\n","        @return\n","            (\n","                source_array: list[list[int]]\n","                target_array_with_bos: list[list[int]]\n","                valid_len: list[int]\n","                target_array_with_eos: list[list[int]]\n","            ),\n","            source_vocab: Vocab\n","            target_vocab: Vocab\n","        '''\n","        #pad with <pad> token if sequence len < time step, else truncate\n","        #NOTE: in the book, they just truncated without adding <eos> at the end,\n","        # I don't think that is correct\n","        pad_or_truncate = lambda sentence, numstep: \\\n","            sentence[:numstep - 1] + ['<eos>'] if len(sentence) > numstep \\\n","                else sentence + ['<pad>'] * (numstep - len(sentence))\n","\n","        def _build_array(sequence, is_target = False):\n","            '''\n","            @params:\n","                sentence: string\n","                is_target: boolean, if sentence is target, append <bos> to beginning of sentence\n","            @return\n","                array: list[str]\n","                vocab: Vocab object\n","            '''\n","            new_sequence = [ ]\n","            for sentence in sequence:\n","                sentence = pad_or_truncate(sentence, self.num_steps)\n","                if is_target:\n","                    sentence = ['<bos>'] + sentence\n","\n","                new_sequence.append(sentence)\n","\n","            vocab = d2l.Vocab(new_sequence, min_freq = 2)\n","\n","            #calculate valid_len for training later\n","            array = torch.tensor([vocab[sentence] for sentence in new_sequence])\n","            valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n","            return array,vocab,valid_len\n","\n","        source_array, source_vocab, valid_len = _build_array(source)\n","        target_array, target_vocab, _ = _build_array(target, is_target= True)\n","\n","        return (source_array, target_array[:,:-1], valid_len, target_array[:,1:]), source_vocab, target_vocab\n","\n","    def __len__(self):\n","        '''\n","        @return\n","            int: length of the english - spanish pairs\n","        '''\n","        return len(self.source_array)\n","\n","    def __getitem__(self,idx):\n","        '''\n","        @params:\n","            idx: int, datapoint index\n","        @return\n","            source_array, target_array, valid_len, label_target_array\n","        '''\n","        return (self.source_array[idx], self.target_array[idx], self.valid_len[idx], self.label_target_array[idx])\n","\n","    def get_dataloader(self, **kwargs):\n","        return DataLoader(self, **kwargs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1708088748046,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"JwdNv-kHbg3y","outputId":"6c5f2709-76f4-421c-d79e-d1b36db24561"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([3825,   84,  201,  202,  202,  202,  202,  202,  202,  202])\n","[\"i'm\", 'warm', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"]}],"source":["# dataset = SpanishDataset()\n","# source = dataset.source\n","# target = dataset.target# print(dataset.source_array[0])\n","\n","# print(dataset.source_vocab.to_tokens(dataset.source_array[500].tolist()))\n","\n","# train_dataloader = dataset.get_dataloader()\n","# sample = next(iter(train_dataloader))\n","\n","# for data in sample:\n","#     print(f'shape = {data.shape},\\t data = {data[0]}')"]},{"cell_type":"markdown","metadata":{"id":"hMJVoX-Rbg3z"},"source":["### Encoder and Decoder Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8DKDpIebg3z"},"outputs":[],"source":["class Encoder(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout = 0):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.GRU(input_size = embed_size, num_layers = num_layers, hidden_size = num_hiddens, dropout = dropout)\n","        #custom initialization\n","\n","    def forward(self, x, *args):\n","        #why x.t(), still confused in the book\n","        emb = self.embedding(x.t())\n","        output, state = self.rnn(emb)\n","        return output, state\n","\n","class Decoder(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout = 0):\n","        #note that the vocab size in decoder is target language vocab size, not source language vocab size\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.GRU(input_size = embed_size + num_hiddens, num_layers = num_layers, hidden_size = num_hiddens, dropout = dropout)\n","        self.dense = nn.LazyLinear(vocab_size)\n","        #custom init module\n","\n","    def init_state(self, enc_output, *args):\n","        '''\n","        use encoder's output to initialize state\n","        @params:\n","            encoder_output\n","        @return:\n","            decoder_input\n","        '''\n","        return enc_output\n","\n","    def forward(self, x, state):\n","        emb = self.embedding(x.t())\n","\n","        enc_output, enc_state = state\n","        #context variable\n","        context = enc_output[-1]\n","        context = context.repeat(emb.shape[0], 1, 1)\n","        emb_and_context = torch.cat((emb, context), -1)\n","        dec_output, dec_state = self.rnn(emb_and_context, enc_state)\n","\n","        #pass to dense layer and swap back (batch_size, num_steps)\n","        y_pred = self.dense(dec_output).swapaxes(0,1)\n","        # print(x.shape)\n","        # print('embedding shape = ', emb.shape)\n","        # print('context shape = ', context.shape)\n","        # print('emb and context shape = ', emb_and_context.shape)\n","        # print('decoder output shape = ', output.shape)\n","        # print('decoder state shape = ', dec_state.shape)\n","        return y_pred, (dec_output, dec_state)\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, x_enc, x_dec, *args):\n","        enc_outputs, enc_state = self.encoder(x_enc, *args)\n","        dec_init_state = self.decoder.init_state((enc_outputs, enc_state), *args)\n","        #only returns decoder output, decode state is not used for final pred\n","        return self.decoder(x_dec, dec_init_state)[0]\n"]},{"cell_type":"markdown","metadata":{"id":"Hs9MBLpwXCcO"},"source":["# Test Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708088748046,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"P5wlabDKbg3z","outputId":"52484c61-d5bd-45ce-96e8-c507da5f3075"},"outputs":[{"name":"stdout","output_type":"stream","text":["output shape =  torch.Size([10, 32, 16])  dtype =  torch.float32\n","state shape =  torch.Size([2, 32, 16])  dtype =  torch.float32\n"]}],"source":["# Test with sample\n","vocab_size, embed_size, num_layers, num_hiddens = 1000, 8, 2, 16\n","batch_size, num_steps = 32, 10\n","\n","x = torch.randint(0,vocab_size,(batch_size, num_steps))\n","\n","encoder = Encoder(vocab_size, embed_size, num_hiddens, num_layers )\n","\n","output, state = encoder(x)\n","\n","print('output shape = ',output.shape, ' dtype = ', output.dtype)\n","print('state shape = ', state.shape, ' dtype = ', state.dtype)"]},{"cell_type":"markdown","metadata":{"id":"OJOKKI_eXEXH"},"source":["# Test Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708088748046,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"v7Z1ApOdbg30","outputId":"9ac4d627-5b30-4554-b581-7c956f397e1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["enc output shape =  torch.Size([10, 32, 16])  dtype =  torch.float32\n","enc state shape =  torch.Size([2, 32, 16])  dtype =  torch.float32\n","y_pred shape =  torch.Size([32, 10, 2000]) dtype =  torch.float32\n","dec state shape  =  torch.Size([2, 32, 16]) dtype =  torch.float32\n"]},{"name":"stderr","output_type":"stream","text":["/Users/jamesnguyen/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]}],"source":["# Test with sample\n","enc_vocab_size, embed_size, num_layers, num_hiddens = 1000, 8, 2, 16\n","dec_vocab_size = 2000\n","batch_size, num_steps = 32, 10\n","\n","x = torch.randint(0,enc_vocab_size,(batch_size, num_steps))\n","\n","encoder = Encoder(enc_vocab_size, embed_size, num_hiddens, num_layers )\n","\n","enc_output, enc_state = encoder(x)\n","\n","print('enc output shape = ',enc_output.shape, ' dtype = ', enc_output.dtype)\n","print('enc state shape = ', enc_state.shape, ' dtype = ', enc_state.dtype)\n","\n","decoder = Decoder(dec_vocab_size, embed_size, num_hiddens, num_layers)\n","decoder_state = decoder.init_state((enc_output, enc_state))\n","\n","y, (dec_output, dec_state) = decoder(x, decoder_state)\n","\n","print('y_pred shape = ', y.shape, 'dtype = ', dec_output.dtype)\n","print('dec state shape  = ', dec_state.shape, 'dtype = ', dec_state.dtype)\n"]},{"cell_type":"markdown","metadata":{"id":"mKFE1EGhXFkY"},"source":["# Test Encoder Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708088748047,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"adW0bSP3bg30","outputId":"32cc97b0-1b83-4a77-c397-370b66db3707"},"outputs":[{"name":"stdout","output_type":"stream","text":["seq2seq output shape =  torch.Size([32, 10, 2000])\n"]}],"source":["#Test seq 2 seq\n","# Test with sample\n","vocab_size_source, embed_size, num_layers, num_hiddens = 1000, 8, 2, 16\n","vocab_size_target = 2000\n","batch_size, num_steps = 32, 10\n","\n","#this represents the source_array\n","x_enc = torch.randint(0,vocab_size_source,(batch_size, num_steps))\n","#this represents the target array with BOS\n","x_dec = torch.randint(0,vocab_size_target,(batch_size, num_steps))\n","\n","encoder = Encoder(vocab_size_source, embed_size, num_hiddens, num_layers)\n","decoder = Decoder(vocab_size_target, embed_size, num_hiddens, num_layers)\n","\n","seq2seq = Seq2Seq(encoder, decoder)\n","\n","output = seq2seq(x_enc, x_dec)\n","print('seq2seq output shape = ', output.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"qtUemVPVbg31"},"source":["### Perplexity\n","\n","Perplexity is PPL = e^(CrossEntropyLoss(y_pred, y))"]},{"cell_type":"markdown","metadata":{"id":"lf61JSJwbg30"},"source":["### Training procedure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSWcFUqLyU7_"},"outputs":[],"source":["\n","class Trainer():\n","  def __init__(self, model, dataset):\n","    self.model = model\n","    self.dataset = dataset\n","    self._run()\n","    if torch.cuda.is_available():\n","      self.device = 'cuda'\n","    else:\n","      self.device = 'cpu'\n","\n","  def _has_gpu(self):\n","    return self.device == 'cuda'\n","\n","  def prepare_batch(self, batch):\n","    if self._has_gpu():\n","      batch = [a.to(self.device) for a in batch]\n","    return batch\n","\n","  def _run(self):\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TO2D-h-KhvQ6","outputId":"14c47510-b07c-4bd9-c41e-c3390c3346db"},"outputs":[{"name":"stderr","output_type":"stream","text":["DEBUG - start building the dataset\n","INFO - done tokenizing source and target, source len = 141370, target len = 141370\n","INFO - done building source and target arrays\n","DEBUG - source array shape (141370,10)\n","DEBUG - source vocab len = 9538\n","DEBUG - valid_len shape  = torch.Size([141370])\n","DEBUG - target array shape = (141370,10)\n","DEBUG - target vocab len = 16679\n"]},{"name":"stdout","output_type":"stream","text":["source vocab size = 9538\n","target vocab size = 16679\n"]}],"source":["#Build the dataset\n","dataset = SpanishDataset()\n","\n","#Extract some paramaters\n","source_vocab_size = len(dataset.source_vocab)\n","print(f'source vocab size = {source_vocab_size}')\n","target_vocab_size = len(dataset.target_vocab)\n","print(f'target vocab size = {target_vocab_size}')\n","embed_size = 100\n","num_hiddens = 256\n","num_layers = 2\n","dropout = 0.2\n","batch_size = 32\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UjP_37FieJa7","outputId":"0b49b922-887d-46e8-fd5e-e7a9e7385ac6"},"outputs":[{"name":"stdout","output_type":"stream","text":["train dataloader len =  4418\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 12754.9326171875:   0%|          | 19/4418 [00:12<46:45,  1.57it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[58], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m ppl_loss(y_pred, tgt_array_eos, dataset\u001b[38;5;241m.\u001b[39mtgt_pad)\n\u001b[0;32m---> 54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     55\u001b[0m step \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     56\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class PerplexityLoss(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.loss_fn = nn.CrossEntropyLoss()\n","\n","  def forward(self, y_pred, y, tgt_pad):\n","    y_pred = y_pred.permute(0,2,1)\n","    l = self.loss_fn(y_pred, y)\n","    mask = (y.reshape(-1) != tgt_pad).type(torch.float32)\n","    return torch.exp((l * mask).sum() / mask.sum())\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","#Get dataloader for\n","train_dataloader = dataset.get_dataloader(batch_size = batch_size, shuffle = True)\n","print('train dataloader len = ',len(train_dataloader))\n","\n","encoder = Encoder(source_vocab_size, embed_size, num_layers, num_hiddens)\n","decoder = Decoder(target_vocab_size, embed_size, num_layers, num_hiddens)\n","\n","seq2seq = Seq2Seq(encoder, decoder)\n","\n","seq2seq.to(device)\n","\n","ppl_loss = PerplexityLoss()\n","optim = torch.optim.Adam(seq2seq.parameters(), lr = 0.01)\n","\n","history = []\n","\n","epochs = 20\n","\n","for e in range(epochs):\n","  loop = tqdm(train_dataloader)\n","  running_loss =0\n","\n","  for data in loop:\n","    src_array, tgt_array_bos, valid_len, tgt_array_eos = data\n","    src_array = src_array.to(device)\n","    tgt_array_bos = tgt_array_bos.to(device)\n","    tgt_array_eos = tgt_array_eos.to(device)\n","    valid_len = valid_len.to(device)\n","    # print('src array shape = ', src_array.shape)\n","    # print(f'tgt array bos shape {tgt_array_bos.shape}' )\n","    # print(f'tgt array eos shape {tgt_array_eos.shape}')\n","    # print(f'shape {valid_len.shape}')\n","\n","    y_pred = seq2seq(src_array, tgt_array_bos)\n","    # print('y pred ', y_pred[0])\n","    # print('y pred GRAD', y_pred.grad)\n","    # print('target ', tgt_array_eos[0])\n","\n","    optim.zero_grad()\n","    loss = ppl_loss(y_pred, tgt_array_eos, dataset.tgt_pad)\n","    loss.backward()\n","    step = optim.step()\n","    running_loss += loss.item()\n","    loop.set_description(f'batch ppl = {loss.item()}')\n","\n","  print(f'epoch = {e}, ppl = {running_loss}')\n","  history.append({'loss': running_loss})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ROAJrTWS2YFp"},"outputs":[],"source":["if os.path.exists('output') == False:\n","    os.mkdir('output')\n","MODEL_PATH = './output/seq2seq.h5'\n","torch.save(seq2seq, MODEL_PATH)"]},{"cell_type":"markdown","metadata":{"id":"U8KZoiHPB3FN"},"source":["# Evaluating seq2seq model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12998,"status":"ok","timestamp":1708111241918,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"-cHFEWsgB26n","outputId":"b97b2387-32a5-4d5b-fb6e-cc04e6c58398"},"outputs":[{"name":"stderr","output_type":"stream","text":["DEBUG - start building the dataset\n"]},{"name":"stdout","output_type":"stream","text":["<class '__main__.Seq2Seq'>\n"]},{"name":"stderr","output_type":"stream","text":["INFO - done tokenizing source and target, source len = 141370, target len = 141370\n","INFO - done building source and target arrays\n","DEBUG - source array shape (141370,10)\n","DEBUG - source vocab len = 9538\n","DEBUG - valid_len shape  = torch.Size([141370])\n","DEBUG - target array shape = (141370,10)\n","DEBUG - target vocab len = 16679\n"]}],"source":["MODEL_PATH = './output/seq2seq.h5'\n","model = torch.load(MODEL_PATH, map_location = torch.device('cpu'))\n","print(type(model))\n","dataset = SpanishDataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708111241918,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"FVV_XkOEDl2S","outputId":"8790ff2e-2b3a-4adb-9503-2c6edd8cae2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[tensor([[4370, 8244, 8641, 9349,  960,  225, 8623, 2702, 8488,  201],\n","        [4367, 2725, 4093, 8491, 7687, 4377, 9287, 4683,  235,  201],\n","        [4367, 6773, 8491, 1191, 4906, 5682,   84,  201,  202,  202],\n","        [4101, 7405,  206, 4994,  353, 8623, 4219, 8890,   84,  201],\n","        [3108,  206, 1679, 1461, 8904, 4680,   84,  201,  202,  202],\n","        [4367, 2057, 7610,   84,  201,  202,  202,  202,  202,  202],\n","        [9231, 3838, 8623, 8491, 5530,   84,  201,  202,  202,  202],\n","        [8010, 9303, 9512,  661,   84,  201,  202,  202,  202,  202],\n","        [4367, 1461, 1874, 9389, 9512, 4386, 9512, 9177, 5293,  201],\n","        [8491,  203,  203, 8488, 8641, 9178, 8623, 1410, 9196,  201]]), tensor([[  189,  6750, 13902,  4547, 12630, 14965, 11894,  7909,  6567,    78],\n","        [  189, 10625, 14765,  9021,  9964,  8249,  4547, 12782, 13845, 15199],\n","        [  189,  1132,  9231,  5820,  9257,    78,   190,   191,   191,   191],\n","        [  189, 16631,  6343, 15375,  2787,  5352,   196, 14375, 15352,    78],\n","        [  189,  6741,  9493,  6257,  7980, 15374, 10623,    78,   190,   191],\n","        [  189, 16013, 13905,  2688,    78,   190,   191,   191,   191,   191],\n","        [  189, 15513,   196,  9084, 10231,    78,   190,   191,   191,   191],\n","        [  189, 12642,  5602,  6826,    78,   190,   191,   191,   191,   191],\n","        [  189, 16013, 12540,  8827,  3593, 15934, 14063, 12719,    78,   190],\n","        [  189,  5820, 13844,   192, 12630, 14965, 12721,  3514,  6379,  4778]]), tensor([10, 10,  8, 10,  8,  5,  7,  6, 10, 10]), tensor([[ 6750, 13902,  4547, 12630, 14965, 11894,  7909,  6567,    78,   190],\n","        [10625, 14765,  9021,  9964,  8249,  4547, 12782, 13845, 15199,   190],\n","        [ 1132,  9231,  5820,  9257,    78,   190,   191,   191,   191,   191],\n","        [16631,  6343, 15375,  2787,  5352,   196, 14375, 15352,    78,   190],\n","        [ 6741,  9493,  6257,  7980, 15374, 10623,    78,   190,   191,   191],\n","        [16013, 13905,  2688,    78,   190,   191,   191,   191,   191,   191],\n","        [15513,   196,  9084, 10231,    78,   190,   191,   191,   191,   191],\n","        [12642,  5602,  6826,    78,   190,   191,   191,   191,   191,   191],\n","        [16013, 12540,  8827,  3593, 15934, 14063, 12719,    78,   190,   191],\n","        [ 5820, 13844,   192, 12630, 14965, 12721,  3514,  6379,  4778,   190]])]\n"]}],"source":["index = []\n","for i in range(10):\n","  index.append(np.random.choice(len(dataset)))\n","\n","batch = []\n","src = []\n","tgt = []\n","valid_len = []\n","tgt_eos = []\n","\n","for i in index:\n","  data = dataset[i]\n","  src.append(data[0])\n","  tgt.append(data[1])\n","  valid_len.append(data[2])\n","  tgt_eos.append(data[3])\n","\n","batch = [torch.stack(a) for a in (src,tgt,valid_len,tgt_eos)]\n","print(batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":185,"status":"ok","timestamp":1708111255617,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"ede5gQu1VnO5","outputId":"05c4afa5-f0a1-4e64-be16-d89b7ba8adbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["enc outputs  torch.Size([10, 32, 16])\n","enc state   torch.Size([2, 10, 256])\n","[tensor([[189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189]])]\n","\n","tensor([[189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189]])\n","torch.Size([10, 1])\n"]},{"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 2. Expected size 10 but got size 1 for tensor number 1 in the list.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     Y, dec_state \u001b[38;5;241m=\u001b[39m seq2seq\u001b[38;5;241m.\u001b[39mdecoder(outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dec_state)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m predict(model, batch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n","Cell \u001b[0;32mIn[26], line 17\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(seq2seq, batch, device, num_steps)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 17\u001b[0m Y, dec_state \u001b[38;5;241m=\u001b[39m seq2seq\u001b[38;5;241m.\u001b[39mdecoder(outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dec_state)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[5], line 42\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m     40\u001b[0m context \u001b[38;5;241m=\u001b[39m enc_output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     41\u001b[0m context \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrepeat(emb\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m emb_and_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((emb, context), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m dec_output, dec_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(emb_and_context, enc_state)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#pass to dense layer and swap back (batch_size, num_steps)\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 10 but got size 1 for tensor number 1 in the list."]}],"source":["def predict(seq2seq, batch, device, num_steps):\n","  batch = [a.to(device) for a in batch]\n","  src, tgt, valid_len, _ = batch\n","\n","  enc_outputs, enc_state = seq2seq.encoder(src, valid_len)\n","  print('enc outputs ', enc_output.shape)\n","  print('enc state  ', enc_state.shape)\n","  dec_outputs, dec_state = seq2seq.decoder.init_state((enc_outputs, enc_state), valid_len)\n","\n","  outputs, attention_weights = [tgt[:,(0)].unsqueeze(1), ], []\n","  # print(outputs)\n","  # print(outputs)\n","  for _ in range(num_steps):\n","    print(outputs[-1])\n","    print(outputs[-1].shape)\n","    Y, dec_state = seq2seq.decoder(outputs[-1], dec_state)\n","    break\n","\n","predict(model, batch, 'cpu', 10)"]},{"cell_type":"markdown","metadata":{"id":"pF_wZM-Pbg31"},"source":["### Unit Tests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9pw8TIXbg31"},"outputs":[],"source":["# class SpanishDatasetTest(unittest.TestCase):\n","\n","#     def test_upper(self):\n","#         self.assertEqual('foo'.upper(), 'FOO')\n","\n","#     def test_isupper(self):\n","#         self.assertTrue('FOO'.isupper())\n","#         self.assertFalse('Foo'.isupper())\n","\n","#     def test_split(self):\n","#         s = 'hello world'\n","#         self.assertEqual(s.split(), ['hello', 'world'])\n","\n","#     def test4(self):\n","#         self.assertEqual('foo', 'foo1')\n","\n","# unittest.main(argv=[''], exit=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DT-xsp-Cbg31"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"vscode":{"interpreter":{"hash":"af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
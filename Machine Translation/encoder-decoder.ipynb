{"cells":[{"cell_type":"markdown","metadata":{},"source":["Youtube series\n","https://www.youtube.com/watch?v=gHk2IWivt_8&list=PLmZlBIcArwhPHmHzyM_cZJQ8_v5paQJTV"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gBIpoXiubl98"},"outputs":[],"source":["# !pip install d2l==1.0.3\n","# !pip install matplotlib_inline"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"38s-iJ9ybg3q"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import shutil\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","import unittest\n","from d2l import torch as d2l\n","import logging\n","import requests\n","import pickle\n","from tqdm import tqdm\n","import numpy as np\n","import shutil"]},{"cell_type":"markdown","metadata":{"id":"TAkeNIyrbg3t"},"source":["### Download the Spanish-English dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1249,"status":"ok","timestamp":1708110991219,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"wMJXKWl7dFAc","outputId":"83588a93-6c6b-48c0-8ade-5e5b83d70aaa"},"outputs":[{"name":"stderr","output_type":"stream","text":["A subdirectory or file data already exists.\n"]},{"name":"stderr","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n"," 26 5286k   26 1413k    0     0  1739k      0  0:00:03 --:--:--  0:00:03 1741k\n","100 5286k  100 5286k    0     0  3521k      0  0:00:01  0:00:01 --:--:-- 3526k\n","'unzip' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["# Google Collab\n","!mkdir data\n","!curl https://www.manythings.org/anki/spa-eng.zip -o data/spa-eng.zip\n","!unzip data/spa-eng.zip -d data/"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"QIAbqZ69bg3v"},"outputs":[],"source":["#Windows\n","# !mkdir data\n","# !curl https://www.manythings.org/anki/spa-eng.zip -o data/spa-eng.zip\n","# !tar -xf data/spa-eng.zip -C data"]},{"cell_type":"markdown","metadata":{"id":"id6Ugoysbg3w"},"source":["### Setting up logger"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wYg9xe5sbg3w"},"outputs":[],"source":["logging.basicConfig(level=logging.DEBUG, format='%(levelname)s - %(message)s')"]},{"cell_type":"markdown","metadata":{"id":"7Q3o30FGbg3w"},"source":["### Dataset\n","###  Process the english spanish translation\n","### link: https://www.manythings.org/anki/"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"QccGM6o7bg3w"},"outputs":[],"source":["class SpanishDataset(Dataset):\n","\n","    def setup_logger(self, level = logging.DEBUG):\n","        self.logger = logging.getLogger()\n","        self.logger.setLevel(level)\n","\n","    def log(self, message:str, level: str = 'debug'):\n","        if level == 'debug':\n","            self.logger.debug(message)\n","        if level == 'info':\n","            self.logger.info(message)\n","        if level == 'warning':\n","            self.logger.warning(message)\n","        if level == 'error':\n","            self.logger.error(message)\n","\n","\n","    def __init__(self, debug = False, num_steps = 10):\n","        super().__init__()\n","\n","        self.setup_logger()\n","\n","        self.DATASET_PATH = './data/spa.txt'\n","        assert os.path.exists(self.DATASET_PATH), 'English spanish dataset is not found'\n","        self.num_steps = num_steps\n","\n","        self.source = []\n","        self.target = []\n","\n","        self.log('start building the dataset')\n","\n","        with open(self.DATASET_PATH, 'r') as file:\n","            for idx, line in enumerate(file.readlines()):\n","                processed = self._preprocess(line)\n","                source_tokens, target_tokens = self._tokenize(processed)\n","                self.source.append(source_tokens)\n","                self.target.append(target_tokens)\n","\n","        self.log(f'done tokenizing source and target, source len = {len(self.source)}, target len = {len(self.target)}', 'info')\n","\n","        (self.source_array, self.target_array, self.valid_len, self.label_target_array), self.source_vocab, self.target_vocab = \\\n","            self._build_arrays(self.source, self.target)\n","\n","        #add tgt_pad (target pad) for masking in training phase\n","        self.tgt_pad = self.target_vocab['<pad>']\n","\n","        shape2d = lambda a: f'({len(a)},{len(a[0])})'\n","        self.log(f'done building source and target arrays', 'info')\n","        self.log(f'source array shape {shape2d(self.source_array)}')\n","        self.log(f'source vocab len = {len(self.source_vocab)}')\n","        self.log(f'valid_len shape  = {self.valid_len.shape}')\n","        self.log(f'target array shape = {shape2d(self.target_array)}')\n","        self.log(f'target vocab len = {len(self.target_vocab)}')\n","\n","    def _preprocess(self, text):\n","        # from D2L processing step in chapter 10\n","        # Replace non-breaking space with space\n","        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n","        # Insert space between words and punctuation marks\n","        no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '\n","        out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n","            for i, char in enumerate(text.lower())]\n","        return ''.join(out)\n","\n","    def _tokenize(self, text):\n","        # Tokenization method in D2L processing step in chapter 10\n","        if len(text.split('\\t')[:-1]) == 2:\n","            part = text.split('\\t')[:-1]\n","            src = [token for token in f'{part[0]} <eos>'.split(' ') if token]\n","            tgt = [token for token in f'{part[1]} <eos>'.split(' ') if token]\n","            return src, tgt\n","        else:\n","            return '',''\n","    def _build_arrays(self, source, target):\n","        '''\n","        @params:\n","            source_raw: list[list[string]], source sequence, eg: [['a', 'b', '<eos>'], ...]\n","            target_rwa: list[list[string]], target sequence\n","        @return\n","            (\n","                source_array: list[list[int]]\n","                target_array_with_bos: list[list[int]]\n","                valid_len: list[int]\n","                target_array_with_eos: list[list[int]]\n","            ),\n","            source_vocab: Vocab\n","            target_vocab: Vocab\n","        '''\n","        #pad with <pad> token if sequence len < time step, else truncate\n","        #NOTE: in the book, they just truncated without adding <eos> at the end,\n","        # I don't think that is correct\n","        pad_or_truncate = lambda sentence, numstep: \\\n","            sentence[:numstep - 1] + ['<eos>'] if len(sentence) > numstep \\\n","                else sentence + ['<pad>'] * (numstep - len(sentence))\n","\n","        def _build_array(sequence, is_target = False):\n","            '''\n","            @params:\n","                sentence: string\n","                is_target: boolean, if sentence is target, append <bos> to beginning of sentence\n","            @return\n","                array: list[str]\n","                vocab: Vocab object\n","            '''\n","            new_sequence = [ ]\n","            for sentence in sequence:\n","                sentence = pad_or_truncate(sentence, self.num_steps)\n","                if is_target:\n","                    sentence = ['<bos>'] + sentence\n","\n","                new_sequence.append(sentence)\n","\n","            vocab = d2l.Vocab(new_sequence, min_freq = 2)\n","\n","            #calculate valid_len for training later\n","            array = torch.tensor([vocab[sentence] for sentence in new_sequence])\n","            valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n","            return array,vocab,valid_len\n","\n","        source_array, source_vocab, valid_len = _build_array(source)\n","        target_array, target_vocab, _ = _build_array(target, is_target= True)\n","\n","        return (source_array, target_array[:,:-1], valid_len, target_array[:,1:]), source_vocab, target_vocab\n","\n","    def __len__(self):\n","        '''\n","        @return\n","            int: length of the english - spanish pairs\n","        '''\n","        return len(self.source_array)\n","\n","    def __getitem__(self,idx):\n","        '''\n","        @params:\n","            idx: int, datapoint index\n","        @return\n","            source_array, target_array, valid_len, label_target_array\n","        '''\n","        return (self.source_array[idx], self.target_array[idx], self.valid_len[idx], self.label_target_array[idx])\n","\n","    def get_dataloader(self, **kwargs):\n","        return DataLoader(self, **kwargs)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1708088748046,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"JwdNv-kHbg3y","outputId":"6c5f2709-76f4-421c-d79e-d1b36db24561"},"outputs":[],"source":["# dataset = SpanishDataset()\n","# source = dataset.source\n","# target = dataset.target# print(dataset.source_array[0])\n","\n","# print(dataset.source_vocab.to_tokens(dataset.source_array[500].tolist()))\n","\n","# train_dataloader = dataset.get_dataloader()\n","# sample = next(iter(train_dataloader))\n","\n","# for data in sample:\n","#     print(f'shape = {data.shape},\\t data = {data[0]}')"]},{"cell_type":"markdown","metadata":{"id":"hMJVoX-Rbg3z"},"source":["### Encoder and Decoder Architecture"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"b8DKDpIebg3z"},"outputs":[],"source":["class Encoder(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout = 0):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.GRU(input_size = embed_size, num_layers = num_layers, hidden_size = num_hiddens, dropout = dropout)\n","        #custom initialization\n","\n","    def forward(self, x, *args):\n","        #why x.t(), still confused in the book\n","        emb = self.embedding(x.t())\n","        output, state = self.rnn(emb)\n","        return output, state\n","\n","class Decoder(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout = 0):\n","        #note that the vocab size in decoder is target language vocab size, not source language vocab size\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.rnn = nn.GRU(input_size = embed_size + num_hiddens, num_layers = num_layers, hidden_size = num_hiddens, dropout = dropout)\n","        self.dense = nn.LazyLinear(vocab_size)\n","        #custom init module\n","\n","    def init_state(self, enc_all_outputs, *args):\n","        '''\n","        use encoder's output to initialize state\n","        @params:\n","            encoder_output\n","        @return:\n","            decoder_input\n","        '''\n","        return enc_all_outputs\n","\n","    def forward(self, x, state):\n","        emb = self.embedding(x.t())\n","\n","        enc_output, enc_state = state\n","        #context variable\n","        context = enc_output[-1]\n","        context = context.repeat(emb.shape[0], 1, 1)\n","        emb_and_context = torch.cat((emb, context), -1)\n","        dec_output, dec_state = self.rnn(emb_and_context, enc_state)\n","\n","        #pass to dense layer and swap back (batch_size, num_steps)\n","        y_pred = self.dense(dec_output).swapaxes(0,1)\n","        # print(x.shape)\n","        # print('embedding shape = ', emb.shape)\n","        # print('context shape = ', context.shape)\n","        # print('emb and context shape = ', emb_and_context.shape)\n","        # print('decoder output shape = ', output.shape)\n","        # print('decoder state shape = ', dec_state.shape)\n","        return y_pred, (dec_output, dec_state)\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, x_enc, x_dec, *args):\n","        enc_outputs, enc_state = self.encoder(x_enc, *args)\n","        dec_init_state = self.decoder.init_state((enc_outputs, enc_state), *args)\n","        #only returns decoder output, decode state is not used for final pred\n","        return self.decoder(x_dec, dec_init_state)[0]\n"]},{"cell_type":"markdown","metadata":{"id":"Hs9MBLpwXCcO"},"source":["# Test Encoder"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708088748046,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"P5wlabDKbg3z","outputId":"52484c61-d5bd-45ce-96e8-c507da5f3075"},"outputs":[{"name":"stdout","output_type":"stream","text":["output shape =  torch.Size([10, 32, 16])  dtype =  torch.float32\n","state shape =  torch.Size([2, 32, 16])  dtype =  torch.float32\n"]}],"source":["# Test with sample\n","vocab_size, embed_size, num_layers, num_hiddens = 1000, 8, 2, 16\n","batch_size, num_steps = 32, 10\n","\n","x = torch.randint(0,vocab_size,(batch_size, num_steps))\n","\n","encoder = Encoder(vocab_size, embed_size, num_hiddens, num_layers )\n","\n","output, state = encoder(x)\n","\n","print('output shape = ',output.shape, ' dtype = ', output.dtype)\n","print('state shape = ', state.shape, ' dtype = ', state.dtype)"]},{"cell_type":"markdown","metadata":{"id":"OJOKKI_eXEXH"},"source":["# Test Decoder"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708088748046,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"v7Z1ApOdbg30","outputId":"9ac4d627-5b30-4554-b581-7c956f397e1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["enc output shape =  torch.Size([10, 32, 16])  dtype =  torch.float32\n","enc state shape =  torch.Size([2, 32, 16])  dtype =  torch.float32\n","y_pred shape =  torch.Size([32, 10, 2000]) dtype =  torch.float32\n","dec state shape  =  torch.Size([2, 32, 16]) dtype =  torch.float32\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]}],"source":["# Test with sample\n","enc_vocab_size, embed_size, num_layers, num_hiddens = 1000, 8, 2, 16\n","dec_vocab_size = 2000\n","batch_size, num_steps = 32, 10\n","\n","x = torch.randint(0,enc_vocab_size,(batch_size, num_steps))\n","\n","encoder = Encoder(enc_vocab_size, embed_size, num_hiddens, num_layers )\n","\n","enc_output, enc_state = encoder(x)\n","\n","print('enc output shape = ',enc_output.shape, ' dtype = ', enc_output.dtype)\n","print('enc state shape = ', enc_state.shape, ' dtype = ', enc_state.dtype)\n","\n","decoder = Decoder(dec_vocab_size, embed_size, num_hiddens, num_layers)\n","decoder_state = decoder.init_state((enc_output, enc_state))\n","\n","y, (dec_output, dec_state) = decoder(x, decoder_state)\n","\n","print('y_pred shape = ', y.shape, 'dtype = ', dec_output.dtype)\n","print('dec state shape  = ', dec_state.shape, 'dtype = ', dec_state.dtype)\n"]},{"cell_type":"markdown","metadata":{"id":"mKFE1EGhXFkY"},"source":["# Test Encoder Decoder"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1708088748047,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"adW0bSP3bg30","outputId":"32cc97b0-1b83-4a77-c397-370b66db3707"},"outputs":[{"name":"stdout","output_type":"stream","text":["seq2seq output shape =  torch.Size([32, 10, 2000])\n"]}],"source":["#Test seq 2 seq\n","# Test with sample\n","vocab_size_source, embed_size, num_layers, num_hiddens = 1000, 8, 2, 16\n","vocab_size_target = 2000\n","batch_size, num_steps = 32, 10\n","\n","#this represents the source_array\n","x_enc = torch.randint(0,vocab_size_source,(batch_size, num_steps))\n","#this represents the target array with BOS\n","x_dec = torch.randint(0,vocab_size_target,(batch_size, num_steps))\n","\n","encoder = Encoder(vocab_size_source, embed_size, num_hiddens, num_layers)\n","decoder = Decoder(vocab_size_target, embed_size, num_hiddens, num_layers)\n","\n","seq2seq = Seq2Seq(encoder, decoder)\n","\n","output = seq2seq(x_enc, x_dec)\n","print('seq2seq output shape = ', output.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"qtUemVPVbg31"},"source":["### Perplexity\n","\n","Perplexity is PPL = e^(CrossEntropyLoss(y_pred, y))"]},{"cell_type":"markdown","metadata":{"id":"lf61JSJwbg30"},"source":["### Training procedure"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"KSWcFUqLyU7_"},"outputs":[],"source":["\n","class Trainer():\n","  def __init__(self, model, dataset):\n","    self.model = model\n","    self.dataset = dataset\n","    self._run()\n","    if torch.cuda.is_available():\n","      self.device = 'cuda'\n","    else:\n","      self.device = 'cpu'\n","\n","  def _has_gpu(self):\n","    return self.device == 'cuda'\n","\n","  def prepare_batch(self, batch):\n","    if self._has_gpu():\n","      batch = [a.to(self.device) for a in batch]\n","    return batch\n","\n","  def _run(self):\n","    pass"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"TO2D-h-KhvQ6","outputId":"14c47510-b07c-4bd9-c41e-c3390c3346db"},"outputs":[{"name":"stderr","output_type":"stream","text":["DEBUG - start building the dataset\n","INFO - done tokenizing source and target, source len = 141370, target len = 141370\n","INFO - done building source and target arrays\n","DEBUG - source array shape (141370,10)\n","DEBUG - source vocab len = 9538\n","DEBUG - valid_len shape  = torch.Size([141370])\n","DEBUG - target array shape = (141370,10)\n","DEBUG - target vocab len = 16679\n"]},{"name":"stdout","output_type":"stream","text":["source vocab size = 9538\n","target vocab size = 16679\n"]}],"source":["#Build the dataset\n","dataset = SpanishDataset()\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"UjP_37FieJa7","outputId":"0b49b922-887d-46e8-fd5e-e7a9e7385ac6"},"outputs":[{"name":"stdout","output_type":"stream","text":["source vocab size = 9538\n","target vocab size = 16679\n","train dataloader len =  553\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 261.39 \t: 100%|██████████| 553/553 [01:21<00:00,  6.75it/s] \n"]},{"name":"stdout","output_type":"stream","text":["epoch = 0, ppl = 676234.8220672607\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 182.68 \t: 100%|██████████| 553/553 [01:22<00:00,  6.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch = 1, ppl = 104761.52668762207\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 163.32 \t: 100%|██████████| 553/553 [01:21<00:00,  6.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch = 2, ppl = 85973.30590057373\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 128.28 \t: 100%|██████████| 553/553 [01:20<00:00,  6.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch = 3, ppl = 81512.13844299316\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 139.04 \t: 100%|██████████| 553/553 [01:23<00:00,  6.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch = 4, ppl = 74910.17710113525\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 118.73 \t: 100%|██████████| 553/553 [01:24<00:00,  6.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch = 5, ppl = 68752.88645172119\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 105.89 \t: 100%|██████████| 553/553 [01:23<00:00,  6.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch = 6, ppl = 63696.14000701904\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 140.29 \t: 100%|██████████| 553/553 [01:23<00:00,  6.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["epoch = 7, ppl = 59483.47602081299\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 75.56 \t: 100%|██████████| 553/553 [01:23<00:00,  6.63it/s] \n"]},{"name":"stdout","output_type":"stream","text":["epoch = 8, ppl = 56032.75653839111\n"]},{"name":"stderr","output_type":"stream","text":["batch ppl = 101.74 \t: 100%|██████████| 553/553 [01:24<00:00,  6.52it/s]"]},{"name":"stdout","output_type":"stream","text":["epoch = 9, ppl = 54147.706802368164\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["#Extract some paramaters\n","source_vocab_size = len(dataset.source_vocab)\n","print(f'source vocab size = {source_vocab_size}')\n","target_vocab_size = len(dataset.target_vocab)\n","print(f'target vocab size = {target_vocab_size}')\n","embed_size = 100\n","num_hiddens = 256\n","num_layers = 2\n","dropout = 0.2\n","batch_size = 256 \n","\n","class PerplexityLoss(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.loss_fn = nn.CrossEntropyLoss()\n","\n","  def forward(self, y_pred, y, tgt_pad):\n","    y_pred = y_pred.permute(0,2,1)\n","    l = self.loss_fn(y_pred, y)\n","    mask = (y.reshape(-1) != tgt_pad).type(torch.float32)\n","    return torch.exp((l * mask).sum() / mask.sum())\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","#Get dataloader for\n","train_dataloader = dataset.get_dataloader(batch_size = batch_size, shuffle = True)\n","print('train dataloader len = ',len(train_dataloader))\n","\n","encoder = Encoder(source_vocab_size, embed_size, num_layers, num_hiddens)\n","decoder = Decoder(target_vocab_size, embed_size, num_layers, num_hiddens)\n","\n","seq2seq = Seq2Seq(encoder, decoder)\n","\n","seq2seq.to(device)\n","\n","ppl_loss = PerplexityLoss()\n","optim = torch.optim.Adam(seq2seq.parameters(), lr = 0.01)\n","\n","history = []\n","\n","epochs = 10\n","\n","for e in range(epochs):\n","  loop = tqdm(train_dataloader)\n","  running_loss =0\n","\n","  for data in loop:\n","    src_array, tgt_array_bos, valid_len, tgt_array_eos = data\n","    src_array = src_array.to(device)\n","    tgt_array_bos = tgt_array_bos.to(device)\n","    tgt_array_eos = tgt_array_eos.to(device)\n","    valid_len = valid_len.to(device)\n","    # print('src array shape = ', src_array.shape)\n","    # print(f'tgt array bos shape {tgt_array_bos.shape}' )\n","    # print(f'tgt array eos shape {tgt_array_eos.shape}')\n","    # print(f'shape {valid_len.shape}')\n","\n","    y_pred = seq2seq(src_array, tgt_array_bos)\n","    # print('y pred ', y_pred[0])\n","    # print('y pred GRAD', y_pred.grad)\n","    # print('target ', tgt_array_eos[0])\n","\n","    optim.zero_grad()\n","    loss = ppl_loss(y_pred, tgt_array_eos, dataset.tgt_pad)\n","    loss.backward()\n","    step = optim.step()\n","    running_loss += loss.item()\n","    loop.set_description(f'batch ppl = {loss.item():.2f} \\t')\n","\n","  print(f'epoch = {e}, ppl = {running_loss}')\n","  history.append({'loss': running_loss})"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"ROAJrTWS2YFp"},"outputs":[],"source":["if os.path.exists('output') == False:\n","    os.mkdir('output')\n","MODEL_PATH = './output/seq2seq.h5'\n","torch.save(seq2seq, MODEL_PATH)"]},{"cell_type":"markdown","metadata":{"id":"U8KZoiHPB3FN"},"source":["# Evaluating seq2seq model"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12998,"status":"ok","timestamp":1708111241918,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"-cHFEWsgB26n","outputId":"b97b2387-32a5-4d5b-fb6e-cc04e6c58398"},"outputs":[{"name":"stderr","output_type":"stream","text":["DEBUG - start building the dataset\n"]},{"name":"stdout","output_type":"stream","text":["<class '__main__.Seq2Seq'>\n"]},{"name":"stderr","output_type":"stream","text":["INFO - done tokenizing source and target, source len = 141370, target len = 141370\n","INFO - done building source and target arrays\n","DEBUG - source array shape (141370,10)\n","DEBUG - source vocab len = 9538\n","DEBUG - valid_len shape  = torch.Size([141370])\n","DEBUG - target array shape = (141370,10)\n","DEBUG - target vocab len = 16679\n"]}],"source":["MODEL_PATH = './output/seq2seq.h5'\n","assert os.path.exists(MODEL_PATH), f'saved model not found at {MODEL_PATH}' \n","model = torch.load(MODEL_PATH, map_location = torch.device('cpu'))\n","print('loaded mode')\n","print(type(model))\n","dataset = SpanishDataset()"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1708111241918,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"FVV_XkOEDl2S","outputId":"8790ff2e-2b3a-4adb-9503-2c6edd8cae2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[tensor([[4367, 9177, 8623, 5200, 8244, 9512,  661, 9327, 9512,  201],\n","        [9512, 6786, 2702, 5113,  974,   84,  201,  202,  202,  202],\n","        [  68, 9512, 5034, 8623, 3825, 9389, 5293,  205,   70,  201],\n","        [ 203, 3861, 7771, 5548, 4455, 1898,   85,  203, 9287,  201],\n","        [4367, 4859, 9287, 4367, 2551,   84,  201,  202,  202,  202],\n","        [8010, 5836, 8542, 7570, 5805, 8491, 9499, 5046,   84,  201],\n","        [4680, 2117, 8563, 2720,   84,  201,  202,  202,  202,  202],\n","        [7834,   79, 1399, 4367, 4093, 8623, 9427, 8653,   84,  201],\n","        [7483, 9522,  800,   79, 4675, 7480,  204,  201,  202,  202],\n","        [8490, 2315,   84,  201,  202,  202,  202,  202,  202,  202]]), tensor([[  189, 12738,  1576,  4547, 12630, 13849, 12729,  5259, 14001,    78],\n","        [  189, 12872, 14678, 15699,  8042,    78,   190,   191,   191,   191],\n","        [  189,    65,  7799,  8827,  3722,   194,   192,   192,     1,   190],\n","        [  189,   192, 14641,  5969,  3591,    79,   192, 12782,   194,   192],\n","        [  189, 14579,  9493, 12630,  8054,    78,   190,   191,   191,   191],\n","        [  189, 11576,   196,  6729,  9031,  4547,  9021,  9579,  1027,    78],\n","        [  189,  4348, 15244,  9698,    78,   190,   191,   191,   191,   191],\n","        [  189,  9493, 14076, 11603,  6671, 10628,  4578, 15078,    78,   190],\n","        [  189,  6394, 15301, 15348,    72, 16422,   193,   190,   191,   191],\n","        [  189,  6567,  6394, 11437,    78,   190,   191,   191,   191,   191]]), tensor([10,  7, 10, 10,  7, 10,  6, 10,  8,  4]), tensor([[12738,  1576,  4547, 12630, 13849, 12729,  5259, 14001,    78,   190],\n","        [12872, 14678, 15699,  8042,    78,   190,   191,   191,   191,   191],\n","        [   65,  7799,  8827,  3722,   194,   192,   192,     1,   190,   191],\n","        [  192, 14641,  5969,  3591,    79,   192, 12782,   194,   192,   190],\n","        [14579,  9493, 12630,  8054,    78,   190,   191,   191,   191,   191],\n","        [11576,   196,  6729,  9031,  4547,  9021,  9579,  1027,    78,   190],\n","        [ 4348, 15244,  9698,    78,   190,   191,   191,   191,   191,   191],\n","        [ 9493, 14076, 11603,  6671, 10628,  4578, 15078,    78,   190,   191],\n","        [ 6394, 15301, 15348,    72, 16422,   193,   190,   191,   191,   191],\n","        [ 6567,  6394, 11437,    78,   190,   191,   191,   191,   191,   191]])]\n"]}],"source":["def idx_to_tokens(tokens, vocab):\n","    return vocab.to_tokens(tokens)\n","\n","index = []\n","for i in range(10):\n","  index.append(np.random.choice(len(dataset)))\n","\n","batch = []\n","src = []\n","tgt = []\n","valid_len = []\n","tgt_eos = []\n","\n","for i in index:\n","  data = dataset[i]\n","  src.append(data[0])\n","  tgt.append(data[1])\n","  valid_len.append(data[2])\n","  tgt_eos.append(data[3])\n","\n","batch = [torch.stack(a) for a in (src,tgt,valid_len,tgt_eos)]\n","print(batch)"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":185,"status":"ok","timestamp":1708111255617,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"},"user_tz":300},"id":"ede5gQu1VnO5","outputId":"05c4afa5-f0a1-4e64-be16-d89b7ba8adbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["source =  tensor([[4367, 9177, 8623, 5200, 8244, 9512,  661, 9327, 9512,  201],\n","        [9512, 6786, 2702, 5113,  974,   84,  201,  202,  202,  202],\n","        [  68, 9512, 5034, 8623, 3825, 9389, 5293,  205,   70,  201],\n","        [ 203, 3861, 7771, 5548, 4455, 1898,   85,  203, 9287,  201],\n","        [4367, 4859, 9287, 4367, 2551,   84,  201,  202,  202,  202],\n","        [8010, 5836, 8542, 7570, 5805, 8491, 9499, 5046,   84,  201],\n","        [4680, 2117, 8563, 2720,   84,  201,  202,  202,  202,  202],\n","        [7834,   79, 1399, 4367, 4093, 8623, 9427, 8653,   84,  201],\n","        [7483, 9522,  800,   79, 4675, 7480,  204,  201,  202,  202],\n","        [8490, 2315,   84,  201,  202,  202,  202,  202,  202,  202]])\n","target =  tensor([[  189, 12738,  1576,  4547, 12630, 13849, 12729,  5259, 14001,    78],\n","        [  189, 12872, 14678, 15699,  8042,    78,   190,   191,   191,   191],\n","        [  189,    65,  7799,  8827,  3722,   194,   192,   192,     1,   190],\n","        [  189,   192, 14641,  5969,  3591,    79,   192, 12782,   194,   192],\n","        [  189, 14579,  9493, 12630,  8054,    78,   190,   191,   191,   191],\n","        [  189, 11576,   196,  6729,  9031,  4547,  9021,  9579,  1027,    78],\n","        [  189,  4348, 15244,  9698,    78,   190,   191,   191,   191,   191],\n","        [  189,  9493, 14076, 11603,  6671, 10628,  4578, 15078,    78,   190],\n","        [  189,  6394, 15301, 15348,    72, 16422,   193,   190,   191,   191],\n","        [  189,  6567,  6394, 11437,    78,   190,   191,   191,   191,   191]])\n","valid len  =  tensor([10,  7, 10, 10,  7, 10,  6, 10,  8,  4])\n","enc outputs  torch.Size([10, 32, 16])\n","enc state   torch.Size([256, 10, 2])\n","dec state =  torch.Size([2, 32, 16])\n","[tensor([[189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189]])]\n","tensor([[189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189],\n","        [189]])\n","tensor([[14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191],\n","        [14965, 14965, 10625,    78,   191,   191,   191,   191,   191,   191]])\n"]}],"source":["def predict(seq2seq, batch, device, num_steps):\n","  batch = [a.to(device) for a in batch]\n","  src, tgt, valid_len, _ = batch\n","  print('source = ', src)\n","  print('target = ', tgt)\n","  print('valid len  = ', valid_len)\n","\n","  enc_outputs, enc_state = seq2seq.encoder(src, valid_len)\n","  print('enc outputs ', enc_output.shape)\n","  print('enc state  ', enc_state.shape)\n","  dec_all_outputs = seq2seq.decoder.init_state((enc_outputs, enc_state), valid_len)\n","  print('dec state = ', dec_state.shape)\n","\n","  outputs, attention_weights = [tgt[:,(0)].unsqueeze(1), ], []\n","  print(outputs)\n","  print(outputs[-1])\n","\n","  for _ in range(num_steps):\n","    y_pred, dec_all_outputs = seq2seq.decoder(outputs[-1], dec_all_outputs)\n","    outputs.append(y_pred.argmax(2))\n","\n","  return torch.cat(outputs[1:], 1)    \n","\n","outputs = predict(model, batch, 'cpu', 10)\n","print(outputs)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tom woke mary up at 6:30 as she had <eos>\n","captura descifró elegida dolores asfixiado .u abandonado abandonados abandonados abandonados\n","tom tom no . <pad> <pad> <pad> <pad> <pad> <pad>\n","\n"]},{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch): \n\u001b[1;32m----> 2\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_vocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     target \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtarget_vocab\u001b[38;5;241m.\u001b[39mto_tokens(data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      4\u001b[0m     pred \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtarget_vocab\u001b[38;5;241m.\u001b[39mto_tokens(outputs[i]\u001b[38;5;241m.\u001b[39mtolist())\n","File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\d2l\\torch.py:704\u001b[0m, in \u001b[0;36mVocab.to_tokens\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(indices, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_to_token[\u001b[38;5;28mint\u001b[39m(index)] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_to_token[indices]\n","File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\torch\\lib\\site-packages\\d2l\\torch.py:704\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices):\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(indices, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midx_to_token\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_to_token[indices]\n","\u001b[1;31mIndexError\u001b[0m: list index out of range"]}],"source":["for i, data in enumerate(batch): \n","    source = dataset.source_vocab.to_tokens(data[0].tolist())\n","    target = dataset.target_vocab.to_tokens(data[1].tolist())\n","    pred = dataset.target_vocab.to_tokens(outputs[i].tolist())\n","    print(' '.join(source))\n","    print(' '.join(target))\n","    print(' '.join(pred))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"pF_wZM-Pbg31"},"source":["### Unit Tests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9pw8TIXbg31"},"outputs":[],"source":["# class SpanishDatasetTest(unittest.TestCase):\n","\n","#     def test_upper(self):\n","#         self.assertEqual('foo'.upper(), 'FOO')\n","\n","#     def test_isupper(self):\n","#         self.assertTrue('FOO'.isupper())\n","#         self.assertFalse('Foo'.isupper())\n","\n","#     def test_split(self):\n","#         s = 'hello world'\n","#         self.assertEqual(s.split(), ['hello', 'world'])\n","\n","#     def test4(self):\n","#         self.assertEqual('foo', 'foo1')\n","\n","# unittest.main(argv=[''], exit=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DT-xsp-Cbg31"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"af18273774455bc90f5456b9f4898eab7ba4de506fde0c1d0784da333c7e8bbc"}}},"nbformat":4,"nbformat_minor":0}

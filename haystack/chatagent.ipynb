{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://haystack.deepset.ai/tutorials/40_building_chat_application_with_function_calling\n",
    "\n",
    "components: \n",
    "InMemoryDocumentStore, SentenceTransformersDocumentEmbedder, SentenceTransformersTextEmbedder, InMemoryEmbeddingRetriever, ChatPromptBuilder, OpenAIChatGenerator, ToolInvoker\n",
    "\n",
    "OpenAPI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 09:44:23.865609: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-31 09:44:23.873153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-31 09:44:23.881909: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-31 09:44:23.884535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-31 09:44:23.891184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-31 09:44:24.278892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/nguyen/anaconda3/envs/torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "openai_key = False\n",
    "hf_token = False \n",
    "with open(\"secrets\") as file:\n",
    "    for line in file.readlines():\n",
    "        key,value = line.strip().split(\"=\")\n",
    "        if key == 'OPENAI_API_KEY':\n",
    "            openai_key = True\n",
    "            os.environ[key]=value\n",
    "        elif key == 'HF_TOKEN':\n",
    "            hf_token = True\n",
    "            os.environ[key]=value\n",
    "assert openai_key, 'OPENAI_API_KEY not found'\n",
    "assert hf_token, 'HF_TOKEN not found'\n",
    "\n",
    "# assert hf_token, 'HF_TOKEN not found'\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack import Document, Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.writers import DocumentWriter\n",
    "#setup OPENAI_API_KEY\n",
    "from pprint import pprint\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage.from_system('Always respond in German'),\n",
    "    ChatMessage.from_user('Briefly explain about the current state of health care in the US'),\n",
    "]\n",
    "\n",
    "chat_gen = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "# chat_gen = OpenAIChatGenerator(model=\"gpt-4o-mini\", streaming_callback = callback_fn)\n",
    "res = chat_gen.run(messages=messages)\n",
    "\n",
    "# document_store = InMemoryDocumentStore(embedding_similarity_function='cosine')\n",
    "# text_embeder = SentenceTransformersTextEmbedder()\n",
    "# retriever = InMemoryEmbeddingRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Gesundheitswesen in den USA steht vor mehreren Herausforderungen. Obwohl das Land über einige der fortschrittlichsten medizinischen Einrichtungen und Technologien verfügt, gibt es bedeutende Probleme wie hohe Kosten, ungleiche Zugänglichkeit und eine große Anzahl von Menschen ohne Krankenversicherung. Der Affordable Care Act hat zwar dazu beigetragen, die Zahl der Unversicherten zu reduzieren, viele Amerikaner kämpfen jedoch weiterhin mit hohen Prämien und Selbstbeteiligungen. Zudem gibt es Diskussionen über die Notwendigkeit von Reformen, um die Qualität der Versorgung zu verbessern und die Kosten zu senken. Telemedizin und digitale Gesundheit nehmen an Bedeutung zu, insbesondere seit der COVID-19-Pandemie.\n"
     ]
    }
   ],
   "source": [
    "print(res['replies'][0]._content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = [\n",
    "    \"The Earth is the only planet in our solar system not named after a god.\",\n",
    "    \"The Amazon rainforest produces more than 20% of the world's oxygen supply.\",\n",
    "    \"Antarctica is the driest, windiest, and coldest continent.\",\n",
    "    \"There are more than 24 time zones around the world.\",\n",
    "    \"The Great Wall of China is the longest man-made structure in the world.\",\n",
    "    \"Mount Everest is the highest point on Earth.\",\n",
    "    \"The Pacific Ocean is the largest and deepest ocean on Earth.\",\n",
    "    \"Russia is the largest country by land area.\",\n",
    "    \"The Sahara Desert is the largest hot desert in the world.\",\n",
    "    \"The Nile River is the longest river in the world.\"\n",
    "]\n",
    "\n",
    "docs = [Document(content=fact) for fact in facts]\n",
    "doc_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2e920da2334c61b8a0b40c6e5b046c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'doc_writer': {'documents_written': 10}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "pipeline.add_component(\n",
    "    instance=SentenceTransformersDocumentEmbedder(model=embedding_model), \n",
    "    name=\"doc_embedder\"\n",
    ")\n",
    "\n",
    "pipeline.add_component(\n",
    "    name=\"doc_writer\",\n",
    "    instance = DocumentWriter(document_store=doc_store) \n",
    ")\n",
    "\n",
    "pipeline.connect('doc_embedder.documents', 'doc_writer.documents')\n",
    "\n",
    "pipeline.run({'doc_embedder': {\"documents\": docs}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG\n",
    "haystack.components.embedders.SentenceTransformersTextEmbedder\n",
    "haystack.components.retrievers.in_memory.InMemoryEmbeddingRetriever\n",
    "haystack.components.builders.ChatPromptBuilder\n",
    "haystack.dataclasses.ChatMessage\n",
    "haystack.components.generators.chat.OpenAIChatGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = [\n",
    "    ChatMessage.from_system(\n",
    "    \"\"\"\n",
    "    Answer the questions based on the given context.\n",
    "\n",
    "    Context:\n",
    "    {% for document in documents %}\n",
    "        {{ document.content }}\n",
    "    {% endfor %}\n",
    "    Question: {{ question }}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "rag = Pipeline()\n",
    "\n",
    "rag.add_component('embedder', SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "rag.add_component('retriever', InMemoryEmbeddingRetriever(document_store = doc_store))\n",
    "rag.add_component('prompt_builder', ChatPromptBuilder(template = template))\n",
    "rag.add_component('llm', OpenAIChatGenerator(model = 'gpt-4o-mini'))\n",
    "\n",
    "rag.connect('embedder', 'retriever.query_embedding')\n",
    "rag.connect('retriever', 'prompt_builder.documents')\n",
    "rag.connect('prompt_builder.prompt', 'llm.messages')\n",
    "\n",
    "rag.draw(\"sample.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4d9548bb6b42eb88b6a1098ee3fc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ask(question):\n",
    "    return rag.run({'embedder': {'text': question}, 'prompt_builder': {'question' : question} })\n",
    "\n",
    "\n",
    "res = ask(\"What is some facts about earth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llm': {'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text=\"Here are some facts about Earth:\\n\\n1. Earth is the only planet in our solar system not named after a god.\\n2. Antarctica is the driest, windiest, and coldest continent on Earth.\\n3. The Amazon rainforest produces more than 20% of the world's oxygen supply.\\n4. Mount Everest is the highest point on Earth.\\n5. The Pacific Ocean is the largest and deepest ocean on Earth.\\n6. There are more than 24 time zones around the world.\\n7. Russia is the largest country by land area.\\n8. The Sahara Desert is the largest hot desert in the world.\\n9. The Great Wall of China is the longest man-made structure in the world.\\n10. The Nile River is the longest river in the world.\")], _name=None, _meta={'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 155, 'prompt_tokens': 182, 'total_tokens': 337, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}})]}}\n",
      "Here are some facts about Earth:\n",
      "\n",
      "1. Earth is the only planet in our solar system not named after a god.\n",
      "2. Antarctica is the driest, windiest, and coldest continent on Earth.\n",
      "3. The Amazon rainforest produces more than 20% of the world's oxygen supply.\n",
      "4. Mount Everest is the highest point on Earth.\n",
      "5. The Pacific Ocean is the largest and deepest ocean on Earth.\n",
      "6. There are more than 24 time zones around the world.\n",
      "7. Russia is the largest country by land area.\n",
      "8. The Sahara Desert is the largest hot desert in the world.\n",
      "9. The Great Wall of China is the longest man-made structure in the world.\n",
      "10. The Nile River is the longest river in the world.\n"
     ]
    }
   ],
   "source": [
    "print(res)\n",
    "print(res['llm']['replies'][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tools in Haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline as a tool\n",
    "from haystack.tools import Tool\n",
    "\n",
    "params = {\n",
    "    'type': 'object',\n",
    "    'properties': {\n",
    "        'question': {\n",
    "            'type': 'string',\n",
    "            'description': 'Query used for search. Infer this information from user message'\n",
    "        }\n",
    "    },\n",
    "    'required': ['question']\n",
    "}\n",
    "\n",
    "rag_tool = Tool(\n",
    "    name='rag_pipeline_tool',\n",
    "    description=\"Get information about provided facts in the document_store\",\n",
    "    parameters=params,\n",
    "    function = ask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Function as a tool\n",
    "from typing import Annotated, Literal\n",
    "from haystack.tools import create_tool_from_function\n",
    "\n",
    "WEATHER_INFO = {\n",
    "    \"Berlin\": {\"weather\": \"mostly sunny\", \"temperature\": 7, \"unit\": \"celsius\"},\n",
    "    \"Paris\": {\"weather\": \"mostly cloudy\", \"temperature\": 8, \"unit\": \"celsius\"},\n",
    "    \"Rome\": {\"weather\": \"sunny\", \"temperature\": 14, \"unit\": \"celsius\"},\n",
    "    \"Madrid\": {\"weather\": \"sunny\", \"temperature\": 10, \"unit\": \"celsius\"},\n",
    "    \"London\": {\"weather\": \"cloudy\", \"temperature\": 9, \"unit\": \"celsius\"},\n",
    "}\n",
    "\n",
    "\n",
    "def get_weather(\n",
    "        city: Annotated[str, 'the city for which to get weather'] = 'Berlin',\n",
    "        unit: Annotated[Literal[\"Celsius\", \"Fahrenheit\"], 'the temperature unit'] = 'Berlin'):\n",
    "    '''A simple function to get the current weather for a location'''\n",
    "    if city in WEATHER_INFO:\n",
    "        return WEATHER_INFO[city]\n",
    "    else:\n",
    "        return {\"weather\": \"sunny\", \"temperature\": 21.8, \"unit\": \"fahrenheit\"}\n",
    "\n",
    "weather_tool = create_tool_from_function(get_weather)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running OpenAIChatGenerator with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.tools import ToolInvoker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_messages = [\n",
    "    ChatMessage.from_system(\n",
    "        \"Use the tool that you're provided with. Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\",\n",
    "    ),\n",
    "    ChatMessage.from_user('Can you tell me 1 interesting fact')\n",
    "]\n",
    "\n",
    "res = chat_gen.run(messages = user_messages, tools = [rag_tool, weather_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>,\n",
      "            _content=[ToolCall(tool_name='rag_pipeline_tool',\n",
      "                               arguments={'question': 'Tell me an interesting '\n",
      "                                                      'fact'},\n",
      "                               id='call_5FJDCudTaBDZCn1ta1SHAUri')],\n",
      "            _name=None,\n",
      "            _meta={'finish_reason': 'tool_calls',\n",
      "                   'index': 0,\n",
      "                   'model': 'gpt-4o-mini-2024-07-18',\n",
      "                   'usage': {'completion_tokens': 21,\n",
      "                             'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0),\n",
      "                             'prompt_tokens': 160,\n",
      "                             'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0),\n",
      "                             'total_tokens': 181}})\n"
     ]
    }
   ],
   "source": [
    "pprint(res['replies'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen/anaconda3/envs/torch/lib/python3.12/site-packages/haystack/components/tools/tool_invoker.py:123: UserWarning: The `ToolInvoker` component is experimental and its API may change in the future.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ac25457f1f47f4876f3b833c535c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatMessage(_role=<ChatRole.TOOL: 'tool'>, _content=[ToolCallResult(result='{\\'llm\\': {\\'replies\\': [ChatMessage(_role=<ChatRole.ASSISTANT: \\'assistant\\'>, _content=[TextContent(text=\"An interesting fact is that the Amazon rainforest produces more than 20% of the world\\'s oxygen supply.\")], _name=None, _meta={\\'model\\': \\'gpt-4o-mini-2024-07-18\\', \\'index\\': 0, \\'finish_reason\\': \\'stop\\', \\'usage\\': {\\'completion_tokens\\': 21, \\'prompt_tokens\\': 181, \\'total_tokens\\': 202, \\'completion_tokens_details\\': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), \\'prompt_tokens_details\\': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}})]}}', origin=ToolCall(tool_name='rag_pipeline_tool', arguments={'question': 'Tell me an interesting fact'}, id='call_5FJDCudTaBDZCn1ta1SHAUri'), error=False)], _name=None, _meta={})]\n"
     ]
    }
   ],
   "source": [
    "tool_invoker = ToolInvoker(tools = [rag_tool, weather_tool])\n",
    "\n",
    "tool_res_message = tool_invoker.run(messages = res['replies'])['tool_messages']\n",
    "# ToolCallResult is a json. so you can call the tool in your code\n",
    "print(tool_res_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[ToolCall(tool_name='rag_pipeline_tool', arguments={'question': 'Tell me an interesting fact'}, id='call_5FJDCudTaBDZCn1ta1SHAUri')], _name=None, _meta={'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'tool_calls', 'usage': {'completion_tokens': 21, 'prompt_tokens': 160, 'total_tokens': 181, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}})]\n"
     ]
    }
   ],
   "source": [
    "print(res['replies'])\n",
    "\n",
    "final_message = user_messages + res['replies'] + tool_res_message\n",
    "\n",
    "final_rep = chat_gen.run(messages = final_message, tools = [rag_tool, weather_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'replies': [ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>,\n",
      "                         _content=[TextContent(text='An interesting fact is '\n",
      "                                                    'that the Amazon '\n",
      "                                                    'rainforest produces more '\n",
      "                                                    \"than 20% of the world's \"\n",
      "                                                    'oxygen supply.')],\n",
      "                         _name=None,\n",
      "                         _meta={'finish_reason': 'stop',\n",
      "                                'index': 0,\n",
      "                                'model': 'gpt-4o-mini-2024-07-18',\n",
      "                                'usage': {'completion_tokens': 22,\n",
      "                                          'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0),\n",
      "                                          'prompt_tokens': 354,\n",
      "                                          'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0),\n",
      "                                          'total_tokens': 376}})]}\n"
     ]
    }
   ],
   "source": [
    "pprint(final_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
